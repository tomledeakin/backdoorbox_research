Creating poisoned training set for adaptive_blend on cifar10...
[target class : 0]
Files already downloaded and verified
Poisoned set directory 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/imgs
Will save to 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'.
Model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' already exists!
<Backdoor Training> Train Epoch: 1 	Loss: 1.707518, lr: 0.100000, Time: 10.28s
Clean ACC: 3220/8000 = 0.402500, Loss: 1.6396985054016113
ASR: 1087/7193 = 0.151119


<Backdoor Training> Train Epoch: 2 	Loss: 1.357585, lr: 0.100000, Time: 6.35s
Clean ACC: 4255/8000 = 0.531875, Loss: 1.2841415405273438
ASR: 1488/7193 = 0.206868


<Backdoor Training> Train Epoch: 3 	Loss: 1.062159, lr: 0.100000, Time: 6.40s
Clean ACC: 4558/8000 = 0.569750, Loss: 1.1937685012817383
ASR: 481/7193 = 0.066871


<Backdoor Training> Train Epoch: 4 	Loss: 1.079408, lr: 0.100000, Time: 6.83s
Clean ACC: 4951/8000 = 0.618875, Loss: 1.1209437847137451
ASR: 691/7193 = 0.096066


<Backdoor Training> Train Epoch: 5 	Loss: 0.782217, lr: 0.100000, Time: 6.71s
Clean ACC: 5411/8000 = 0.676375, Loss: 0.9169033169746399
ASR: 696/7193 = 0.096761


<Backdoor Training> Train Epoch: 6 	Loss: 0.701915, lr: 0.100000, Time: 6.65s
Clean ACC: 5743/8000 = 0.717875, Loss: 0.8120471239089966
ASR: 774/7193 = 0.107605


<Backdoor Training> Train Epoch: 7 	Loss: 0.608135, lr: 0.100000, Time: 6.71s
Clean ACC: 5966/8000 = 0.745750, Loss: 0.7408771514892578
ASR: 2909/7193 = 0.404421


<Backdoor Training> Train Epoch: 8 	Loss: 0.472471, lr: 0.100000, Time: 6.72s
Clean ACC: 6175/8000 = 0.771875, Loss: 0.6775630712509155
ASR: 3407/7193 = 0.473655


<Backdoor Training> Train Epoch: 9 	Loss: 0.673589, lr: 0.100000, Time: 6.76s
Clean ACC: 6426/8000 = 0.803250, Loss: 0.5648231506347656
ASR: 4977/7193 = 0.691923


<Backdoor Training> Train Epoch: 10 	Loss: 0.508586, lr: 0.100000, Time: 6.66s
Clean ACC: 6384/8000 = 0.798000, Loss: 0.5733116865158081
ASR: 4887/7193 = 0.679411


<Backdoor Training> Train Epoch: 11 	Loss: 0.446590, lr: 0.100000, Time: 6.33s
Clean ACC: 6464/8000 = 0.808000, Loss: 0.5560817718505859
ASR: 5401/7193 = 0.750869


<Backdoor Training> Train Epoch: 12 	Loss: 0.501907, lr: 0.100000, Time: 6.28s
Clean ACC: 6562/8000 = 0.820250, Loss: 0.5486975908279419
ASR: 6308/7193 = 0.876964


<Backdoor Training> Train Epoch: 13 	Loss: 0.361967, lr: 0.100000, Time: 6.20s
Clean ACC: 6619/8000 = 0.827375, Loss: 0.4945237934589386
ASR: 4703/7193 = 0.653830


<Backdoor Training> Train Epoch: 14 	Loss: 0.382733, lr: 0.100000, Time: 6.35s
Clean ACC: 6668/8000 = 0.833500, Loss: 0.4929552674293518
ASR: 6945/7193 = 0.965522


<Backdoor Training> Train Epoch: 15 	Loss: 0.397339, lr: 0.100000, Time: 6.67s
Clean ACC: 6713/8000 = 0.839125, Loss: 0.48142823576927185
ASR: 6505/7193 = 0.904351


<Backdoor Training> Train Epoch: 16 	Loss: 0.445793, lr: 0.100000, Time: 6.71s
Clean ACC: 6839/8000 = 0.854875, Loss: 0.4319969117641449
ASR: 7044/7193 = 0.979285


<Backdoor Training> Train Epoch: 17 	Loss: 0.472139, lr: 0.100000, Time: 6.75s
Clean ACC: 6861/8000 = 0.857625, Loss: 0.43996962904930115
ASR: 7066/7193 = 0.982344


<Backdoor Training> Train Epoch: 18 	Loss: 0.515744, lr: 0.100000, Time: 6.69s
Clean ACC: 6809/8000 = 0.851125, Loss: 0.4633012115955353
ASR: 7171/7193 = 0.996941


<Backdoor Training> Train Epoch: 19 	Loss: 0.243816, lr: 0.100000, Time: 6.69s
Clean ACC: 6944/8000 = 0.868000, Loss: 0.39267799258232117
ASR: 6979/7193 = 0.970249


<Backdoor Training> Train Epoch: 20 	Loss: 0.432329, lr: 0.100000, Time: 6.64s
Clean ACC: 6788/8000 = 0.848500, Loss: 0.48123669624328613
ASR: 6667/7193 = 0.926873


<Backdoor Training> Train Epoch: 21 	Loss: 0.330697, lr: 0.100000, Time: 6.80s
Clean ACC: 6918/8000 = 0.864750, Loss: 0.40826332569122314
ASR: 6875/7193 = 0.955790


<Backdoor Training> Train Epoch: 22 	Loss: 0.278875, lr: 0.100000, Time: 6.33s
Clean ACC: 6990/8000 = 0.873750, Loss: 0.3790665864944458
ASR: 7148/7193 = 0.993744


<Backdoor Training> Train Epoch: 23 	Loss: 0.384043, lr: 0.100000, Time: 6.33s
Clean ACC: 6908/8000 = 0.863500, Loss: 0.446443110704422
ASR: 7122/7193 = 0.990129


<Backdoor Training> Train Epoch: 24 	Loss: 0.252260, lr: 0.100000, Time: 6.22s
Clean ACC: 7009/8000 = 0.876125, Loss: 0.38164022564888
ASR: 6859/7193 = 0.953566


<Backdoor Training> Train Epoch: 25 	Loss: 0.191665, lr: 0.100000, Time: 6.34s
Clean ACC: 6987/8000 = 0.873375, Loss: 0.3895863890647888
ASR: 7102/7193 = 0.987349


<Backdoor Training> Train Epoch: 26 	Loss: 0.238983, lr: 0.100000, Time: 6.49s
Clean ACC: 6981/8000 = 0.872625, Loss: 0.4173058867454529
ASR: 7171/7193 = 0.996941


<Backdoor Training> Train Epoch: 27 	Loss: 0.190251, lr: 0.100000, Time: 6.62s
Clean ACC: 6998/8000 = 0.874750, Loss: 0.395210325717926
ASR: 6880/7193 = 0.956485


<Backdoor Training> Train Epoch: 28 	Loss: 0.345356, lr: 0.100000, Time: 6.66s
Clean ACC: 6976/8000 = 0.872000, Loss: 0.4237894117832184
ASR: 7175/7193 = 0.997498


<Backdoor Training> Train Epoch: 29 	Loss: 0.209063, lr: 0.100000, Time: 6.71s
Clean ACC: 6984/8000 = 0.873000, Loss: 0.4216269850730896
ASR: 7089/7193 = 0.985541


<Backdoor Training> Train Epoch: 30 	Loss: 0.239562, lr: 0.100000, Time: 6.84s
Clean ACC: 6906/8000 = 0.863250, Loss: 0.45992085337638855
ASR: 7121/7193 = 0.989990


<Backdoor Training> Train Epoch: 31 	Loss: 0.203233, lr: 0.100000, Time: 6.72s
Clean ACC: 7019/8000 = 0.877375, Loss: 0.3879604637622833
ASR: 7128/7193 = 0.990963


<Backdoor Training> Train Epoch: 32 	Loss: 0.161123, lr: 0.100000, Time: 6.67s
Clean ACC: 6930/8000 = 0.866250, Loss: 0.423852801322937
ASR: 7008/7193 = 0.974281


<Backdoor Training> Train Epoch: 33 	Loss: 0.207103, lr: 0.100000, Time: 6.31s
Clean ACC: 7001/8000 = 0.875125, Loss: 0.41819798946380615
ASR: 7076/7193 = 0.983734


<Backdoor Training> Train Epoch: 34 	Loss: 0.306271, lr: 0.100000, Time: 6.28s
Clean ACC: 7079/8000 = 0.884875, Loss: 0.3675704896450043
ASR: 7171/7193 = 0.996941


<Backdoor Training> Train Epoch: 35 	Loss: 0.117091, lr: 0.100000, Time: 6.40s
Clean ACC: 7097/8000 = 0.887125, Loss: 0.3533487915992737
ASR: 7141/7193 = 0.992771


<Backdoor Training> Train Epoch: 36 	Loss: 0.197723, lr: 0.100000, Time: 6.42s
Clean ACC: 7039/8000 = 0.879875, Loss: 0.3931763172149658
ASR: 7128/7193 = 0.990963


<Backdoor Training> Train Epoch: 37 	Loss: 0.145443, lr: 0.100000, Time: 6.25s
Clean ACC: 7088/8000 = 0.886000, Loss: 0.37664496898651123
ASR: 7191/7193 = 0.999722


<Backdoor Training> Train Epoch: 38 	Loss: 0.165969, lr: 0.100000, Time: 6.81s
Clean ACC: 7079/8000 = 0.884875, Loss: 0.3871598243713379
ASR: 7179/7193 = 0.998054


<Backdoor Training> Train Epoch: 39 	Loss: 0.110742, lr: 0.100000, Time: 6.66s
Clean ACC: 7096/8000 = 0.887000, Loss: 0.3854069113731384
ASR: 7039/7193 = 0.978590


<Backdoor Training> Train Epoch: 40 	Loss: 0.133617, lr: 0.100000, Time: 6.68s
Clean ACC: 7102/8000 = 0.887750, Loss: 0.39124396443367004
ASR: 6933/7193 = 0.963854


<Backdoor Training> Train Epoch: 41 	Loss: 0.097607, lr: 0.100000, Time: 6.69s
Clean ACC: 7042/8000 = 0.880250, Loss: 0.4201042652130127
ASR: 7136/7193 = 0.992076


<Backdoor Training> Train Epoch: 42 	Loss: 0.162889, lr: 0.100000, Time: 6.83s
Clean ACC: 6978/8000 = 0.872250, Loss: 0.4556439220905304
ASR: 7175/7193 = 0.997498


<Backdoor Training> Train Epoch: 43 	Loss: 0.098734, lr: 0.100000, Time: 6.73s
Clean ACC: 7129/8000 = 0.891125, Loss: 0.3737833499908447
ASR: 7148/7193 = 0.993744


<Backdoor Training> Train Epoch: 44 	Loss: 0.096681, lr: 0.100000, Time: 6.32s
Clean ACC: 7046/8000 = 0.880750, Loss: 0.39989444613456726
ASR: 7150/7193 = 0.994022


<Backdoor Training> Train Epoch: 45 	Loss: 0.170799, lr: 0.100000, Time: 6.32s
Clean ACC: 7069/8000 = 0.883625, Loss: 0.40020501613616943
ASR: 7038/7193 = 0.978451


<Backdoor Training> Train Epoch: 46 	Loss: 0.146930, lr: 0.100000, Time: 6.34s
Clean ACC: 7103/8000 = 0.887875, Loss: 0.3914737105369568
ASR: 7176/7193 = 0.997637


<Backdoor Training> Train Epoch: 47 	Loss: 0.188794, lr: 0.100000, Time: 6.21s
Clean ACC: 7107/8000 = 0.888375, Loss: 0.4023572504520416
ASR: 7142/7193 = 0.992910


<Backdoor Training> Train Epoch: 48 	Loss: 0.087938, lr: 0.100000, Time: 6.30s
Clean ACC: 7136/8000 = 0.892000, Loss: 0.35749921202659607
ASR: 6986/7193 = 0.971222


<Backdoor Training> Train Epoch: 49 	Loss: 0.259909, lr: 0.100000, Time: 6.77s
Clean ACC: 7056/8000 = 0.882000, Loss: 0.3996831774711609
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 50 	Loss: 0.184844, lr: 0.100000, Time: 6.66s
Clean ACC: 7016/8000 = 0.877000, Loss: 0.42933183908462524
ASR: 7176/7193 = 0.997637


<Backdoor Training> Train Epoch: 51 	Loss: 0.055878, lr: 0.010000, Time: 6.67s
Clean ACC: 7384/8000 = 0.923000, Loss: 0.2625371515750885
ASR: 7179/7193 = 0.998054


<Backdoor Training> Train Epoch: 52 	Loss: 0.051460, lr: 0.010000, Time: 6.67s
Clean ACC: 7416/8000 = 0.927000, Loss: 0.2613505423069
ASR: 7181/7193 = 0.998332


<Backdoor Training> Train Epoch: 53 	Loss: 0.038426, lr: 0.010000, Time: 6.66s
Clean ACC: 7416/8000 = 0.927000, Loss: 0.26401180028915405
ASR: 7179/7193 = 0.998054


<Backdoor Training> Train Epoch: 54 	Loss: 0.075504, lr: 0.010000, Time: 6.69s
Clean ACC: 7429/8000 = 0.928625, Loss: 0.2640351951122284
ASR: 7179/7193 = 0.998054


<Backdoor Training> Train Epoch: 55 	Loss: 0.009992, lr: 0.010000, Time: 6.58s
Clean ACC: 7443/8000 = 0.930375, Loss: 0.26666030287742615
ASR: 7182/7193 = 0.998471


<Backdoor Training> Train Epoch: 56 	Loss: 0.018391, lr: 0.010000, Time: 6.40s
Clean ACC: 7428/8000 = 0.928500, Loss: 0.2726360559463501
ASR: 7180/7193 = 0.998193


<Backdoor Training> Train Epoch: 57 	Loss: 0.010630, lr: 0.010000, Time: 6.29s
Clean ACC: 7443/8000 = 0.930375, Loss: 0.2766079306602478
ASR: 7180/7193 = 0.998193


<Backdoor Training> Train Epoch: 58 	Loss: 0.009755, lr: 0.010000, Time: 6.31s
Clean ACC: 7454/8000 = 0.931750, Loss: 0.2770002782344818
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 59 	Loss: 0.021014, lr: 0.010000, Time: 6.49s
Clean ACC: 7435/8000 = 0.929375, Loss: 0.28221291303634644
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 60 	Loss: 0.020738, lr: 0.010000, Time: 6.65s
Clean ACC: 7445/8000 = 0.930625, Loss: 0.28174036741256714
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 61 	Loss: 0.027636, lr: 0.010000, Time: 6.70s
Clean ACC: 7456/8000 = 0.932000, Loss: 0.28183501958847046
ASR: 7185/7193 = 0.998888


<Backdoor Training> Train Epoch: 62 	Loss: 0.009575, lr: 0.010000, Time: 6.65s
Clean ACC: 7451/8000 = 0.931375, Loss: 0.2826830744743347
ASR: 7181/7193 = 0.998332


<Backdoor Training> Train Epoch: 63 	Loss: 0.001769, lr: 0.010000, Time: 6.59s
Clean ACC: 7453/8000 = 0.931625, Loss: 0.28556063771247864
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 64 	Loss: 0.001567, lr: 0.010000, Time: 6.71s
Clean ACC: 7455/8000 = 0.931875, Loss: 0.2847929298877716
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 65 	Loss: 0.007437, lr: 0.010000, Time: 6.63s
Clean ACC: 7459/8000 = 0.932375, Loss: 0.2855801582336426
ASR: 7182/7193 = 0.998471


<Backdoor Training> Train Epoch: 66 	Loss: 0.001383, lr: 0.010000, Time: 6.66s
Clean ACC: 7460/8000 = 0.932500, Loss: 0.2897889018058777
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 67 	Loss: 0.030313, lr: 0.010000, Time: 6.38s
Clean ACC: 7452/8000 = 0.931500, Loss: 0.29285675287246704
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 68 	Loss: 0.009124, lr: 0.010000, Time: 6.24s
Clean ACC: 7447/8000 = 0.930875, Loss: 0.2964470088481903
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 69 	Loss: 0.003553, lr: 0.010000, Time: 6.23s
Clean ACC: 7438/8000 = 0.929750, Loss: 0.2982240617275238
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 70 	Loss: 0.007256, lr: 0.010000, Time: 6.40s
Clean ACC: 7453/8000 = 0.931625, Loss: 0.2983364164829254
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 71 	Loss: 0.000760, lr: 0.010000, Time: 6.42s
Clean ACC: 7439/8000 = 0.929875, Loss: 0.29967159032821655
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 72 	Loss: 0.001541, lr: 0.010000, Time: 6.75s
Clean ACC: 7456/8000 = 0.932000, Loss: 0.29695016145706177
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 73 	Loss: 0.019919, lr: 0.010000, Time: 6.66s
Clean ACC: 7465/8000 = 0.933125, Loss: 0.29447799921035767
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 74 	Loss: 0.003303, lr: 0.010000, Time: 6.73s
Clean ACC: 7449/8000 = 0.931125, Loss: 0.29921597242355347
ASR: 7182/7193 = 0.998471


<Backdoor Training> Train Epoch: 75 	Loss: 0.010394, lr: 0.010000, Time: 6.73s
Clean ACC: 7442/8000 = 0.930250, Loss: 0.30230867862701416
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 76 	Loss: 0.002520, lr: 0.001000, Time: 6.78s
Clean ACC: 7450/8000 = 0.931250, Loss: 0.30100932717323303
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 77 	Loss: 0.003456, lr: 0.001000, Time: 6.72s
Clean ACC: 7454/8000 = 0.931750, Loss: 0.30074363946914673
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 78 	Loss: 0.000474, lr: 0.001000, Time: 6.43s
Clean ACC: 7445/8000 = 0.930625, Loss: 0.29995712637901306
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 79 	Loss: 0.002728, lr: 0.001000, Time: 6.25s
Clean ACC: 7453/8000 = 0.931625, Loss: 0.2990722358226776
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 80 	Loss: 0.001667, lr: 0.001000, Time: 6.36s
Clean ACC: 7450/8000 = 0.931250, Loss: 0.30118757486343384
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 81 	Loss: 0.019257, lr: 0.001000, Time: 6.38s
Clean ACC: 7458/8000 = 0.932250, Loss: 0.29817891120910645
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 82 	Loss: 0.003011, lr: 0.001000, Time: 6.48s
Clean ACC: 7461/8000 = 0.932625, Loss: 0.298309326171875
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 83 	Loss: 0.003099, lr: 0.001000, Time: 6.69s
Clean ACC: 7450/8000 = 0.931250, Loss: 0.2974298894405365
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 84 	Loss: 0.002375, lr: 0.001000, Time: 6.68s
Clean ACC: 7459/8000 = 0.932375, Loss: 0.29831138253211975
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 85 	Loss: 0.001563, lr: 0.001000, Time: 6.62s
Clean ACC: 7459/8000 = 0.932375, Loss: 0.2959882318973541
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 86 	Loss: 0.008040, lr: 0.001000, Time: 6.54s
Clean ACC: 7467/8000 = 0.933375, Loss: 0.29742947220802307
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 87 	Loss: 0.003731, lr: 0.001000, Time: 6.70s
Clean ACC: 7453/8000 = 0.931625, Loss: 0.29844018816947937
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 88 	Loss: 0.001700, lr: 0.001000, Time: 6.74s
Clean ACC: 7465/8000 = 0.933125, Loss: 0.30002954602241516
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 89 	Loss: 0.002886, lr: 0.001000, Time: 6.63s
Clean ACC: 7474/8000 = 0.934250, Loss: 0.2968589961528778
ASR: 7181/7193 = 0.998332


<Backdoor Training> Train Epoch: 90 	Loss: 0.003430, lr: 0.001000, Time: 6.37s
Clean ACC: 7473/8000 = 0.934125, Loss: 0.29565495252609253
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 91 	Loss: 0.001570, lr: 0.001000, Time: 6.23s
Clean ACC: 7463/8000 = 0.932875, Loss: 0.2988162636756897
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 92 	Loss: 0.004676, lr: 0.001000, Time: 6.34s
Clean ACC: 7459/8000 = 0.932375, Loss: 0.2978576123714447
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 93 	Loss: 0.018108, lr: 0.001000, Time: 6.38s
Clean ACC: 7458/8000 = 0.932250, Loss: 0.2997213900089264
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 94 	Loss: 0.004530, lr: 0.001000, Time: 6.64s
Clean ACC: 7462/8000 = 0.932750, Loss: 0.29845303297042847
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 95 	Loss: 0.001327, lr: 0.001000, Time: 6.69s
Clean ACC: 7463/8000 = 0.932875, Loss: 0.2972411513328552
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 96 	Loss: 0.001701, lr: 0.001000, Time: 6.82s
Clean ACC: 7455/8000 = 0.931875, Loss: 0.2986510097980499
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 97 	Loss: 0.000565, lr: 0.001000, Time: 6.69s
Clean ACC: 7454/8000 = 0.931750, Loss: 0.30112236738204956
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 98 	Loss: 0.006159, lr: 0.001000, Time: 6.69s
Clean ACC: 7459/8000 = 0.932375, Loss: 0.30193647742271423
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 99 	Loss: 0.002473, lr: 0.001000, Time: 6.70s
Clean ACC: 7473/8000 = 0.934125, Loss: 0.29455801844596863
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 100 	Loss: 0.003743, lr: 0.001000, Time: 6.58s
Clean ACC: 7461/8000 = 0.932625, Loss: 0.29968535900115967
ASR: 7183/7193 = 0.998610


Testing the backdoor model...
Evaluating model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 7461/8000 = 0.932625, Loss: 0.29968535900115967
ASR: 7183/7193 = 0.998610

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7461/8000 = 0.932625, Loss: 0.2996881902217865
ASR: 7183/7193 = 0.998610

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.369188, poison_dis: 7.886140
Silhouette Score: 0.45287648
Saved figure at assets/pca_cifar10_adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7461/8000 = 0.932625, Loss: 0.2996881902217865
ASR: 7183/7193 = 0.998610

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.369188, poison_dis: 7.886140
Silhouette Score: 0.45287648
Saved figure at assets/tsne_cifar10_adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7461/8000 = 0.932625, Loss: 0.2996881902217865
ASR: 7183/7193 = 0.998610

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.369188, poison_dis: 7.886140
Silhouette Score: 0.45287648
SVM Accuracy: 1.0
Saved figure at assets/oracle_cifar10_adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/hellokitty_32.png
trigger_mask_path: ./triggers/mask_hellokitty_32.png
Evaluating model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 93.26250457763672
asr: 99.86097717285156
target label: tensor([0], device='cuda:0')
start_index: 9
TPR: 99.59
FPR: 2.33
AUC: 0.9988
f1 score: 0.9864421469696032
Elapsed time: 16.61s
Experiment for cifar10 with adaptive_blend completed.
