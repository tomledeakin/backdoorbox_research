Creating poisoned training set for adaptive_blend on cifar10...
[target class : 0]
Files already downloaded and verified
Poisoned set directory 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/imgs
Will save to 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'.
Model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' already exists!
<Backdoor Training> Train Epoch: 1 	Loss: 1.524372, lr: 0.100000, Time: 9.86s
Clean ACC: 2929/8000 = 0.366125, Loss: 1.761157512664795
ASR: 394/7193 = 0.054775


<Backdoor Training> Train Epoch: 2 	Loss: 1.610318, lr: 0.100000, Time: 6.02s
Clean ACC: 3963/8000 = 0.495375, Loss: 1.3685908317565918
ASR: 950/7193 = 0.132073


<Backdoor Training> Train Epoch: 3 	Loss: 1.302067, lr: 0.100000, Time: 5.92s
Clean ACC: 4820/8000 = 0.602500, Loss: 1.1159031391143799
ASR: 1087/7193 = 0.151119


<Backdoor Training> Train Epoch: 4 	Loss: 0.868993, lr: 0.100000, Time: 5.91s
Clean ACC: 5230/8000 = 0.653750, Loss: 0.9898238778114319
ASR: 392/7193 = 0.054497


<Backdoor Training> Train Epoch: 5 	Loss: 0.820921, lr: 0.100000, Time: 5.90s
Clean ACC: 5362/8000 = 0.670250, Loss: 0.9358712434768677
ASR: 935/7193 = 0.129987


<Backdoor Training> Train Epoch: 6 	Loss: 0.730154, lr: 0.100000, Time: 5.95s
Clean ACC: 6015/8000 = 0.751875, Loss: 0.7183129191398621
ASR: 3013/7193 = 0.418879


<Backdoor Training> Train Epoch: 7 	Loss: 0.706522, lr: 0.100000, Time: 5.91s
Clean ACC: 6104/8000 = 0.763000, Loss: 0.6939056515693665
ASR: 3374/7193 = 0.469067


<Backdoor Training> Train Epoch: 8 	Loss: 0.591713, lr: 0.100000, Time: 5.92s
Clean ACC: 6280/8000 = 0.785000, Loss: 0.6526473760604858
ASR: 4729/7193 = 0.657445


<Backdoor Training> Train Epoch: 9 	Loss: 0.695976, lr: 0.100000, Time: 5.95s
Clean ACC: 6238/8000 = 0.779750, Loss: 0.6596474647521973
ASR: 6550/7193 = 0.910608


<Backdoor Training> Train Epoch: 10 	Loss: 0.637280, lr: 0.100000, Time: 5.93s
Clean ACC: 6408/8000 = 0.801000, Loss: 0.5865546464920044
ASR: 6199/7193 = 0.861810


<Backdoor Training> Train Epoch: 11 	Loss: 0.566226, lr: 0.100000, Time: 5.95s
Clean ACC: 6576/8000 = 0.822000, Loss: 0.5444365739822388
ASR: 6801/7193 = 0.945503


<Backdoor Training> Train Epoch: 12 	Loss: 0.457668, lr: 0.100000, Time: 5.93s
Clean ACC: 6631/8000 = 0.828875, Loss: 0.4969022572040558
ASR: 7051/7193 = 0.980259


<Backdoor Training> Train Epoch: 13 	Loss: 0.230247, lr: 0.100000, Time: 5.94s
Clean ACC: 6803/8000 = 0.850375, Loss: 0.4554539918899536
ASR: 7059/7193 = 0.981371


<Backdoor Training> Train Epoch: 14 	Loss: 0.613218, lr: 0.100000, Time: 5.96s
Clean ACC: 6730/8000 = 0.841250, Loss: 0.483565092086792
ASR: 6955/7193 = 0.966912


<Backdoor Training> Train Epoch: 15 	Loss: 0.298899, lr: 0.100000, Time: 5.96s
Clean ACC: 6778/8000 = 0.847250, Loss: 0.4530888497829437
ASR: 7131/7193 = 0.991381


<Backdoor Training> Train Epoch: 16 	Loss: 0.297893, lr: 0.100000, Time: 5.94s
Clean ACC: 6880/8000 = 0.860000, Loss: 0.42682918906211853
ASR: 7128/7193 = 0.990963


<Backdoor Training> Train Epoch: 17 	Loss: 0.449032, lr: 0.100000, Time: 5.94s
Clean ACC: 6915/8000 = 0.864375, Loss: 0.41054365038871765
ASR: 7008/7193 = 0.974281


<Backdoor Training> Train Epoch: 18 	Loss: 0.229982, lr: 0.100000, Time: 5.94s
Clean ACC: 6856/8000 = 0.857000, Loss: 0.43588343262672424
ASR: 6960/7193 = 0.967607


<Backdoor Training> Train Epoch: 19 	Loss: 0.333855, lr: 0.100000, Time: 5.96s
Clean ACC: 6992/8000 = 0.874000, Loss: 0.3831331133842468
ASR: 7140/7193 = 0.992632


<Backdoor Training> Train Epoch: 20 	Loss: 0.193302, lr: 0.100000, Time: 5.95s
Clean ACC: 6854/8000 = 0.856750, Loss: 0.43581482768058777
ASR: 6733/7193 = 0.936049


<Backdoor Training> Train Epoch: 21 	Loss: 0.222716, lr: 0.100000, Time: 5.94s
Clean ACC: 6795/8000 = 0.849375, Loss: 0.49693241715431213
ASR: 7171/7193 = 0.996941


<Backdoor Training> Train Epoch: 22 	Loss: 0.207247, lr: 0.100000, Time: 5.97s
Clean ACC: 6968/8000 = 0.871000, Loss: 0.4214884042739868
ASR: 7109/7193 = 0.988322


<Backdoor Training> Train Epoch: 23 	Loss: 0.253859, lr: 0.100000, Time: 5.98s
Clean ACC: 7109/8000 = 0.888625, Loss: 0.34396418929100037
ASR: 7150/7193 = 0.994022


<Backdoor Training> Train Epoch: 24 	Loss: 0.193555, lr: 0.100000, Time: 5.95s
Clean ACC: 7093/8000 = 0.886625, Loss: 0.3564684987068176
ASR: 7138/7193 = 0.992354


<Backdoor Training> Train Epoch: 25 	Loss: 0.318261, lr: 0.100000, Time: 5.97s
Clean ACC: 7067/8000 = 0.883375, Loss: 0.3641100525856018
ASR: 7171/7193 = 0.996941


<Backdoor Training> Train Epoch: 26 	Loss: 0.310139, lr: 0.100000, Time: 5.97s
Clean ACC: 7022/8000 = 0.877750, Loss: 0.38193342089653015
ASR: 7180/7193 = 0.998193


<Backdoor Training> Train Epoch: 27 	Loss: 0.231400, lr: 0.100000, Time: 5.97s
Clean ACC: 7027/8000 = 0.878375, Loss: 0.3874831795692444
ASR: 7181/7193 = 0.998332


<Backdoor Training> Train Epoch: 28 	Loss: 0.170368, lr: 0.100000, Time: 5.96s
Clean ACC: 6997/8000 = 0.874625, Loss: 0.4102703928947449
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 29 	Loss: 0.188689, lr: 0.100000, Time: 5.96s
Clean ACC: 7072/8000 = 0.884000, Loss: 0.3722091317176819
ASR: 7091/7193 = 0.985820


<Backdoor Training> Train Epoch: 30 	Loss: 0.245483, lr: 0.100000, Time: 5.94s
Clean ACC: 6980/8000 = 0.872500, Loss: 0.4240906238555908
ASR: 7030/7193 = 0.977339


<Backdoor Training> Train Epoch: 31 	Loss: 0.200180, lr: 0.100000, Time: 5.94s
Clean ACC: 7045/8000 = 0.880625, Loss: 0.3981136977672577
ASR: 7178/7193 = 0.997915


<Backdoor Training> Train Epoch: 32 	Loss: 0.151858, lr: 0.100000, Time: 5.96s
Clean ACC: 7131/8000 = 0.891375, Loss: 0.3382214903831482
ASR: 7175/7193 = 0.997498


<Backdoor Training> Train Epoch: 33 	Loss: 0.211125, lr: 0.100000, Time: 5.95s
Clean ACC: 7102/8000 = 0.887750, Loss: 0.3722134828567505
ASR: 7144/7193 = 0.993188


<Backdoor Training> Train Epoch: 34 	Loss: 0.123451, lr: 0.100000, Time: 6.00s
Clean ACC: 7114/8000 = 0.889250, Loss: 0.35593268275260925
ASR: 7162/7193 = 0.995690


<Backdoor Training> Train Epoch: 35 	Loss: 0.365473, lr: 0.100000, Time: 5.97s
Clean ACC: 7046/8000 = 0.880750, Loss: 0.3923366963863373
ASR: 7185/7193 = 0.998888


<Backdoor Training> Train Epoch: 36 	Loss: 0.266452, lr: 0.100000, Time: 5.95s
Clean ACC: 7179/8000 = 0.897375, Loss: 0.32731905579566956
ASR: 7066/7193 = 0.982344


<Backdoor Training> Train Epoch: 37 	Loss: 0.110852, lr: 0.100000, Time: 6.00s
Clean ACC: 7150/8000 = 0.893750, Loss: 0.3587956726551056
ASR: 6759/7193 = 0.939664


<Backdoor Training> Train Epoch: 38 	Loss: 0.036889, lr: 0.100000, Time: 5.94s
Clean ACC: 7198/8000 = 0.899750, Loss: 0.33860915899276733
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 39 	Loss: 0.182821, lr: 0.100000, Time: 5.94s
Clean ACC: 7015/8000 = 0.876875, Loss: 0.4316810369491577
ASR: 7175/7193 = 0.997498


<Backdoor Training> Train Epoch: 40 	Loss: 0.158028, lr: 0.100000, Time: 5.97s
Clean ACC: 7209/8000 = 0.901125, Loss: 0.34400075674057007
ASR: 7153/7193 = 0.994439


<Backdoor Training> Train Epoch: 41 	Loss: 0.195917, lr: 0.100000, Time: 5.94s
Clean ACC: 7141/8000 = 0.892625, Loss: 0.3572331964969635
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 42 	Loss: 0.249762, lr: 0.100000, Time: 5.96s
Clean ACC: 7069/8000 = 0.883625, Loss: 0.37675154209136963
ASR: 7178/7193 = 0.997915


<Backdoor Training> Train Epoch: 43 	Loss: 0.259357, lr: 0.100000, Time: 6.00s
Clean ACC: 7052/8000 = 0.881500, Loss: 0.39101147651672363
ASR: 7172/7193 = 0.997080


<Backdoor Training> Train Epoch: 44 	Loss: 0.179848, lr: 0.100000, Time: 5.94s
Clean ACC: 7209/8000 = 0.901125, Loss: 0.33345827460289
ASR: 7169/7193 = 0.996663


<Backdoor Training> Train Epoch: 45 	Loss: 0.147005, lr: 0.100000, Time: 5.95s
Clean ACC: 7161/8000 = 0.895125, Loss: 0.3552876114845276
ASR: 7156/7193 = 0.994856


<Backdoor Training> Train Epoch: 46 	Loss: 0.146801, lr: 0.100000, Time: 5.94s
Clean ACC: 7079/8000 = 0.884875, Loss: 0.41503387689590454
ASR: 7147/7193 = 0.993605


<Backdoor Training> Train Epoch: 47 	Loss: 0.134741, lr: 0.100000, Time: 5.96s
Clean ACC: 7080/8000 = 0.885000, Loss: 0.4093354046344757
ASR: 7161/7193 = 0.995551


<Backdoor Training> Train Epoch: 48 	Loss: 0.142895, lr: 0.100000, Time: 5.95s
Clean ACC: 7217/8000 = 0.902125, Loss: 0.3370247185230255
ASR: 6991/7193 = 0.971917


<Backdoor Training> Train Epoch: 49 	Loss: 0.171615, lr: 0.100000, Time: 5.95s
Clean ACC: 7198/8000 = 0.899750, Loss: 0.34754782915115356
ASR: 7182/7193 = 0.998471


<Backdoor Training> Train Epoch: 50 	Loss: 0.214270, lr: 0.100000, Time: 5.95s
Clean ACC: 7263/8000 = 0.907875, Loss: 0.3121386766433716
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 51 	Loss: 0.061213, lr: 0.010000, Time: 5.94s
Clean ACC: 7478/8000 = 0.934750, Loss: 0.2230084091424942
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 52 	Loss: 0.013637, lr: 0.010000, Time: 5.96s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.22416554391384125
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 53 	Loss: 0.037396, lr: 0.010000, Time: 5.96s
Clean ACC: 7515/8000 = 0.939375, Loss: 0.22346460819244385
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 54 	Loss: 0.013872, lr: 0.010000, Time: 5.94s
Clean ACC: 7491/8000 = 0.936375, Loss: 0.23210924863815308
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 55 	Loss: 0.057320, lr: 0.010000, Time: 5.96s
Clean ACC: 7527/8000 = 0.940875, Loss: 0.23013973236083984
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 56 	Loss: 0.025110, lr: 0.010000, Time: 5.96s
Clean ACC: 7520/8000 = 0.940000, Loss: 0.2320484071969986
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 57 	Loss: 0.011544, lr: 0.010000, Time: 5.96s
Clean ACC: 7520/8000 = 0.940000, Loss: 0.23389071226119995
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 58 	Loss: 0.002446, lr: 0.010000, Time: 5.95s
Clean ACC: 7525/8000 = 0.940625, Loss: 0.2340998649597168
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 59 	Loss: 0.027017, lr: 0.010000, Time: 5.94s
Clean ACC: 7519/8000 = 0.939875, Loss: 0.23938825726509094
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 60 	Loss: 0.007877, lr: 0.010000, Time: 5.95s
Clean ACC: 7516/8000 = 0.939500, Loss: 0.24294336140155792
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 61 	Loss: 0.009884, lr: 0.010000, Time: 5.96s
Clean ACC: 7523/8000 = 0.940375, Loss: 0.2447732388973236
ASR: 7185/7193 = 0.998888


<Backdoor Training> Train Epoch: 62 	Loss: 0.002062, lr: 0.010000, Time: 6.03s
Clean ACC: 7508/8000 = 0.938500, Loss: 0.24929432570934296
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 63 	Loss: 0.001168, lr: 0.010000, Time: 6.03s
Clean ACC: 7512/8000 = 0.939000, Loss: 0.24976235628128052
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 64 	Loss: 0.004149, lr: 0.010000, Time: 5.95s
Clean ACC: 7514/8000 = 0.939250, Loss: 0.24889758229255676
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 65 	Loss: 0.006681, lr: 0.010000, Time: 5.95s
Clean ACC: 7522/8000 = 0.940250, Loss: 0.2512020170688629
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 66 	Loss: 0.000892, lr: 0.010000, Time: 5.98s
Clean ACC: 7501/8000 = 0.937625, Loss: 0.2542183995246887
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 67 	Loss: 0.006395, lr: 0.010000, Time: 5.97s
Clean ACC: 7533/8000 = 0.941625, Loss: 0.2505565285682678
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 68 	Loss: 0.027291, lr: 0.010000, Time: 5.96s
Clean ACC: 7522/8000 = 0.940250, Loss: 0.2551345229148865
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 69 	Loss: 0.004942, lr: 0.010000, Time: 5.98s
Clean ACC: 7511/8000 = 0.938875, Loss: 0.2566526234149933
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 70 	Loss: 0.008155, lr: 0.010000, Time: 5.96s
Clean ACC: 7527/8000 = 0.940875, Loss: 0.2568829655647278
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 71 	Loss: 0.004374, lr: 0.010000, Time: 5.96s
Clean ACC: 7517/8000 = 0.939625, Loss: 0.25763699412345886
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 72 	Loss: 0.002521, lr: 0.010000, Time: 5.95s
Clean ACC: 7518/8000 = 0.939750, Loss: 0.25788387656211853
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 73 	Loss: 0.005415, lr: 0.010000, Time: 5.95s
Clean ACC: 7517/8000 = 0.939625, Loss: 0.25739866495132446
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 74 	Loss: 0.009094, lr: 0.010000, Time: 5.95s
Clean ACC: 7537/8000 = 0.942125, Loss: 0.2600155174732208
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 75 	Loss: 0.004537, lr: 0.010000, Time: 5.94s
Clean ACC: 7515/8000 = 0.939375, Loss: 0.2624465823173523
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 76 	Loss: 0.005296, lr: 0.001000, Time: 5.94s
Clean ACC: 7518/8000 = 0.939750, Loss: 0.26102933287620544
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 77 	Loss: 0.009305, lr: 0.001000, Time: 5.94s
Clean ACC: 7516/8000 = 0.939500, Loss: 0.25886672735214233
ASR: 7185/7193 = 0.998888


<Backdoor Training> Train Epoch: 78 	Loss: 0.004055, lr: 0.001000, Time: 6.02s
Clean ACC: 7515/8000 = 0.939375, Loss: 0.259634792804718
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 79 	Loss: 0.011523, lr: 0.001000, Time: 5.94s
Clean ACC: 7528/8000 = 0.941000, Loss: 0.2609630227088928
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 80 	Loss: 0.001167, lr: 0.001000, Time: 5.96s
Clean ACC: 7521/8000 = 0.940125, Loss: 0.2573360800743103
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 81 	Loss: 0.003637, lr: 0.001000, Time: 5.94s
Clean ACC: 7513/8000 = 0.939125, Loss: 0.26010194420814514
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 82 	Loss: 0.001359, lr: 0.001000, Time: 5.95s
Clean ACC: 7514/8000 = 0.939250, Loss: 0.26122555136680603
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 83 	Loss: 0.001183, lr: 0.001000, Time: 5.96s
Clean ACC: 7526/8000 = 0.940750, Loss: 0.25846585631370544
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 84 	Loss: 0.004876, lr: 0.001000, Time: 5.93s
Clean ACC: 7527/8000 = 0.940875, Loss: 0.26080718636512756
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 85 	Loss: 0.007323, lr: 0.001000, Time: 5.95s
Clean ACC: 7533/8000 = 0.941625, Loss: 0.25792068243026733
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 86 	Loss: 0.001499, lr: 0.001000, Time: 5.95s
Clean ACC: 7537/8000 = 0.942125, Loss: 0.2581583261489868
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 87 	Loss: 0.002948, lr: 0.001000, Time: 5.95s
Clean ACC: 7517/8000 = 0.939625, Loss: 0.25831711292266846
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 88 	Loss: 0.000826, lr: 0.001000, Time: 5.95s
Clean ACC: 7537/8000 = 0.942125, Loss: 0.2565230131149292
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 89 	Loss: 0.003957, lr: 0.001000, Time: 5.96s
Clean ACC: 7532/8000 = 0.941500, Loss: 0.2554638981819153
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 90 	Loss: 0.006920, lr: 0.001000, Time: 5.98s
Clean ACC: 7527/8000 = 0.940875, Loss: 0.25717872381210327
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 91 	Loss: 0.005237, lr: 0.001000, Time: 5.94s
Clean ACC: 7525/8000 = 0.940625, Loss: 0.2595382630825043
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 92 	Loss: 0.001204, lr: 0.001000, Time: 5.97s
Clean ACC: 7532/8000 = 0.941500, Loss: 0.25927281379699707
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 93 	Loss: 0.006586, lr: 0.001000, Time: 5.95s
Clean ACC: 7531/8000 = 0.941375, Loss: 0.2590906620025635
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 94 	Loss: 0.004104, lr: 0.001000, Time: 5.97s
Clean ACC: 7532/8000 = 0.941500, Loss: 0.25796735286712646
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 95 	Loss: 0.002327, lr: 0.001000, Time: 5.94s
Clean ACC: 7532/8000 = 0.941500, Loss: 0.2590254843235016
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 96 	Loss: 0.000844, lr: 0.001000, Time: 5.94s
Clean ACC: 7528/8000 = 0.941000, Loss: 0.2574620246887207
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 97 	Loss: 0.007087, lr: 0.001000, Time: 5.95s
Clean ACC: 7529/8000 = 0.941125, Loss: 0.25935983657836914
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 98 	Loss: 0.000136, lr: 0.001000, Time: 5.96s
Clean ACC: 7530/8000 = 0.941250, Loss: 0.2572304606437683
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 99 	Loss: 0.001268, lr: 0.001000, Time: 5.97s
Clean ACC: 7531/8000 = 0.941375, Loss: 0.2575409710407257
ASR: 7187/7193 = 0.999166


<Backdoor Training> Train Epoch: 100 	Loss: 0.006542, lr: 0.001000, Time: 5.94s
Clean ACC: 7531/8000 = 0.941375, Loss: 0.25860071182250977
ASR: 7188/7193 = 0.999305


Testing the backdoor model...
Evaluating model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 7531/8000 = 0.941375, Loss: 0.25860071182250977
ASR: 7188/7193 = 0.999305

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7531/8000 = 0.941375, Loss: 0.2586136758327484
ASR: 7188/7193 = 0.999305

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.252348, poison_dis: 7.783795
Silhouette Score: 0.46268094
Saved figure at assets/pca_cifar10_adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7531/8000 = 0.941375, Loss: 0.2586136758327484
ASR: 7188/7193 = 0.999305

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.252348, poison_dis: 7.783795
Silhouette Score: 0.46268094
Saved figure at assets/tsne_cifar10_adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7531/8000 = 0.941375, Loss: 0.2586136758327484
ASR: 7188/7193 = 0.999305

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.252348, poison_dis: 7.783795
Silhouette Score: 0.46268094
SVM Accuracy: 1.0
Saved figure at assets/oracle_cifar10_adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/hellokitty_32.png
trigger_mask_path: ./triggers/mask_hellokitty_32.png
Evaluating model 'poisoned_train_set/cifar10/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 94.13750457763672
asr: 99.93048858642578
target label: tensor([0], device='cuda:0')
start_index: 9
TPR: 95.56
FPR: 2.35
AUC: 0.9959
f1 score: 0.9657045411482347
Elapsed time: 18.42s
Experiment for cifar10 with adaptive_blend completed.
