Creating poisoned training set for SIG on GTSRB...
[target class : 2]
Poisoned set directory 'poisoned_train_set/gtsrb/SIG_0.010_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/gtsrb/SIG_0.010_poison_seed=0/imgs
Will save to 'poisoned_train_set/gtsrb/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt'.
<Backdoor Training> Train Epoch: 1 	Loss: 0.067044, lr: 0.010000, Time: 7.55s
Clean ACC: 9720/10630 = 0.914393, Loss: 0.3027447462081909
ASR: 3833/10005 = 0.383108


<Backdoor Training> Train Epoch: 2 	Loss: 0.030304, lr: 0.010000, Time: 3.48s
Clean ACC: 10021/10630 = 0.942709, Loss: 0.18807941675186157
ASR: 4619/10005 = 0.461669


<Backdoor Training> Train Epoch: 3 	Loss: 0.005815, lr: 0.010000, Time: 3.51s
Clean ACC: 10025/10630 = 0.943086, Loss: 0.20659394562244415
ASR: 5471/10005 = 0.546827


<Backdoor Training> Train Epoch: 4 	Loss: 0.112719, lr: 0.010000, Time: 3.51s
Clean ACC: 10124/10630 = 0.952399, Loss: 0.16659055650234222
ASR: 4638/10005 = 0.463568


<Backdoor Training> Train Epoch: 5 	Loss: 0.001831, lr: 0.010000, Time: 3.42s
Clean ACC: 10223/10630 = 0.961712, Loss: 0.14014042913913727
ASR: 5279/10005 = 0.527636


<Backdoor Training> Train Epoch: 6 	Loss: 0.088052, lr: 0.010000, Time: 3.40s
Clean ACC: 10206/10630 = 0.960113, Loss: 0.14415386319160461
ASR: 5280/10005 = 0.527736


<Backdoor Training> Train Epoch: 7 	Loss: 0.009783, lr: 0.010000, Time: 3.45s
Clean ACC: 10218/10630 = 0.961242, Loss: 0.1275007277727127
ASR: 4623/10005 = 0.462069


<Backdoor Training> Train Epoch: 8 	Loss: 0.005566, lr: 0.010000, Time: 3.52s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.11904928833246231
ASR: 4922/10005 = 0.491954


<Backdoor Training> Train Epoch: 9 	Loss: 0.013893, lr: 0.010000, Time: 3.47s
Clean ACC: 10233/10630 = 0.962653, Loss: 0.11979173868894577
ASR: 4745/10005 = 0.474263


<Backdoor Training> Train Epoch: 10 	Loss: 0.002881, lr: 0.010000, Time: 3.54s
Clean ACC: 10268/10630 = 0.965945, Loss: 0.11336862295866013
ASR: 5183/10005 = 0.518041


<Backdoor Training> Train Epoch: 11 	Loss: 0.000474, lr: 0.010000, Time: 3.58s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.10761454701423645
ASR: 5155/10005 = 0.515242


<Backdoor Training> Train Epoch: 12 	Loss: 0.003348, lr: 0.010000, Time: 3.63s
Clean ACC: 10308/10630 = 0.969708, Loss: 0.1042252704501152
ASR: 5120/10005 = 0.511744


<Backdoor Training> Train Epoch: 13 	Loss: 0.001793, lr: 0.010000, Time: 3.54s
Clean ACC: 10301/10630 = 0.969050, Loss: 0.10654382407665253
ASR: 4915/10005 = 0.491254


<Backdoor Training> Train Epoch: 14 	Loss: 0.002085, lr: 0.010000, Time: 3.57s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.10885770618915558
ASR: 4644/10005 = 0.464168


<Backdoor Training> Train Epoch: 15 	Loss: 0.015784, lr: 0.010000, Time: 3.51s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.10619310289621353
ASR: 4886/10005 = 0.488356


<Backdoor Training> Train Epoch: 16 	Loss: 0.001440, lr: 0.010000, Time: 3.42s
Clean ACC: 10312/10630 = 0.970085, Loss: 0.10283230245113373
ASR: 4862/10005 = 0.485957


<Backdoor Training> Train Epoch: 17 	Loss: 0.001365, lr: 0.010000, Time: 3.52s
Clean ACC: 10318/10630 = 0.970649, Loss: 0.09708638489246368
ASR: 5017/10005 = 0.501449


<Backdoor Training> Train Epoch: 18 	Loss: 0.001063, lr: 0.010000, Time: 3.59s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.09137121587991714
ASR: 4861/10005 = 0.485857


<Backdoor Training> Train Epoch: 19 	Loss: 0.001408, lr: 0.010000, Time: 3.52s
Clean ACC: 10351/10630 = 0.973754, Loss: 0.09082957357168198
ASR: 4916/10005 = 0.491354


<Backdoor Training> Train Epoch: 20 	Loss: 0.006381, lr: 0.010000, Time: 3.61s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09214901924133301
ASR: 5227/10005 = 0.522439


<Backdoor Training> Train Epoch: 21 	Loss: 0.007659, lr: 0.010000, Time: 3.63s
Clean ACC: 10169/10630 = 0.956632, Loss: 0.15467971563339233
ASR: 4819/10005 = 0.481659


<Backdoor Training> Train Epoch: 22 	Loss: 0.001105, lr: 0.010000, Time: 3.54s
Clean ACC: 10240/10630 = 0.963311, Loss: 0.11938715726137161
ASR: 5024/10005 = 0.502149


<Backdoor Training> Train Epoch: 23 	Loss: 0.000461, lr: 0.010000, Time: 3.41s
Clean ACC: 10317/10630 = 0.970555, Loss: 0.10245978087186813
ASR: 5109/10005 = 0.510645


<Backdoor Training> Train Epoch: 24 	Loss: 0.004580, lr: 0.010000, Time: 3.49s
Clean ACC: 10325/10630 = 0.971308, Loss: 0.09570299834012985
ASR: 5111/10005 = 0.510845


<Backdoor Training> Train Epoch: 25 	Loss: 0.065673, lr: 0.010000, Time: 3.59s
Clean ACC: 10294/10630 = 0.968391, Loss: 0.1045377105474472
ASR: 5251/10005 = 0.524838


<Backdoor Training> Train Epoch: 26 	Loss: 0.019148, lr: 0.010000, Time: 3.53s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.1200302243232727
ASR: 4752/10005 = 0.474963


<Backdoor Training> Train Epoch: 27 	Loss: 0.004694, lr: 0.010000, Time: 3.51s
Clean ACC: 10327/10630 = 0.971496, Loss: 0.09480240195989609
ASR: 5243/10005 = 0.524038


<Backdoor Training> Train Epoch: 28 	Loss: 0.030950, lr: 0.010000, Time: 3.57s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.11667139828205109
ASR: 5417/10005 = 0.541429


<Backdoor Training> Train Epoch: 29 	Loss: 0.002605, lr: 0.010000, Time: 3.52s
Clean ACC: 10336/10630 = 0.972342, Loss: 0.09671436250209808
ASR: 5015/10005 = 0.501249


<Backdoor Training> Train Epoch: 30 	Loss: 0.000556, lr: 0.010000, Time: 3.42s
Clean ACC: 10344/10630 = 0.973095, Loss: 0.09255711734294891
ASR: 5002/10005 = 0.499950


<Backdoor Training> Train Epoch: 31 	Loss: 0.001762, lr: 0.001000, Time: 3.59s
Clean ACC: 10338/10630 = 0.972531, Loss: 0.09312364459037781
ASR: 4899/10005 = 0.489655


<Backdoor Training> Train Epoch: 32 	Loss: 0.005190, lr: 0.001000, Time: 3.52s
Clean ACC: 10346/10630 = 0.973283, Loss: 0.0883464440703392
ASR: 4989/10005 = 0.498651


<Backdoor Training> Train Epoch: 33 	Loss: 0.000754, lr: 0.001000, Time: 3.60s
Clean ACC: 10341/10630 = 0.972813, Loss: 0.09024415910243988
ASR: 4969/10005 = 0.496652


<Backdoor Training> Train Epoch: 34 	Loss: 0.001483, lr: 0.001000, Time: 3.58s
Clean ACC: 10348/10630 = 0.973471, Loss: 0.08939407020807266
ASR: 4903/10005 = 0.490055


<Backdoor Training> Train Epoch: 35 	Loss: 0.000494, lr: 0.001000, Time: 3.58s
Clean ACC: 10348/10630 = 0.973471, Loss: 0.08877283334732056
ASR: 4956/10005 = 0.495352


<Backdoor Training> Train Epoch: 36 	Loss: 0.002398, lr: 0.001000, Time: 3.60s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.08968137204647064
ASR: 4979/10005 = 0.497651


<Backdoor Training> Train Epoch: 37 	Loss: 0.002633, lr: 0.001000, Time: 3.62s
Clean ACC: 10348/10630 = 0.973471, Loss: 0.0892031118273735
ASR: 4986/10005 = 0.498351


<Backdoor Training> Train Epoch: 38 	Loss: 0.000456, lr: 0.001000, Time: 3.55s
Clean ACC: 10355/10630 = 0.974130, Loss: 0.08666969835758209
ASR: 4826/10005 = 0.482359


<Backdoor Training> Train Epoch: 39 	Loss: 0.000176, lr: 0.001000, Time: 3.53s
Clean ACC: 10352/10630 = 0.973848, Loss: 0.08787871897220612
ASR: 4896/10005 = 0.489355


<Backdoor Training> Train Epoch: 40 	Loss: 0.000738, lr: 0.001000, Time: 3.55s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.089691162109375
ASR: 4906/10005 = 0.490355


<Backdoor Training> Train Epoch: 41 	Loss: 0.000303, lr: 0.001000, Time: 3.54s
Clean ACC: 10351/10630 = 0.973754, Loss: 0.08981427550315857
ASR: 4840/10005 = 0.483758


<Backdoor Training> Train Epoch: 42 	Loss: 0.000366, lr: 0.001000, Time: 3.53s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.0879746675491333
ASR: 4897/10005 = 0.489455


<Backdoor Training> Train Epoch: 43 	Loss: 0.002137, lr: 0.001000, Time: 3.56s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.08871787786483765
ASR: 4984/10005 = 0.498151


<Backdoor Training> Train Epoch: 44 	Loss: 0.001680, lr: 0.001000, Time: 3.60s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.0865490734577179
ASR: 4965/10005 = 0.496252


<Backdoor Training> Train Epoch: 45 	Loss: 0.000131, lr: 0.001000, Time: 3.47s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.08862074464559555
ASR: 4835/10005 = 0.483258


<Backdoor Training> Train Epoch: 46 	Loss: 0.000747, lr: 0.001000, Time: 3.55s
Clean ACC: 10357/10630 = 0.974318, Loss: 0.08722610771656036
ASR: 4805/10005 = 0.480260


<Backdoor Training> Train Epoch: 47 	Loss: 0.000400, lr: 0.001000, Time: 3.54s
Clean ACC: 10352/10630 = 0.973848, Loss: 0.08790504187345505
ASR: 4874/10005 = 0.487156


<Backdoor Training> Train Epoch: 48 	Loss: 0.000198, lr: 0.001000, Time: 3.55s
Clean ACC: 10352/10630 = 0.973848, Loss: 0.08860715478658676
ASR: 4892/10005 = 0.488956


<Backdoor Training> Train Epoch: 49 	Loss: 0.008154, lr: 0.001000, Time: 3.40s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.08660926669836044
ASR: 4952/10005 = 0.494953


<Backdoor Training> Train Epoch: 50 	Loss: 0.001330, lr: 0.001000, Time: 3.56s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.08968663215637207
ASR: 4801/10005 = 0.479860


<Backdoor Training> Train Epoch: 51 	Loss: 0.001036, lr: 0.001000, Time: 3.59s
Clean ACC: 10349/10630 = 0.973565, Loss: 0.08721689134836197
ASR: 4920/10005 = 0.491754


<Backdoor Training> Train Epoch: 52 	Loss: 0.000433, lr: 0.001000, Time: 3.54s
Clean ACC: 10349/10630 = 0.973565, Loss: 0.08875345438718796
ASR: 5003/10005 = 0.500050


<Backdoor Training> Train Epoch: 53 	Loss: 0.005233, lr: 0.001000, Time: 3.57s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.08840003609657288
ASR: 5010/10005 = 0.500750


<Backdoor Training> Train Epoch: 54 	Loss: 0.011497, lr: 0.001000, Time: 3.56s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.08632596582174301
ASR: 4863/10005 = 0.486057


<Backdoor Training> Train Epoch: 55 	Loss: 0.006572, lr: 0.001000, Time: 3.53s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09400027990341187
ASR: 5015/10005 = 0.501249


<Backdoor Training> Train Epoch: 56 	Loss: 0.000925, lr: 0.001000, Time: 3.55s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.08953703939914703
ASR: 4996/10005 = 0.499350


<Backdoor Training> Train Epoch: 57 	Loss: 0.001385, lr: 0.001000, Time: 3.60s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.08966317772865295
ASR: 4892/10005 = 0.488956


<Backdoor Training> Train Epoch: 58 	Loss: 0.000724, lr: 0.001000, Time: 3.52s
Clean ACC: 10348/10630 = 0.973471, Loss: 0.08721557259559631
ASR: 4926/10005 = 0.492354


<Backdoor Training> Train Epoch: 59 	Loss: 0.001017, lr: 0.001000, Time: 3.53s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.08701057732105255
ASR: 5016/10005 = 0.501349


<Backdoor Training> Train Epoch: 60 	Loss: 0.003426, lr: 0.001000, Time: 3.53s
Clean ACC: 10357/10630 = 0.974318, Loss: 0.08726567775011063
ASR: 4922/10005 = 0.491954


<Backdoor Training> Train Epoch: 61 	Loss: 0.000258, lr: 0.000100, Time: 3.51s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.08568049967288971
ASR: 4933/10005 = 0.493053


<Backdoor Training> Train Epoch: 62 	Loss: 0.000234, lr: 0.000100, Time: 3.52s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.08641006052494049
ASR: 4894/10005 = 0.489155


<Backdoor Training> Train Epoch: 63 	Loss: 0.001259, lr: 0.000100, Time: 3.51s
Clean ACC: 10351/10630 = 0.973754, Loss: 0.08871002495288849
ASR: 4927/10005 = 0.492454


<Backdoor Training> Train Epoch: 64 	Loss: 0.000780, lr: 0.000100, Time: 3.46s
Clean ACC: 10356/10630 = 0.974224, Loss: 0.08705998957157135
ASR: 4966/10005 = 0.496352


<Backdoor Training> Train Epoch: 65 	Loss: 0.000835, lr: 0.000100, Time: 3.57s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.08706985414028168
ASR: 4886/10005 = 0.488356


<Backdoor Training> Train Epoch: 66 	Loss: 0.000120, lr: 0.000100, Time: 3.60s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.08690034598112106
ASR: 5007/10005 = 0.500450


<Backdoor Training> Train Epoch: 67 	Loss: 0.000506, lr: 0.000100, Time: 3.55s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.08769389986991882
ASR: 4981/10005 = 0.497851


<Backdoor Training> Train Epoch: 68 	Loss: 0.000191, lr: 0.000100, Time: 3.57s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.08692507445812225
ASR: 4958/10005 = 0.495552


<Backdoor Training> Train Epoch: 69 	Loss: 0.000405, lr: 0.000100, Time: 3.50s
Clean ACC: 10357/10630 = 0.974318, Loss: 0.08681604266166687
ASR: 4887/10005 = 0.488456


<Backdoor Training> Train Epoch: 70 	Loss: 0.002416, lr: 0.000100, Time: 3.54s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.0878181904554367
ASR: 4982/10005 = 0.497951


<Backdoor Training> Train Epoch: 71 	Loss: 0.000343, lr: 0.000100, Time: 3.55s
Clean ACC: 10355/10630 = 0.974130, Loss: 0.08798377960920334
ASR: 4893/10005 = 0.489055


<Backdoor Training> Train Epoch: 72 	Loss: 0.008209, lr: 0.000100, Time: 3.61s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.08623749017715454
ASR: 4960/10005 = 0.495752


<Backdoor Training> Train Epoch: 73 	Loss: 0.002458, lr: 0.000100, Time: 3.58s
Clean ACC: 10342/10630 = 0.972907, Loss: 0.08889753371477127
ASR: 4844/10005 = 0.484158


<Backdoor Training> Train Epoch: 74 	Loss: 0.000675, lr: 0.000100, Time: 3.55s
Clean ACC: 10357/10630 = 0.974318, Loss: 0.0860542580485344
ASR: 4909/10005 = 0.490655


<Backdoor Training> Train Epoch: 75 	Loss: 0.001761, lr: 0.000100, Time: 3.58s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.0871059000492096
ASR: 4967/10005 = 0.496452


<Backdoor Training> Train Epoch: 76 	Loss: 0.000236, lr: 0.000100, Time: 3.54s
Clean ACC: 10355/10630 = 0.974130, Loss: 0.08760662376880646
ASR: 4936/10005 = 0.493353


<Backdoor Training> Train Epoch: 77 	Loss: 0.000306, lr: 0.000100, Time: 3.57s
Clean ACC: 10356/10630 = 0.974224, Loss: 0.08835369348526001
ASR: 4920/10005 = 0.491754


<Backdoor Training> Train Epoch: 78 	Loss: 0.000448, lr: 0.000100, Time: 3.48s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.08584236353635788
ASR: 4975/10005 = 0.497251


<Backdoor Training> Train Epoch: 79 	Loss: 0.007648, lr: 0.000100, Time: 3.51s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.08573237806558609
ASR: 4957/10005 = 0.495452


<Backdoor Training> Train Epoch: 80 	Loss: 0.000290, lr: 0.000100, Time: 3.57s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.08707208186388016
ASR: 4989/10005 = 0.498651


<Backdoor Training> Train Epoch: 81 	Loss: 0.000420, lr: 0.000100, Time: 3.60s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.08585032820701599
ASR: 4928/10005 = 0.492554


<Backdoor Training> Train Epoch: 82 	Loss: 0.000858, lr: 0.000100, Time: 3.62s
Clean ACC: 10352/10630 = 0.973848, Loss: 0.08782900869846344
ASR: 4795/10005 = 0.479260


<Backdoor Training> Train Epoch: 83 	Loss: 0.004255, lr: 0.000100, Time: 3.57s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.08500378578901291
ASR: 4870/10005 = 0.486757


<Backdoor Training> Train Epoch: 84 	Loss: 0.000193, lr: 0.000100, Time: 3.61s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.08595766872167587
ASR: 4993/10005 = 0.499050


<Backdoor Training> Train Epoch: 85 	Loss: 0.008996, lr: 0.000100, Time: 3.51s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.085237056016922
ASR: 4808/10005 = 0.480560


<Backdoor Training> Train Epoch: 86 	Loss: 0.004629, lr: 0.000100, Time: 3.53s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.08753190189599991
ASR: 4899/10005 = 0.489655


<Backdoor Training> Train Epoch: 87 	Loss: 0.000152, lr: 0.000100, Time: 3.55s
Clean ACC: 10368/10630 = 0.975353, Loss: 0.08473216742277145
ASR: 4829/10005 = 0.482659


<Backdoor Training> Train Epoch: 88 	Loss: 0.000654, lr: 0.000100, Time: 3.48s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.0855494812130928
ASR: 4952/10005 = 0.494953


<Backdoor Training> Train Epoch: 89 	Loss: 0.000153, lr: 0.000100, Time: 3.60s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.08813915401697159
ASR: 5010/10005 = 0.500750


<Backdoor Training> Train Epoch: 90 	Loss: 0.000622, lr: 0.000100, Time: 3.59s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.08579229563474655
ASR: 4888/10005 = 0.488556


<Backdoor Training> Train Epoch: 91 	Loss: 0.000418, lr: 0.000100, Time: 3.65s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.08508580923080444
ASR: 4853/10005 = 0.485057


<Backdoor Training> Train Epoch: 92 	Loss: 0.002333, lr: 0.000100, Time: 3.56s
Clean ACC: 10356/10630 = 0.974224, Loss: 0.08691369742155075
ASR: 4975/10005 = 0.497251


<Backdoor Training> Train Epoch: 93 	Loss: 0.000247, lr: 0.000100, Time: 3.58s
Clean ACC: 10357/10630 = 0.974318, Loss: 0.08638490736484528
ASR: 4812/10005 = 0.480960


<Backdoor Training> Train Epoch: 94 	Loss: 0.000957, lr: 0.000100, Time: 3.53s
Clean ACC: 10369/10630 = 0.975447, Loss: 0.08571245521306992
ASR: 4988/10005 = 0.498551


<Backdoor Training> Train Epoch: 95 	Loss: 0.000464, lr: 0.000100, Time: 3.59s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.08743257075548172
ASR: 4972/10005 = 0.496952


<Backdoor Training> Train Epoch: 96 	Loss: 0.000587, lr: 0.000100, Time: 3.63s
Clean ACC: 10356/10630 = 0.974224, Loss: 0.08817288279533386
ASR: 4842/10005 = 0.483958


<Backdoor Training> Train Epoch: 97 	Loss: 0.007408, lr: 0.000100, Time: 3.48s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.08579417318105698
ASR: 4962/10005 = 0.495952


<Backdoor Training> Train Epoch: 98 	Loss: 0.000803, lr: 0.000100, Time: 3.52s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.08791519701480865
ASR: 4851/10005 = 0.484858


<Backdoor Training> Train Epoch: 99 	Loss: 0.000216, lr: 0.000100, Time: 3.60s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.08657807111740112
ASR: 4928/10005 = 0.492554


<Backdoor Training> Train Epoch: 100 	Loss: 0.001611, lr: 0.000100, Time: 3.52s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.08480259031057358
ASR: 4963/10005 = 0.496052


Testing the backdoor model...
Evaluating model 'poisoned_train_set/gtsrb/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 10361/10630 = 0.974694, Loss: 0.08480259031057358
ASR: 4963/10005 = 0.496052

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/gtsrb/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10361/10630 = 0.974694, Loss: 0.08479467034339905
ASR: 4963/10005 = 0.496052

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.387565, poison_dis: 9.381842
Silhouette Score: 0.18285728
Saved figure at assets/pca_gtsrb_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10361/10630 = 0.974694, Loss: 0.08479467034339905
ASR: 4963/10005 = 0.496052

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.387565, poison_dis: 9.381842
Silhouette Score: 0.18285728
Saved figure at assets/tsne_gtsrb_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10361/10630 = 0.974694, Loss: 0.08479467034339905
ASR: 4963/10005 = 0.496052

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.387565, poison_dis: 9.381842
Silhouette Score: 0.18285728
SVM Accuracy: 1.0
Saved figure at assets/oracle_gtsrb_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/none
No trigger mask found! By default masking all black pixels...
Evaluating model 'poisoned_train_set/gtsrb/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 97.46942901611328
asr: 52.63754653930664
target label: tensor([2], device='cuda:0')
start_index: 12
TPR: 5.66
FPR: 8.02
AUC: 0.4287
f1 score: 0.09963588215822575
Elapsed time: 19.51s
Experiment for GTSRB with SIG completed.
