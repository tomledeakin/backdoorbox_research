Creating poisoned training set for adaptive_blend on GTSRB...
[target class : 2]
Poisoned set directory 'poisoned_train_set/gtsrb/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/gtsrb/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/imgs
Will save to 'poisoned_train_set/gtsrb/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'.
<Backdoor Training> Train Epoch: 1 	Loss: 0.153397, lr: 0.010000, Time: 7.91s
Clean ACC: 9199/10630 = 0.865381, Loss: 0.46353885531425476
ASR: 7583/10005 = 0.757921


<Backdoor Training> Train Epoch: 2 	Loss: 0.057908, lr: 0.010000, Time: 3.54s
Clean ACC: 9977/10630 = 0.938570, Loss: 0.21535564959049225
ASR: 8818/10005 = 0.881359


<Backdoor Training> Train Epoch: 3 	Loss: 0.021135, lr: 0.010000, Time: 3.51s
Clean ACC: 9791/10630 = 0.921072, Loss: 0.2999243438243866
ASR: 9721/10005 = 0.971614


<Backdoor Training> Train Epoch: 4 	Loss: 0.011849, lr: 0.010000, Time: 3.50s
Clean ACC: 10122/10630 = 0.952211, Loss: 0.17778517305850983
ASR: 9826/10005 = 0.982109


<Backdoor Training> Train Epoch: 5 	Loss: 0.022547, lr: 0.010000, Time: 3.64s
Clean ACC: 10105/10630 = 0.950611, Loss: 0.18545891344547272
ASR: 9924/10005 = 0.991904


<Backdoor Training> Train Epoch: 6 	Loss: 0.004832, lr: 0.010000, Time: 3.44s
Clean ACC: 10158/10630 = 0.955597, Loss: 0.1727537214756012
ASR: 9821/10005 = 0.981609


<Backdoor Training> Train Epoch: 7 	Loss: 0.021183, lr: 0.010000, Time: 3.62s
Clean ACC: 10118/10630 = 0.951834, Loss: 0.19268901646137238
ASR: 9982/10005 = 0.997701


<Backdoor Training> Train Epoch: 8 	Loss: 0.006609, lr: 0.010000, Time: 3.56s
Clean ACC: 10245/10630 = 0.963782, Loss: 0.14289921522140503
ASR: 9888/10005 = 0.988306


<Backdoor Training> Train Epoch: 9 	Loss: 0.013245, lr: 0.010000, Time: 3.60s
Clean ACC: 10248/10630 = 0.964064, Loss: 0.1313515603542328
ASR: 9978/10005 = 0.997301


<Backdoor Training> Train Epoch: 10 	Loss: 0.007448, lr: 0.010000, Time: 3.58s
Clean ACC: 10178/10630 = 0.957479, Loss: 0.16236208379268646
ASR: 9982/10005 = 0.997701


<Backdoor Training> Train Epoch: 11 	Loss: 0.000228, lr: 0.010000, Time: 3.61s
Clean ACC: 10264/10630 = 0.965569, Loss: 0.11930008977651596
ASR: 9936/10005 = 0.993103


<Backdoor Training> Train Epoch: 12 	Loss: 0.005054, lr: 0.010000, Time: 3.69s
Clean ACC: 10302/10630 = 0.969144, Loss: 0.11194313317537308
ASR: 9925/10005 = 0.992004


<Backdoor Training> Train Epoch: 13 	Loss: 0.052011, lr: 0.010000, Time: 3.62s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.11891626566648483
ASR: 9911/10005 = 0.990605


<Backdoor Training> Train Epoch: 14 	Loss: 0.040982, lr: 0.010000, Time: 3.61s
Clean ACC: 10249/10630 = 0.964158, Loss: 0.1431499868631363
ASR: 9975/10005 = 0.997001


<Backdoor Training> Train Epoch: 15 	Loss: 0.000626, lr: 0.010000, Time: 3.60s
Clean ACC: 10253/10630 = 0.964534, Loss: 0.12544721364974976
ASR: 9962/10005 = 0.995702


<Backdoor Training> Train Epoch: 16 	Loss: 0.137526, lr: 0.010000, Time: 3.50s
Clean ACC: 10080/10630 = 0.948260, Loss: 0.1865541785955429
ASR: 9837/10005 = 0.983208


<Backdoor Training> Train Epoch: 17 	Loss: 0.029535, lr: 0.010000, Time: 3.51s
Clean ACC: 10233/10630 = 0.962653, Loss: 0.13503898680210114
ASR: 9926/10005 = 0.992104


<Backdoor Training> Train Epoch: 18 	Loss: 0.000459, lr: 0.010000, Time: 3.52s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.12252716720104218
ASR: 9917/10005 = 0.991204


<Backdoor Training> Train Epoch: 19 	Loss: 0.012672, lr: 0.010000, Time: 3.62s
Clean ACC: 10312/10630 = 0.970085, Loss: 0.11735754460096359
ASR: 9908/10005 = 0.990305


<Backdoor Training> Train Epoch: 20 	Loss: 0.003036, lr: 0.010000, Time: 3.59s
Clean ACC: 10321/10630 = 0.970931, Loss: 0.10056263953447342
ASR: 9961/10005 = 0.995602


<Backdoor Training> Train Epoch: 21 	Loss: 0.000269, lr: 0.010000, Time: 3.58s
Clean ACC: 10300/10630 = 0.968956, Loss: 0.11708684265613556
ASR: 9936/10005 = 0.993103


<Backdoor Training> Train Epoch: 22 	Loss: 0.001860, lr: 0.010000, Time: 3.63s
Clean ACC: 10344/10630 = 0.973095, Loss: 0.10021509230136871
ASR: 9947/10005 = 0.994203


<Backdoor Training> Train Epoch: 23 	Loss: 0.007764, lr: 0.010000, Time: 3.57s
Clean ACC: 10306/10630 = 0.969520, Loss: 0.11296719312667847
ASR: 9937/10005 = 0.993203


<Backdoor Training> Train Epoch: 24 	Loss: 0.000331, lr: 0.010000, Time: 3.51s
Clean ACC: 10307/10630 = 0.969614, Loss: 0.10433885455131531
ASR: 9959/10005 = 0.995402


<Backdoor Training> Train Epoch: 25 	Loss: 0.000456, lr: 0.010000, Time: 3.54s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.0961579978466034
ASR: 9926/10005 = 0.992104


<Backdoor Training> Train Epoch: 26 	Loss: 0.001151, lr: 0.010000, Time: 3.57s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.09092941880226135
ASR: 9931/10005 = 0.992604


<Backdoor Training> Train Epoch: 27 	Loss: 0.001467, lr: 0.010000, Time: 3.59s
Clean ACC: 10326/10630 = 0.971402, Loss: 0.09883525967597961
ASR: 9946/10005 = 0.994103


<Backdoor Training> Train Epoch: 28 	Loss: 0.000473, lr: 0.010000, Time: 3.59s
Clean ACC: 10333/10630 = 0.972060, Loss: 0.09760931879281998
ASR: 9979/10005 = 0.997401


<Backdoor Training> Train Epoch: 29 	Loss: 0.001002, lr: 0.010000, Time: 3.64s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09475801885128021
ASR: 9958/10005 = 0.995302


<Backdoor Training> Train Epoch: 30 	Loss: 0.000345, lr: 0.010000, Time: 3.53s
Clean ACC: 10355/10630 = 0.974130, Loss: 0.0941949263215065
ASR: 9975/10005 = 0.997001


<Backdoor Training> Train Epoch: 31 	Loss: 0.000962, lr: 0.001000, Time: 3.59s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.09525317698717117
ASR: 9983/10005 = 0.997801


<Backdoor Training> Train Epoch: 32 	Loss: 0.014438, lr: 0.001000, Time: 3.62s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.09411069750785828
ASR: 9980/10005 = 0.997501


<Backdoor Training> Train Epoch: 33 	Loss: 0.001989, lr: 0.001000, Time: 3.55s
Clean ACC: 10336/10630 = 0.972342, Loss: 0.09898842871189117
ASR: 9977/10005 = 0.997201


<Backdoor Training> Train Epoch: 34 	Loss: 0.002563, lr: 0.001000, Time: 3.61s
Clean ACC: 10349/10630 = 0.973565, Loss: 0.09739962965250015
ASR: 9979/10005 = 0.997401


<Backdoor Training> Train Epoch: 35 	Loss: 0.001135, lr: 0.001000, Time: 3.61s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.0969899520277977
ASR: 9978/10005 = 0.997301


<Backdoor Training> Train Epoch: 36 	Loss: 0.002104, lr: 0.001000, Time: 3.52s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.09485757350921631
ASR: 9974/10005 = 0.996902


<Backdoor Training> Train Epoch: 37 	Loss: 0.003955, lr: 0.001000, Time: 3.54s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09495613723993301
ASR: 9977/10005 = 0.997201


<Backdoor Training> Train Epoch: 38 	Loss: 0.001844, lr: 0.001000, Time: 3.54s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.09631785750389099
ASR: 9982/10005 = 0.997701


<Backdoor Training> Train Epoch: 39 	Loss: 0.000962, lr: 0.001000, Time: 3.62s
Clean ACC: 10362/10630 = 0.974788, Loss: 0.09320058673620224
ASR: 9982/10005 = 0.997701


<Backdoor Training> Train Epoch: 40 	Loss: 0.000339, lr: 0.001000, Time: 3.54s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09400863200426102
ASR: 9984/10005 = 0.997901


<Backdoor Training> Train Epoch: 41 	Loss: 0.000566, lr: 0.001000, Time: 3.54s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.09544727951288223
ASR: 9982/10005 = 0.997701


<Backdoor Training> Train Epoch: 42 	Loss: 0.000836, lr: 0.001000, Time: 3.59s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.09347216039896011
ASR: 9984/10005 = 0.997901


<Backdoor Training> Train Epoch: 43 	Loss: 0.000789, lr: 0.001000, Time: 3.59s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.09447312355041504
ASR: 9977/10005 = 0.997201


<Backdoor Training> Train Epoch: 44 	Loss: 0.001425, lr: 0.001000, Time: 3.53s
Clean ACC: 10367/10630 = 0.975259, Loss: 0.09207958728075027
ASR: 9980/10005 = 0.997501


<Backdoor Training> Train Epoch: 45 	Loss: 0.000542, lr: 0.001000, Time: 3.53s
Clean ACC: 10362/10630 = 0.974788, Loss: 0.09219137579202652
ASR: 9981/10005 = 0.997601


<Backdoor Training> Train Epoch: 46 	Loss: 0.000467, lr: 0.001000, Time: 3.59s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09504106640815735
ASR: 9984/10005 = 0.997901


<Backdoor Training> Train Epoch: 47 	Loss: 0.000957, lr: 0.001000, Time: 3.66s
Clean ACC: 10351/10630 = 0.973754, Loss: 0.09501656889915466
ASR: 9974/10005 = 0.996902


<Backdoor Training> Train Epoch: 48 	Loss: 0.001000, lr: 0.001000, Time: 3.58s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.09441780298948288
ASR: 9970/10005 = 0.996502


<Backdoor Training> Train Epoch: 49 	Loss: 0.001645, lr: 0.001000, Time: 3.65s
Clean ACC: 10351/10630 = 0.973754, Loss: 0.09433240443468094
ASR: 9982/10005 = 0.997701


<Backdoor Training> Train Epoch: 50 	Loss: 0.000220, lr: 0.001000, Time: 3.64s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.09661270678043365
ASR: 9955/10005 = 0.995002


<Backdoor Training> Train Epoch: 51 	Loss: 0.000506, lr: 0.001000, Time: 3.59s
Clean ACC: 10356/10630 = 0.974224, Loss: 0.09150966256856918
ASR: 9962/10005 = 0.995702


<Backdoor Training> Train Epoch: 52 	Loss: 0.000305, lr: 0.001000, Time: 3.52s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.0913984477519989
ASR: 9962/10005 = 0.995702


<Backdoor Training> Train Epoch: 53 	Loss: 0.000727, lr: 0.001000, Time: 3.61s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.09251812100410461
ASR: 9980/10005 = 0.997501


<Backdoor Training> Train Epoch: 54 	Loss: 0.007404, lr: 0.001000, Time: 3.55s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09253425151109695
ASR: 9981/10005 = 0.997601


<Backdoor Training> Train Epoch: 55 	Loss: 0.000312, lr: 0.001000, Time: 3.59s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.09247314929962158
ASR: 9980/10005 = 0.997501


<Backdoor Training> Train Epoch: 56 	Loss: 0.000096, lr: 0.001000, Time: 3.55s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.09081603586673737
ASR: 9977/10005 = 0.997201


<Backdoor Training> Train Epoch: 57 	Loss: 0.000121, lr: 0.001000, Time: 3.59s
Clean ACC: 10373/10630 = 0.975823, Loss: 0.0912972092628479
ASR: 9973/10005 = 0.996802


<Backdoor Training> Train Epoch: 58 	Loss: 0.001242, lr: 0.001000, Time: 3.54s
Clean ACC: 10352/10630 = 0.973848, Loss: 0.09325077384710312
ASR: 9962/10005 = 0.995702


<Backdoor Training> Train Epoch: 59 	Loss: 0.000435, lr: 0.001000, Time: 3.61s
Clean ACC: 10362/10630 = 0.974788, Loss: 0.0937419980764389
ASR: 9981/10005 = 0.997601


<Backdoor Training> Train Epoch: 60 	Loss: 0.000689, lr: 0.001000, Time: 3.47s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.0907285064458847
ASR: 9963/10005 = 0.995802


<Backdoor Training> Train Epoch: 61 	Loss: 0.005236, lr: 0.000100, Time: 3.51s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09322093427181244
ASR: 9974/10005 = 0.996902


<Backdoor Training> Train Epoch: 62 	Loss: 0.000434, lr: 0.000100, Time: 3.59s
Clean ACC: 10365/10630 = 0.975071, Loss: 0.09318587183952332
ASR: 9974/10005 = 0.996902


<Backdoor Training> Train Epoch: 63 	Loss: 0.000105, lr: 0.000100, Time: 3.60s
Clean ACC: 10369/10630 = 0.975447, Loss: 0.09068995714187622
ASR: 9979/10005 = 0.997401


<Backdoor Training> Train Epoch: 64 	Loss: 0.000542, lr: 0.000100, Time: 3.55s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09164118021726608
ASR: 9969/10005 = 0.996402


<Backdoor Training> Train Epoch: 65 	Loss: 0.002342, lr: 0.000100, Time: 3.54s
Clean ACC: 10369/10630 = 0.975447, Loss: 0.09074137359857559
ASR: 9979/10005 = 0.997401


<Backdoor Training> Train Epoch: 66 	Loss: 0.001438, lr: 0.000100, Time: 3.55s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.09032133221626282
ASR: 9960/10005 = 0.995502


<Backdoor Training> Train Epoch: 67 	Loss: 0.002254, lr: 0.000100, Time: 3.58s
Clean ACC: 10368/10630 = 0.975353, Loss: 0.08906424045562744
ASR: 9971/10005 = 0.996602


<Backdoor Training> Train Epoch: 68 	Loss: 0.008431, lr: 0.000100, Time: 3.53s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.0915680006146431
ASR: 9961/10005 = 0.995602


<Backdoor Training> Train Epoch: 69 	Loss: 0.000869, lr: 0.000100, Time: 3.55s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.09399456530809402
ASR: 9981/10005 = 0.997601


<Backdoor Training> Train Epoch: 70 	Loss: 0.000247, lr: 0.000100, Time: 3.59s
Clean ACC: 10365/10630 = 0.975071, Loss: 0.09062694758176804
ASR: 9976/10005 = 0.997101


<Backdoor Training> Train Epoch: 71 	Loss: 0.000699, lr: 0.000100, Time: 3.55s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09118236601352692
ASR: 9975/10005 = 0.997001


<Backdoor Training> Train Epoch: 72 	Loss: 0.000496, lr: 0.000100, Time: 3.53s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.09245166927576065
ASR: 9969/10005 = 0.996402


<Backdoor Training> Train Epoch: 73 	Loss: 0.001308, lr: 0.000100, Time: 3.63s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.09209572523832321
ASR: 9956/10005 = 0.995102


<Backdoor Training> Train Epoch: 74 	Loss: 0.001750, lr: 0.000100, Time: 3.53s
Clean ACC: 10365/10630 = 0.975071, Loss: 0.0909799188375473
ASR: 9971/10005 = 0.996602


<Backdoor Training> Train Epoch: 75 	Loss: 0.000129, lr: 0.000100, Time: 3.53s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.09261498600244522
ASR: 9979/10005 = 0.997401


<Backdoor Training> Train Epoch: 76 	Loss: 0.001299, lr: 0.000100, Time: 3.63s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.09437203407287598
ASR: 9981/10005 = 0.997601


<Backdoor Training> Train Epoch: 77 	Loss: 0.000724, lr: 0.000100, Time: 3.67s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.0907180979847908
ASR: 9976/10005 = 0.997101


<Backdoor Training> Train Epoch: 78 	Loss: 0.000108, lr: 0.000100, Time: 3.56s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.09050343185663223
ASR: 9965/10005 = 0.996002


<Backdoor Training> Train Epoch: 79 	Loss: 0.001811, lr: 0.000100, Time: 3.63s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09387784451246262
ASR: 9975/10005 = 0.997001


<Backdoor Training> Train Epoch: 80 	Loss: 0.004899, lr: 0.000100, Time: 3.56s
Clean ACC: 10362/10630 = 0.974788, Loss: 0.09046322107315063
ASR: 9970/10005 = 0.996502


<Backdoor Training> Train Epoch: 81 	Loss: 0.000150, lr: 0.000100, Time: 3.66s
Clean ACC: 10367/10630 = 0.975259, Loss: 0.09222744405269623
ASR: 9970/10005 = 0.996502


<Backdoor Training> Train Epoch: 82 	Loss: 0.001176, lr: 0.000100, Time: 3.51s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.09256137162446976
ASR: 9971/10005 = 0.996602


<Backdoor Training> Train Epoch: 83 	Loss: 0.000292, lr: 0.000100, Time: 3.57s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09203197807073593
ASR: 9972/10005 = 0.996702


<Backdoor Training> Train Epoch: 84 	Loss: 0.000244, lr: 0.000100, Time: 3.61s
Clean ACC: 10365/10630 = 0.975071, Loss: 0.09105327725410461
ASR: 9954/10005 = 0.994903


<Backdoor Training> Train Epoch: 85 	Loss: 0.000691, lr: 0.000100, Time: 3.59s
Clean ACC: 10365/10630 = 0.975071, Loss: 0.09104261547327042
ASR: 9980/10005 = 0.997501


<Backdoor Training> Train Epoch: 86 	Loss: 0.000200, lr: 0.000100, Time: 3.61s
Clean ACC: 10368/10630 = 0.975353, Loss: 0.0910496637225151
ASR: 9977/10005 = 0.997201


<Backdoor Training> Train Epoch: 87 	Loss: 0.000262, lr: 0.000100, Time: 3.53s
Clean ACC: 10368/10630 = 0.975353, Loss: 0.09043139964342117
ASR: 9959/10005 = 0.995402


<Backdoor Training> Train Epoch: 88 	Loss: 0.000287, lr: 0.000100, Time: 3.56s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09333062916994095
ASR: 9965/10005 = 0.996002


<Backdoor Training> Train Epoch: 89 	Loss: 0.000172, lr: 0.000100, Time: 3.65s
Clean ACC: 10378/10630 = 0.976294, Loss: 0.08918482810258865
ASR: 9972/10005 = 0.996702


<Backdoor Training> Train Epoch: 90 	Loss: 0.001428, lr: 0.000100, Time: 3.62s
Clean ACC: 10362/10630 = 0.974788, Loss: 0.09317699074745178
ASR: 9979/10005 = 0.997401


<Backdoor Training> Train Epoch: 91 	Loss: 0.002374, lr: 0.000100, Time: 3.63s
Clean ACC: 10366/10630 = 0.975165, Loss: 0.09248945116996765
ASR: 9983/10005 = 0.997801


<Backdoor Training> Train Epoch: 92 	Loss: 0.000274, lr: 0.000100, Time: 3.55s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.09066979587078094
ASR: 9976/10005 = 0.997101


<Backdoor Training> Train Epoch: 93 	Loss: 0.000406, lr: 0.000100, Time: 3.67s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09211708605289459
ASR: 9978/10005 = 0.997301


<Backdoor Training> Train Epoch: 94 	Loss: 0.004622, lr: 0.000100, Time: 3.60s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.09238014370203018
ASR: 9975/10005 = 0.997001


<Backdoor Training> Train Epoch: 95 	Loss: 0.000613, lr: 0.000100, Time: 3.59s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.0916428342461586
ASR: 9973/10005 = 0.996802


<Backdoor Training> Train Epoch: 96 	Loss: 0.000285, lr: 0.000100, Time: 3.54s
Clean ACC: 10369/10630 = 0.975447, Loss: 0.08851919323205948
ASR: 9977/10005 = 0.997201


<Backdoor Training> Train Epoch: 97 	Loss: 0.000164, lr: 0.000100, Time: 3.65s
Clean ACC: 10367/10630 = 0.975259, Loss: 0.09112168103456497
ASR: 9974/10005 = 0.996902


<Backdoor Training> Train Epoch: 98 	Loss: 0.009901, lr: 0.000100, Time: 3.50s
Clean ACC: 10365/10630 = 0.975071, Loss: 0.09270016103982925
ASR: 9974/10005 = 0.996902


<Backdoor Training> Train Epoch: 99 	Loss: 0.000190, lr: 0.000100, Time: 3.56s
Clean ACC: 10356/10630 = 0.974224, Loss: 0.09144413471221924
ASR: 9974/10005 = 0.996902


<Backdoor Training> Train Epoch: 100 	Loss: 0.003574, lr: 0.000100, Time: 3.57s
Clean ACC: 10367/10630 = 0.975259, Loss: 0.08995503187179565
ASR: 9977/10005 = 0.997201


Testing the backdoor model...
Evaluating model 'poisoned_train_set/gtsrb/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 10367/10630 = 0.975259, Loss: 0.08995503187179565
ASR: 9977/10005 = 0.997201

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/gtsrb/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10367/10630 = 0.975259, Loss: 0.08995671570301056
ASR: 9977/10005 = 0.997201

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.204545, poison_dis: 12.963470
Silhouette Score: 0.3394888
Saved figure at assets/pca_gtsrb_adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10367/10630 = 0.975259, Loss: 0.08995671570301056
ASR: 9977/10005 = 0.997201

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.204545, poison_dis: 12.963470
Silhouette Score: 0.3394888
Saved figure at assets/tsne_gtsrb_adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10367/10630 = 0.975259, Loss: 0.08995671570301056
ASR: 9977/10005 = 0.997201

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.204545, poison_dis: 12.963470
Silhouette Score: 0.3394888
SVM Accuracy: 1.0
Saved figure at assets/oracle_gtsrb_adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/hellokitty_32.png
trigger_mask_path: ./triggers/mask_hellokitty_32.png
Evaluating model 'poisoned_train_set/gtsrb/adaptive_blend_0.010_alpha=0.200_cover=0.000_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 97.52587127685547
asr: 99.73529815673828
target label: tensor([2], device='cuda:0')
start_index: 12
TPR: 61.49
FPR: 15.72
AUC: 0.8246
f1 score: 0.6939533896055635
Elapsed time: 18.94s
Experiment for GTSRB with adaptive_blend completed.
