Creating poisoned training set for adaptive_patch on GTSRB...
[target class : 2]
Poisoned set directory 'poisoned_train_set/gtsrb/adaptive_patch_0.010_cover=0.000_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/gtsrb/adaptive_patch_0.010_cover=0.000_poison_seed=0/imgs
Will save to 'poisoned_train_set/gtsrb/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt'.
<Backdoor Training> Train Epoch: 1 	Loss: 0.161729, lr: 0.010000, Time: 4.01s
Clean ACC: 9154/10630 = 0.861148, Loss: 0.4682055711746216
ASR: 4215/10005 = 0.421289


<Backdoor Training> Train Epoch: 2 	Loss: 0.072387, lr: 0.010000, Time: 3.65s
Clean ACC: 9833/10630 = 0.925024, Loss: 0.2763981223106384
ASR: 7269/10005 = 0.726537


<Backdoor Training> Train Epoch: 3 	Loss: 0.327526, lr: 0.010000, Time: 3.48s
Clean ACC: 9708/10630 = 0.913264, Loss: 0.31330665946006775
ASR: 8929/10005 = 0.892454


<Backdoor Training> Train Epoch: 4 	Loss: 0.516769, lr: 0.010000, Time: 3.54s
Clean ACC: 10034/10630 = 0.943932, Loss: 0.2112559676170349
ASR: 9712/10005 = 0.970715


<Backdoor Training> Train Epoch: 5 	Loss: 0.109212, lr: 0.010000, Time: 3.54s
Clean ACC: 9970/10630 = 0.937912, Loss: 0.2214064747095108
ASR: 9635/10005 = 0.963018


<Backdoor Training> Train Epoch: 6 	Loss: 0.036388, lr: 0.010000, Time: 3.45s
Clean ACC: 10180/10630 = 0.957667, Loss: 0.14402922987937927
ASR: 9696/10005 = 0.969115


<Backdoor Training> Train Epoch: 7 	Loss: 0.035950, lr: 0.010000, Time: 3.50s
Clean ACC: 10112/10630 = 0.951270, Loss: 0.17420247197151184
ASR: 9864/10005 = 0.985907


<Backdoor Training> Train Epoch: 8 	Loss: 0.008267, lr: 0.010000, Time: 3.56s
Clean ACC: 10137/10630 = 0.953622, Loss: 0.16815216839313507
ASR: 9708/10005 = 0.970315


<Backdoor Training> Train Epoch: 9 	Loss: 0.001555, lr: 0.010000, Time: 3.59s
Clean ACC: 10179/10630 = 0.957573, Loss: 0.15598458051681519
ASR: 9759/10005 = 0.975412


<Backdoor Training> Train Epoch: 10 	Loss: 0.160154, lr: 0.010000, Time: 3.59s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.11749175190925598
ASR: 9659/10005 = 0.965417


<Backdoor Training> Train Epoch: 11 	Loss: 0.001427, lr: 0.010000, Time: 3.59s
Clean ACC: 10229/10630 = 0.962277, Loss: 0.12960213422775269
ASR: 9348/10005 = 0.934333


<Backdoor Training> Train Epoch: 12 	Loss: 0.002900, lr: 0.010000, Time: 3.54s
Clean ACC: 10274/10630 = 0.966510, Loss: 0.12561264634132385
ASR: 9443/10005 = 0.943828


<Backdoor Training> Train Epoch: 13 	Loss: 0.001617, lr: 0.010000, Time: 3.53s
Clean ACC: 10200/10630 = 0.959548, Loss: 0.13735496997833252
ASR: 9569/10005 = 0.956422


<Backdoor Training> Train Epoch: 14 	Loss: 0.000409, lr: 0.010000, Time: 3.63s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.12024413049221039
ASR: 9399/10005 = 0.939430


<Backdoor Training> Train Epoch: 15 	Loss: 0.004783, lr: 0.010000, Time: 3.52s
Clean ACC: 10278/10630 = 0.966886, Loss: 0.12337646633386612
ASR: 9798/10005 = 0.979310


<Backdoor Training> Train Epoch: 16 	Loss: 0.004153, lr: 0.010000, Time: 3.53s
Clean ACC: 10243/10630 = 0.963594, Loss: 0.13623356819152832
ASR: 9525/10005 = 0.952024


<Backdoor Training> Train Epoch: 17 	Loss: 0.012751, lr: 0.010000, Time: 3.54s
Clean ACC: 10189/10630 = 0.958514, Loss: 0.1469469666481018
ASR: 9491/10005 = 0.948626


<Backdoor Training> Train Epoch: 18 	Loss: 0.009818, lr: 0.010000, Time: 3.52s
Clean ACC: 10184/10630 = 0.958043, Loss: 0.15120990574359894
ASR: 9635/10005 = 0.963018


<Backdoor Training> Train Epoch: 19 	Loss: 0.002402, lr: 0.010000, Time: 3.58s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.11983434110879898
ASR: 9673/10005 = 0.966817


<Backdoor Training> Train Epoch: 20 	Loss: 0.002823, lr: 0.010000, Time: 3.55s
Clean ACC: 10301/10630 = 0.969050, Loss: 0.11409511417150497
ASR: 9597/10005 = 0.959220


<Backdoor Training> Train Epoch: 21 	Loss: 0.012340, lr: 0.010000, Time: 3.45s
Clean ACC: 10281/10630 = 0.967168, Loss: 0.12162324786186218
ASR: 9538/10005 = 0.953323


<Backdoor Training> Train Epoch: 22 	Loss: 0.002487, lr: 0.010000, Time: 3.60s
Clean ACC: 10278/10630 = 0.966886, Loss: 0.12245838344097137
ASR: 9833/10005 = 0.982809


<Backdoor Training> Train Epoch: 23 	Loss: 0.012610, lr: 0.010000, Time: 3.49s
Clean ACC: 10336/10630 = 0.972342, Loss: 0.11016213148832321
ASR: 9933/10005 = 0.992804


<Backdoor Training> Train Epoch: 24 	Loss: 0.006635, lr: 0.010000, Time: 3.50s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.12178809940814972
ASR: 9780/10005 = 0.977511


<Backdoor Training> Train Epoch: 25 	Loss: 0.014641, lr: 0.010000, Time: 3.46s
Clean ACC: 10320/10630 = 0.970837, Loss: 0.11575552821159363
ASR: 9786/10005 = 0.978111


<Backdoor Training> Train Epoch: 26 	Loss: 0.020422, lr: 0.010000, Time: 3.55s
Clean ACC: 10303/10630 = 0.969238, Loss: 0.12486011534929276
ASR: 9692/10005 = 0.968716


<Backdoor Training> Train Epoch: 27 	Loss: 0.000637, lr: 0.010000, Time: 3.55s
Clean ACC: 10276/10630 = 0.966698, Loss: 0.12853674590587616
ASR: 9929/10005 = 0.992404


<Backdoor Training> Train Epoch: 28 	Loss: 0.001216, lr: 0.010000, Time: 3.50s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.11967632919549942
ASR: 9635/10005 = 0.963018


<Backdoor Training> Train Epoch: 29 	Loss: 0.043524, lr: 0.010000, Time: 3.53s
Clean ACC: 10312/10630 = 0.970085, Loss: 0.11621693521738052
ASR: 9569/10005 = 0.956422


<Backdoor Training> Train Epoch: 30 	Loss: 0.001291, lr: 0.010000, Time: 3.51s
Clean ACC: 10306/10630 = 0.969520, Loss: 0.11941535025835037
ASR: 9568/10005 = 0.956322


<Backdoor Training> Train Epoch: 31 	Loss: 0.014610, lr: 0.001000, Time: 3.49s
Clean ACC: 10321/10630 = 0.970931, Loss: 0.10926469415426254
ASR: 9692/10005 = 0.968716


<Backdoor Training> Train Epoch: 32 	Loss: 0.033657, lr: 0.001000, Time: 3.54s
Clean ACC: 10327/10630 = 0.971496, Loss: 0.10883305966854095
ASR: 9744/10005 = 0.973913


<Backdoor Training> Train Epoch: 33 	Loss: 0.000215, lr: 0.001000, Time: 3.53s
Clean ACC: 10318/10630 = 0.970649, Loss: 0.1088147684931755
ASR: 9784/10005 = 0.977911


<Backdoor Training> Train Epoch: 34 	Loss: 0.001605, lr: 0.001000, Time: 3.47s
Clean ACC: 10330/10630 = 0.971778, Loss: 0.10563681274652481
ASR: 9809/10005 = 0.980410


<Backdoor Training> Train Epoch: 35 	Loss: 0.001133, lr: 0.001000, Time: 3.55s
Clean ACC: 10338/10630 = 0.972531, Loss: 0.10313453525304794
ASR: 9802/10005 = 0.979710


<Backdoor Training> Train Epoch: 36 	Loss: 0.000776, lr: 0.001000, Time: 3.65s
Clean ACC: 10344/10630 = 0.973095, Loss: 0.10116232186555862
ASR: 9785/10005 = 0.978011


<Backdoor Training> Train Epoch: 37 	Loss: 0.008821, lr: 0.001000, Time: 3.50s
Clean ACC: 10338/10630 = 0.972531, Loss: 0.10363904386758804
ASR: 9787/10005 = 0.978211


<Backdoor Training> Train Epoch: 38 	Loss: 0.001687, lr: 0.001000, Time: 3.55s
Clean ACC: 10346/10630 = 0.973283, Loss: 0.10040004551410675
ASR: 9817/10005 = 0.981209


<Backdoor Training> Train Epoch: 39 	Loss: 0.001118, lr: 0.001000, Time: 3.54s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.10073564946651459
ASR: 9794/10005 = 0.978911


<Backdoor Training> Train Epoch: 40 	Loss: 0.000815, lr: 0.001000, Time: 3.55s
Clean ACC: 10336/10630 = 0.972342, Loss: 0.10015079379081726
ASR: 9828/10005 = 0.982309


<Backdoor Training> Train Epoch: 41 	Loss: 0.001022, lr: 0.001000, Time: 3.60s
Clean ACC: 10342/10630 = 0.972907, Loss: 0.10032892972230911
ASR: 9824/10005 = 0.981909


<Backdoor Training> Train Epoch: 42 	Loss: 0.000497, lr: 0.001000, Time: 3.47s
Clean ACC: 10347/10630 = 0.973377, Loss: 0.0988786444067955
ASR: 9789/10005 = 0.978411


<Backdoor Training> Train Epoch: 43 	Loss: 0.000494, lr: 0.001000, Time: 3.46s
Clean ACC: 10347/10630 = 0.973377, Loss: 0.09717871248722076
ASR: 9824/10005 = 0.981909


<Backdoor Training> Train Epoch: 44 	Loss: 0.003188, lr: 0.001000, Time: 3.50s
Clean ACC: 10352/10630 = 0.973848, Loss: 0.09803827852010727
ASR: 9821/10005 = 0.981609


<Backdoor Training> Train Epoch: 45 	Loss: 0.000372, lr: 0.001000, Time: 3.57s
Clean ACC: 10346/10630 = 0.973283, Loss: 0.09724094718694687
ASR: 9789/10005 = 0.978411


<Backdoor Training> Train Epoch: 46 	Loss: 0.000552, lr: 0.001000, Time: 3.48s
Clean ACC: 10355/10630 = 0.974130, Loss: 0.09688795357942581
ASR: 9837/10005 = 0.983208


<Backdoor Training> Train Epoch: 47 	Loss: 0.000615, lr: 0.001000, Time: 3.59s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.0964023619890213
ASR: 9817/10005 = 0.981209


<Backdoor Training> Train Epoch: 48 	Loss: 0.000611, lr: 0.001000, Time: 3.52s
Clean ACC: 10355/10630 = 0.974130, Loss: 0.09462793171405792
ASR: 9818/10005 = 0.981309


<Backdoor Training> Train Epoch: 49 	Loss: 0.001353, lr: 0.001000, Time: 3.56s
Clean ACC: 10347/10630 = 0.973377, Loss: 0.09930869191884995
ASR: 9859/10005 = 0.985407


<Backdoor Training> Train Epoch: 50 	Loss: 0.000319, lr: 0.001000, Time: 3.56s
Clean ACC: 10348/10630 = 0.973471, Loss: 0.09846463054418564
ASR: 9879/10005 = 0.987406


<Backdoor Training> Train Epoch: 51 	Loss: 0.002528, lr: 0.001000, Time: 3.57s
Clean ACC: 10347/10630 = 0.973377, Loss: 0.09675707668066025
ASR: 9858/10005 = 0.985307


<Backdoor Training> Train Epoch: 52 	Loss: 0.001231, lr: 0.001000, Time: 3.60s
Clean ACC: 10351/10630 = 0.973754, Loss: 0.09809865802526474
ASR: 9821/10005 = 0.981609


<Backdoor Training> Train Epoch: 53 	Loss: 0.001960, lr: 0.001000, Time: 3.55s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.09888772666454315
ASR: 9840/10005 = 0.983508


<Backdoor Training> Train Epoch: 54 	Loss: 0.002491, lr: 0.001000, Time: 3.54s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.0985078290104866
ASR: 9886/10005 = 0.988106


<Backdoor Training> Train Epoch: 55 	Loss: 0.001783, lr: 0.001000, Time: 3.54s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09626272320747375
ASR: 9868/10005 = 0.986307


<Backdoor Training> Train Epoch: 56 	Loss: 0.001513, lr: 0.001000, Time: 3.50s
Clean ACC: 10356/10630 = 0.974224, Loss: 0.09718642383813858
ASR: 9892/10005 = 0.988706


<Backdoor Training> Train Epoch: 57 	Loss: 0.002425, lr: 0.001000, Time: 3.55s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.09743804484605789
ASR: 9816/10005 = 0.981109


<Backdoor Training> Train Epoch: 58 	Loss: 0.000934, lr: 0.001000, Time: 3.56s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.09578956663608551
ASR: 9842/10005 = 0.983708


<Backdoor Training> Train Epoch: 59 	Loss: 0.001681, lr: 0.001000, Time: 3.56s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.09480927884578705
ASR: 9856/10005 = 0.985107


<Backdoor Training> Train Epoch: 60 	Loss: 0.000842, lr: 0.001000, Time: 3.60s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09536103159189224
ASR: 9837/10005 = 0.983208


<Backdoor Training> Train Epoch: 61 	Loss: 0.000223, lr: 0.000100, Time: 3.58s
Clean ACC: 10362/10630 = 0.974788, Loss: 0.09360890835523605
ASR: 9858/10005 = 0.985307


<Backdoor Training> Train Epoch: 62 	Loss: 0.004558, lr: 0.000100, Time: 3.55s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.09546609967947006
ASR: 9828/10005 = 0.982309


<Backdoor Training> Train Epoch: 63 	Loss: 0.001462, lr: 0.000100, Time: 3.49s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.0930706039071083
ASR: 9860/10005 = 0.985507


<Backdoor Training> Train Epoch: 64 	Loss: 0.000314, lr: 0.000100, Time: 3.54s
Clean ACC: 10362/10630 = 0.974788, Loss: 0.0927378237247467
ASR: 9812/10005 = 0.980710


<Backdoor Training> Train Epoch: 65 	Loss: 0.004166, lr: 0.000100, Time: 3.62s
Clean ACC: 10357/10630 = 0.974318, Loss: 0.09512579441070557
ASR: 9866/10005 = 0.986107


<Backdoor Training> Train Epoch: 66 	Loss: 0.017963, lr: 0.000100, Time: 3.59s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.09373398870229721
ASR: 9854/10005 = 0.984908


<Backdoor Training> Train Epoch: 67 	Loss: 0.003139, lr: 0.000100, Time: 3.56s
Clean ACC: 10355/10630 = 0.974130, Loss: 0.09448789805173874
ASR: 9861/10005 = 0.985607


<Backdoor Training> Train Epoch: 68 	Loss: 0.000278, lr: 0.000100, Time: 3.63s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.0944429337978363
ASR: 9851/10005 = 0.984608


<Backdoor Training> Train Epoch: 69 	Loss: 0.002390, lr: 0.000100, Time: 3.53s
Clean ACC: 10365/10630 = 0.975071, Loss: 0.09280184656381607
ASR: 9827/10005 = 0.982209


<Backdoor Training> Train Epoch: 70 	Loss: 0.001479, lr: 0.000100, Time: 3.44s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09639376401901245
ASR: 9865/10005 = 0.986007


<Backdoor Training> Train Epoch: 71 	Loss: 0.020530, lr: 0.000100, Time: 3.56s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.0951274037361145
ASR: 9852/10005 = 0.984708


<Backdoor Training> Train Epoch: 72 	Loss: 0.001588, lr: 0.000100, Time: 3.58s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09439320862293243
ASR: 9840/10005 = 0.983508


<Backdoor Training> Train Epoch: 73 	Loss: 0.002017, lr: 0.000100, Time: 3.44s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.09542068094015121
ASR: 9851/10005 = 0.984608


<Backdoor Training> Train Epoch: 74 	Loss: 0.009375, lr: 0.000100, Time: 3.50s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.09709472209215164
ASR: 9857/10005 = 0.985207


<Backdoor Training> Train Epoch: 75 	Loss: 0.002255, lr: 0.000100, Time: 3.63s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.09548240900039673
ASR: 9861/10005 = 0.985607


<Backdoor Training> Train Epoch: 76 	Loss: 0.000110, lr: 0.000100, Time: 3.59s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.095718152821064
ASR: 9837/10005 = 0.983208


<Backdoor Training> Train Epoch: 77 	Loss: 0.008099, lr: 0.000100, Time: 3.62s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09462979435920715
ASR: 9861/10005 = 0.985607


<Backdoor Training> Train Epoch: 78 	Loss: 0.002223, lr: 0.000100, Time: 3.55s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09480366855859756
ASR: 9862/10005 = 0.985707


<Backdoor Training> Train Epoch: 79 	Loss: 0.000454, lr: 0.000100, Time: 3.51s
Clean ACC: 10359/10630 = 0.974506, Loss: 0.09539622813463211
ASR: 9845/10005 = 0.984008


<Backdoor Training> Train Epoch: 80 	Loss: 0.000517, lr: 0.000100, Time: 3.59s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.09383091330528259
ASR: 9830/10005 = 0.982509


<Backdoor Training> Train Epoch: 81 	Loss: 0.000801, lr: 0.000100, Time: 3.49s
Clean ACC: 10357/10630 = 0.974318, Loss: 0.09381098300218582
ASR: 9838/10005 = 0.983308


<Backdoor Training> Train Epoch: 82 	Loss: 0.002167, lr: 0.000100, Time: 3.58s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.09549270570278168
ASR: 9839/10005 = 0.983408


<Backdoor Training> Train Epoch: 83 	Loss: 0.007849, lr: 0.000100, Time: 3.57s
Clean ACC: 10365/10630 = 0.975071, Loss: 0.09457254409790039
ASR: 9850/10005 = 0.984508


<Backdoor Training> Train Epoch: 84 	Loss: 0.002197, lr: 0.000100, Time: 3.71s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.09253858774900436
ASR: 9840/10005 = 0.983508


<Backdoor Training> Train Epoch: 85 	Loss: 0.000701, lr: 0.000100, Time: 3.80s
Clean ACC: 10356/10630 = 0.974224, Loss: 0.09576132148504257
ASR: 9850/10005 = 0.984508


<Backdoor Training> Train Epoch: 86 	Loss: 0.005565, lr: 0.000100, Time: 3.78s
Clean ACC: 10362/10630 = 0.974788, Loss: 0.09350655227899551
ASR: 9870/10005 = 0.986507


<Backdoor Training> Train Epoch: 87 	Loss: 0.000305, lr: 0.000100, Time: 3.77s
Clean ACC: 10362/10630 = 0.974788, Loss: 0.09321557730436325
ASR: 9856/10005 = 0.985107


<Backdoor Training> Train Epoch: 88 	Loss: 0.002476, lr: 0.000100, Time: 3.73s
Clean ACC: 10357/10630 = 0.974318, Loss: 0.09479633718729019
ASR: 9843/10005 = 0.983808


<Backdoor Training> Train Epoch: 89 	Loss: 0.000689, lr: 0.000100, Time: 3.68s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.09477344155311584
ASR: 9847/10005 = 0.984208


<Backdoor Training> Train Epoch: 90 	Loss: 0.003026, lr: 0.000100, Time: 3.73s
Clean ACC: 10361/10630 = 0.974694, Loss: 0.09495122730731964
ASR: 9843/10005 = 0.983808


<Backdoor Training> Train Epoch: 91 	Loss: 0.001123, lr: 0.000100, Time: 3.77s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.0925372913479805
ASR: 9850/10005 = 0.984508


<Backdoor Training> Train Epoch: 92 	Loss: 0.004484, lr: 0.000100, Time: 3.73s
Clean ACC: 10370/10630 = 0.975541, Loss: 0.09170034527778625
ASR: 9875/10005 = 0.987006


<Backdoor Training> Train Epoch: 93 	Loss: 0.000225, lr: 0.000100, Time: 3.77s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09458506852388382
ASR: 9863/10005 = 0.985807


<Backdoor Training> Train Epoch: 94 	Loss: 0.000766, lr: 0.000100, Time: 3.78s
Clean ACC: 10358/10630 = 0.974412, Loss: 0.09457725286483765
ASR: 9856/10005 = 0.985107


<Backdoor Training> Train Epoch: 95 	Loss: 0.000878, lr: 0.000100, Time: 3.69s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.09399384260177612
ASR: 9848/10005 = 0.984308


<Backdoor Training> Train Epoch: 96 	Loss: 0.007917, lr: 0.000100, Time: 3.76s
Clean ACC: 10356/10630 = 0.974224, Loss: 0.09452014416456223
ASR: 9841/10005 = 0.983608


<Backdoor Training> Train Epoch: 97 	Loss: 0.011651, lr: 0.000100, Time: 3.58s
Clean ACC: 10364/10630 = 0.974976, Loss: 0.09220973402261734
ASR: 9852/10005 = 0.984708


<Backdoor Training> Train Epoch: 98 	Loss: 0.000493, lr: 0.000100, Time: 3.45s
Clean ACC: 10363/10630 = 0.974882, Loss: 0.09410572797060013
ASR: 9865/10005 = 0.986007


<Backdoor Training> Train Epoch: 99 	Loss: 0.000926, lr: 0.000100, Time: 3.52s
Clean ACC: 10360/10630 = 0.974600, Loss: 0.09384792298078537
ASR: 9843/10005 = 0.983808


<Backdoor Training> Train Epoch: 100 	Loss: 0.001472, lr: 0.000100, Time: 3.46s
Clean ACC: 10365/10630 = 0.975071, Loss: 0.09274517744779587
ASR: 9853/10005 = 0.984808


Testing the backdoor model...
Evaluating model 'poisoned_train_set/gtsrb/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 10365/10630 = 0.975071, Loss: 0.09274517744779587
ASR: 9853/10005 = 0.984808

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/gtsrb/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10366/10630 = 0.975165, Loss: 0.09274407476186752
ASR: 9853/10005 = 0.984808

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 7.195625, poison_dis: 13.998438
Silhouette Score: 0.2928041
Saved figure at assets/pca_gtsrb_adaptive_patch_0.010_cover=0.000_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10366/10630 = 0.975165, Loss: 0.09274407476186752
ASR: 9853/10005 = 0.984808

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 7.195625, poison_dis: 13.998438
Silhouette Score: 0.2928041
Saved figure at assets/tsne_gtsrb_adaptive_patch_0.010_cover=0.000_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10366/10630 = 0.975165, Loss: 0.09274407476186752
ASR: 9853/10005 = 0.984808

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 7.195625, poison_dis: 13.998438
Silhouette Score: 0.2928041
SVM Accuracy: 1.0
Saved figure at assets/oracle_gtsrb_adaptive_patch_0.010_cover=0.000_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/none
No trigger mask found! By default masking all black pixels...
Evaluating model 'poisoned_train_set/gtsrb/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 97.5070571899414
asr: 98.56304931640625
target label: tensor([2], device='cuda:0')
start_index: 8
TPR: 98.57
FPR: 6.45
AUC: 0.9588
f1 score: 0.961549050197302
Elapsed time: 38.05s
Experiment for GTSRB with adaptive_patch completed.
