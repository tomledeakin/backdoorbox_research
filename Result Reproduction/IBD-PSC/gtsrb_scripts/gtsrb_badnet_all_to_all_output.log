Creating poisoned training set for badnet_all_to_all on GTSRB...
[target class : 2]
Poisoned set directory 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/imgs
Will save to 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt'.
<Backdoor Training> Train Epoch: 1 	Loss: 0.124139, lr: 0.010000, Time: 8.38s
Clean ACC: 9574/10630 = 0.900659, Loss: 0.3622514009475708
ASR: 76/10630 = 0.007150


<Backdoor Training> Train Epoch: 2 	Loss: 0.071389, lr: 0.010000, Time: 3.53s
Clean ACC: 9803/10630 = 0.922201, Loss: 0.28360897302627563
ASR: 136/10630 = 0.012794


<Backdoor Training> Train Epoch: 3 	Loss: 0.159194, lr: 0.010000, Time: 3.53s
Clean ACC: 10136/10630 = 0.953528, Loss: 0.17196597158908844
ASR: 64/10630 = 0.006021


<Backdoor Training> Train Epoch: 4 	Loss: 0.226815, lr: 0.010000, Time: 3.61s
Clean ACC: 9996/10630 = 0.940357, Loss: 0.21777477860450745
ASR: 127/10630 = 0.011947


<Backdoor Training> Train Epoch: 5 	Loss: 0.379308, lr: 0.010000, Time: 3.53s
Clean ACC: 10152/10630 = 0.955033, Loss: 0.18262717127799988
ASR: 60/10630 = 0.005644


<Backdoor Training> Train Epoch: 6 	Loss: 0.318392, lr: 0.010000, Time: 3.51s
Clean ACC: 10146/10630 = 0.954468, Loss: 0.16993175446987152
ASR: 76/10630 = 0.007150


<Backdoor Training> Train Epoch: 7 	Loss: 0.016248, lr: 0.010000, Time: 3.62s
Clean ACC: 10266/10630 = 0.965757, Loss: 0.13597369194030762
ASR: 60/10630 = 0.005644


<Backdoor Training> Train Epoch: 8 	Loss: 0.252175, lr: 0.010000, Time: 3.50s
Clean ACC: 10146/10630 = 0.954468, Loss: 0.16690611839294434
ASR: 103/10630 = 0.009690


<Backdoor Training> Train Epoch: 9 	Loss: 0.009314, lr: 0.010000, Time: 3.56s
Clean ACC: 10168/10630 = 0.956538, Loss: 0.16174332797527313
ASR: 106/10630 = 0.009972


<Backdoor Training> Train Epoch: 10 	Loss: 0.005980, lr: 0.010000, Time: 3.52s
Clean ACC: 10197/10630 = 0.959266, Loss: 0.1638103723526001
ASR: 47/10630 = 0.004421


<Backdoor Training> Train Epoch: 11 	Loss: 0.031464, lr: 0.010000, Time: 3.43s
Clean ACC: 10267/10630 = 0.965851, Loss: 0.12058775126934052
ASR: 78/10630 = 0.007338


<Backdoor Training> Train Epoch: 12 	Loss: 0.022562, lr: 0.010000, Time: 3.54s
Clean ACC: 10264/10630 = 0.965569, Loss: 0.12650668621063232
ASR: 86/10630 = 0.008090


<Backdoor Training> Train Epoch: 13 	Loss: 0.049671, lr: 0.010000, Time: 3.51s
Clean ACC: 10256/10630 = 0.964817, Loss: 0.1281937062740326
ASR: 63/10630 = 0.005927


<Backdoor Training> Train Epoch: 14 	Loss: 0.012749, lr: 0.010000, Time: 3.59s
Clean ACC: 10225/10630 = 0.961900, Loss: 0.13691923022270203
ASR: 234/10630 = 0.022013


<Backdoor Training> Train Epoch: 15 	Loss: 0.007256, lr: 0.010000, Time: 3.53s
Clean ACC: 10166/10630 = 0.956350, Loss: 0.15572986006736755
ASR: 810/10630 = 0.076199


<Backdoor Training> Train Epoch: 16 	Loss: 0.001638, lr: 0.010000, Time: 3.56s
Clean ACC: 10166/10630 = 0.956350, Loss: 0.14856082201004028
ASR: 760/10630 = 0.071496


<Backdoor Training> Train Epoch: 17 	Loss: 0.010362, lr: 0.010000, Time: 3.59s
Clean ACC: 10292/10630 = 0.968203, Loss: 0.11606435477733612
ASR: 946/10630 = 0.088993


<Backdoor Training> Train Epoch: 18 	Loss: 0.004351, lr: 0.010000, Time: 3.60s
Clean ACC: 10166/10630 = 0.956350, Loss: 0.14693592488765717
ASR: 1015/10630 = 0.095484


<Backdoor Training> Train Epoch: 19 	Loss: 0.017807, lr: 0.010000, Time: 3.55s
Clean ACC: 10239/10630 = 0.963217, Loss: 0.13348573446273804
ASR: 1379/10630 = 0.129727


<Backdoor Training> Train Epoch: 20 	Loss: 0.003973, lr: 0.010000, Time: 3.58s
Clean ACC: 10304/10630 = 0.969332, Loss: 0.1073501855134964
ASR: 1613/10630 = 0.151740


<Backdoor Training> Train Epoch: 21 	Loss: 0.029752, lr: 0.010000, Time: 3.44s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.11805183440446854
ASR: 1715/10630 = 0.161336


<Backdoor Training> Train Epoch: 22 	Loss: 0.006974, lr: 0.010000, Time: 3.51s
Clean ACC: 10255/10630 = 0.964722, Loss: 0.12384992837905884
ASR: 2228/10630 = 0.209595


<Backdoor Training> Train Epoch: 23 	Loss: 0.003996, lr: 0.010000, Time: 3.53s
Clean ACC: 10258/10630 = 0.965005, Loss: 0.12200140208005905
ASR: 1848/10630 = 0.173848


<Backdoor Training> Train Epoch: 24 	Loss: 0.015430, lr: 0.010000, Time: 3.66s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.12070996314287186
ASR: 2520/10630 = 0.237065


<Backdoor Training> Train Epoch: 25 	Loss: 0.005636, lr: 0.010000, Time: 3.48s
Clean ACC: 10282/10630 = 0.967262, Loss: 0.12290629744529724
ASR: 2370/10630 = 0.222954


<Backdoor Training> Train Epoch: 26 	Loss: 0.006602, lr: 0.010000, Time: 3.59s
Clean ACC: 10273/10630 = 0.966416, Loss: 0.11193042248487473
ASR: 2911/10630 = 0.273848


<Backdoor Training> Train Epoch: 27 	Loss: 0.009047, lr: 0.010000, Time: 3.43s
Clean ACC: 10200/10630 = 0.959548, Loss: 0.14946134388446808
ASR: 2954/10630 = 0.277893


<Backdoor Training> Train Epoch: 28 	Loss: 0.000757, lr: 0.010000, Time: 3.57s
Clean ACC: 10245/10630 = 0.963782, Loss: 0.12534978985786438
ASR: 3611/10630 = 0.339699


<Backdoor Training> Train Epoch: 29 	Loss: 0.000864, lr: 0.010000, Time: 3.53s
Clean ACC: 10319/10630 = 0.970743, Loss: 0.10293074697256088
ASR: 2712/10630 = 0.255127


<Backdoor Training> Train Epoch: 30 	Loss: 0.006795, lr: 0.010000, Time: 3.57s
Clean ACC: 10302/10630 = 0.969144, Loss: 0.10838472843170166
ASR: 3403/10630 = 0.320132


<Backdoor Training> Train Epoch: 31 	Loss: 0.001643, lr: 0.001000, Time: 3.38s
Clean ACC: 10309/10630 = 0.969802, Loss: 0.1032659187912941
ASR: 3189/10630 = 0.300000


<Backdoor Training> Train Epoch: 32 	Loss: 0.001175, lr: 0.001000, Time: 3.76s
Clean ACC: 10310/10630 = 0.969897, Loss: 0.10173031687736511
ASR: 3232/10630 = 0.304045


<Backdoor Training> Train Epoch: 33 	Loss: 0.009771, lr: 0.001000, Time: 3.64s
Clean ACC: 10299/10630 = 0.968862, Loss: 0.10366511344909668
ASR: 3052/10630 = 0.287112


<Backdoor Training> Train Epoch: 34 	Loss: 0.002329, lr: 0.001000, Time: 3.44s
Clean ACC: 10312/10630 = 0.970085, Loss: 0.09919597208499908
ASR: 3007/10630 = 0.282879


<Backdoor Training> Train Epoch: 35 	Loss: 0.003910, lr: 0.001000, Time: 3.55s
Clean ACC: 10308/10630 = 0.969708, Loss: 0.09945855289697647
ASR: 3085/10630 = 0.290216


<Backdoor Training> Train Epoch: 36 	Loss: 0.003812, lr: 0.001000, Time: 3.55s
Clean ACC: 10319/10630 = 0.970743, Loss: 0.09936957061290741
ASR: 2996/10630 = 0.281844


<Backdoor Training> Train Epoch: 37 	Loss: 0.004927, lr: 0.001000, Time: 3.65s
Clean ACC: 10315/10630 = 0.970367, Loss: 0.09778974950313568
ASR: 3056/10630 = 0.287488


<Backdoor Training> Train Epoch: 38 	Loss: 0.002622, lr: 0.001000, Time: 3.63s
Clean ACC: 10312/10630 = 0.970085, Loss: 0.09822915494441986
ASR: 3054/10630 = 0.287300


<Backdoor Training> Train Epoch: 39 	Loss: 0.001667, lr: 0.001000, Time: 3.71s
Clean ACC: 10309/10630 = 0.969802, Loss: 0.0989241972565651
ASR: 3109/10630 = 0.292474


<Backdoor Training> Train Epoch: 40 	Loss: 0.001372, lr: 0.001000, Time: 3.51s
Clean ACC: 10326/10630 = 0.971402, Loss: 0.0961616188287735
ASR: 3024/10630 = 0.284478


<Backdoor Training> Train Epoch: 41 	Loss: 0.003043, lr: 0.001000, Time: 3.59s
Clean ACC: 10321/10630 = 0.970931, Loss: 0.09831833094358444
ASR: 2979/10630 = 0.280245


<Backdoor Training> Train Epoch: 42 	Loss: 0.002639, lr: 0.001000, Time: 3.54s
Clean ACC: 10324/10630 = 0.971214, Loss: 0.09859292209148407
ASR: 3050/10630 = 0.286924


<Backdoor Training> Train Epoch: 43 	Loss: 0.001719, lr: 0.001000, Time: 3.49s
Clean ACC: 10316/10630 = 0.970461, Loss: 0.0976271778345108
ASR: 3018/10630 = 0.283913


<Backdoor Training> Train Epoch: 44 	Loss: 0.004399, lr: 0.001000, Time: 3.52s
Clean ACC: 10312/10630 = 0.970085, Loss: 0.09766532480716705
ASR: 3253/10630 = 0.306021


<Backdoor Training> Train Epoch: 45 	Loss: 0.004933, lr: 0.001000, Time: 3.56s
Clean ACC: 10321/10630 = 0.970931, Loss: 0.09734541922807693
ASR: 3123/10630 = 0.293791


<Backdoor Training> Train Epoch: 46 	Loss: 0.003882, lr: 0.001000, Time: 3.53s
Clean ACC: 10316/10630 = 0.970461, Loss: 0.10079410672187805
ASR: 3014/10630 = 0.283537


<Backdoor Training> Train Epoch: 47 	Loss: 0.026306, lr: 0.001000, Time: 3.66s
Clean ACC: 10317/10630 = 0.970555, Loss: 0.09879246354103088
ASR: 3032/10630 = 0.285230


<Backdoor Training> Train Epoch: 48 	Loss: 0.001453, lr: 0.001000, Time: 3.48s
Clean ACC: 10323/10630 = 0.971119, Loss: 0.09726467728614807
ASR: 2952/10630 = 0.277705


<Backdoor Training> Train Epoch: 49 	Loss: 0.076745, lr: 0.001000, Time: 3.55s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09806732833385468
ASR: 2914/10630 = 0.274130


<Backdoor Training> Train Epoch: 50 	Loss: 0.021981, lr: 0.001000, Time: 3.56s
Clean ACC: 10307/10630 = 0.969614, Loss: 0.10159223526716232
ASR: 2909/10630 = 0.273659


<Backdoor Training> Train Epoch: 51 	Loss: 0.002888, lr: 0.001000, Time: 3.56s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09702582657337189
ASR: 3007/10630 = 0.282879


<Backdoor Training> Train Epoch: 52 	Loss: 0.018829, lr: 0.001000, Time: 3.58s
Clean ACC: 10318/10630 = 0.970649, Loss: 0.0995582640171051
ASR: 2915/10630 = 0.274224


<Backdoor Training> Train Epoch: 53 	Loss: 0.032856, lr: 0.001000, Time: 3.56s
Clean ACC: 10326/10630 = 0.971402, Loss: 0.09753729403018951
ASR: 2801/10630 = 0.263500


<Backdoor Training> Train Epoch: 54 	Loss: 0.001288, lr: 0.001000, Time: 3.49s
Clean ACC: 10315/10630 = 0.970367, Loss: 0.09677457064390182
ASR: 2989/10630 = 0.281185


<Backdoor Training> Train Epoch: 55 	Loss: 0.000516, lr: 0.001000, Time: 3.58s
Clean ACC: 10323/10630 = 0.971119, Loss: 0.09710868448019028
ASR: 2889/10630 = 0.271778


<Backdoor Training> Train Epoch: 56 	Loss: 0.009442, lr: 0.001000, Time: 3.60s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09586435556411743
ASR: 2901/10630 = 0.272907


<Backdoor Training> Train Epoch: 57 	Loss: 0.002081, lr: 0.001000, Time: 3.57s
Clean ACC: 10321/10630 = 0.970931, Loss: 0.09793941676616669
ASR: 2919/10630 = 0.274600


<Backdoor Training> Train Epoch: 58 	Loss: 0.001209, lr: 0.001000, Time: 3.49s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09647907316684723
ASR: 3051/10630 = 0.287018


<Backdoor Training> Train Epoch: 59 	Loss: 0.000727, lr: 0.001000, Time: 3.47s
Clean ACC: 10334/10630 = 0.972154, Loss: 0.09517470747232437
ASR: 2921/10630 = 0.274788


<Backdoor Training> Train Epoch: 60 	Loss: 0.005376, lr: 0.001000, Time: 3.53s
Clean ACC: 10329/10630 = 0.971684, Loss: 0.09506735950708389
ASR: 2851/10630 = 0.268203


<Backdoor Training> Train Epoch: 61 	Loss: 0.002038, lr: 0.000100, Time: 3.56s
Clean ACC: 10318/10630 = 0.970649, Loss: 0.09694702923297882
ASR: 2887/10630 = 0.271590


<Backdoor Training> Train Epoch: 62 	Loss: 0.001131, lr: 0.000100, Time: 3.61s
Clean ACC: 10328/10630 = 0.971590, Loss: 0.09747237712144852
ASR: 2947/10630 = 0.277234


<Backdoor Training> Train Epoch: 63 	Loss: 0.001510, lr: 0.000100, Time: 3.60s
Clean ACC: 10330/10630 = 0.971778, Loss: 0.0949208214879036
ASR: 2869/10630 = 0.269897


<Backdoor Training> Train Epoch: 64 	Loss: 0.000498, lr: 0.000100, Time: 3.52s
Clean ACC: 10323/10630 = 0.971119, Loss: 0.09561196714639664
ASR: 2883/10630 = 0.271214


<Backdoor Training> Train Epoch: 65 	Loss: 0.022648, lr: 0.000100, Time: 3.54s
Clean ACC: 10328/10630 = 0.971590, Loss: 0.09492963552474976
ASR: 2878/10630 = 0.270743


<Backdoor Training> Train Epoch: 66 	Loss: 0.001547, lr: 0.000100, Time: 3.53s
Clean ACC: 10331/10630 = 0.971872, Loss: 0.09557397663593292
ASR: 2922/10630 = 0.274882


<Backdoor Training> Train Epoch: 67 	Loss: 0.004089, lr: 0.000100, Time: 3.59s
Clean ACC: 10331/10630 = 0.971872, Loss: 0.09568233042955399
ASR: 2910/10630 = 0.273754


<Backdoor Training> Train Epoch: 68 	Loss: 0.004359, lr: 0.000100, Time: 3.63s
Clean ACC: 10327/10630 = 0.971496, Loss: 0.09601239114999771
ASR: 2818/10630 = 0.265099


<Backdoor Training> Train Epoch: 69 	Loss: 0.001264, lr: 0.000100, Time: 3.46s
Clean ACC: 10328/10630 = 0.971590, Loss: 0.09584028273820877
ASR: 2911/10630 = 0.273848


<Backdoor Training> Train Epoch: 70 	Loss: 0.002458, lr: 0.000100, Time: 3.59s
Clean ACC: 10324/10630 = 0.971214, Loss: 0.09442997723817825
ASR: 2921/10630 = 0.274788


<Backdoor Training> Train Epoch: 71 	Loss: 0.000495, lr: 0.000100, Time: 3.56s
Clean ACC: 10318/10630 = 0.970649, Loss: 0.09894663840532303
ASR: 2890/10630 = 0.271872


<Backdoor Training> Train Epoch: 72 	Loss: 0.001351, lr: 0.000100, Time: 3.52s
Clean ACC: 10330/10630 = 0.971778, Loss: 0.09492550045251846
ASR: 2816/10630 = 0.264911


<Backdoor Training> Train Epoch: 73 	Loss: 0.003815, lr: 0.000100, Time: 3.84s
Clean ACC: 10320/10630 = 0.970837, Loss: 0.09660089015960693
ASR: 2787/10630 = 0.262183


<Backdoor Training> Train Epoch: 74 	Loss: 0.001427, lr: 0.000100, Time: 3.57s
Clean ACC: 10319/10630 = 0.970743, Loss: 0.09835102409124374
ASR: 2939/10630 = 0.276482


<Backdoor Training> Train Epoch: 75 	Loss: 0.024970, lr: 0.000100, Time: 3.57s
Clean ACC: 10321/10630 = 0.970931, Loss: 0.09781957417726517
ASR: 2909/10630 = 0.273659


<Backdoor Training> Train Epoch: 76 	Loss: 0.005841, lr: 0.000100, Time: 3.55s
Clean ACC: 10318/10630 = 0.970649, Loss: 0.09662216156721115
ASR: 2831/10630 = 0.266322


<Backdoor Training> Train Epoch: 77 	Loss: 0.001101, lr: 0.000100, Time: 3.57s
Clean ACC: 10332/10630 = 0.971966, Loss: 0.09613490849733353
ASR: 2793/10630 = 0.262747


<Backdoor Training> Train Epoch: 78 	Loss: 0.000668, lr: 0.000100, Time: 3.56s
Clean ACC: 10327/10630 = 0.971496, Loss: 0.09648636728525162
ASR: 2875/10630 = 0.270461


<Backdoor Training> Train Epoch: 79 	Loss: 0.001850, lr: 0.000100, Time: 3.60s
Clean ACC: 10313/10630 = 0.970179, Loss: 0.09598619490861893
ASR: 2837/10630 = 0.266886


<Backdoor Training> Train Epoch: 80 	Loss: 0.000538, lr: 0.000100, Time: 3.59s
Clean ACC: 10323/10630 = 0.971119, Loss: 0.0970894917845726
ASR: 2913/10630 = 0.274036


<Backdoor Training> Train Epoch: 81 	Loss: 0.002233, lr: 0.000100, Time: 3.58s
Clean ACC: 10331/10630 = 0.971872, Loss: 0.0967554822564125
ASR: 2873/10630 = 0.270273


<Backdoor Training> Train Epoch: 82 	Loss: 0.021685, lr: 0.000100, Time: 3.49s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09605889767408371
ASR: 2903/10630 = 0.273095


<Backdoor Training> Train Epoch: 83 	Loss: 0.003674, lr: 0.000100, Time: 3.56s
Clean ACC: 10327/10630 = 0.971496, Loss: 0.09615077823400497
ASR: 2819/10630 = 0.265193


<Backdoor Training> Train Epoch: 84 	Loss: 0.004333, lr: 0.000100, Time: 3.61s
Clean ACC: 10323/10630 = 0.971119, Loss: 0.0967632308602333
ASR: 2806/10630 = 0.263970


<Backdoor Training> Train Epoch: 85 	Loss: 0.000982, lr: 0.000100, Time: 3.53s
Clean ACC: 10326/10630 = 0.971402, Loss: 0.09587789326906204
ASR: 2876/10630 = 0.270555


<Backdoor Training> Train Epoch: 86 	Loss: 0.001017, lr: 0.000100, Time: 3.51s
Clean ACC: 10331/10630 = 0.971872, Loss: 0.09527647495269775
ASR: 2851/10630 = 0.268203


<Backdoor Training> Train Epoch: 87 	Loss: 0.000507, lr: 0.000100, Time: 3.61s
Clean ACC: 10329/10630 = 0.971684, Loss: 0.09356465190649033
ASR: 2891/10630 = 0.271966


<Backdoor Training> Train Epoch: 88 	Loss: 0.000973, lr: 0.000100, Time: 3.61s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09495805948972702
ASR: 2888/10630 = 0.271684


<Backdoor Training> Train Epoch: 89 	Loss: 0.001371, lr: 0.000100, Time: 3.72s
Clean ACC: 10325/10630 = 0.971308, Loss: 0.09450097382068634
ASR: 2934/10630 = 0.276011


<Backdoor Training> Train Epoch: 90 	Loss: 0.001919, lr: 0.000100, Time: 3.71s
Clean ACC: 10326/10630 = 0.971402, Loss: 0.09460102766752243
ASR: 2891/10630 = 0.271966


<Backdoor Training> Train Epoch: 91 	Loss: 0.000561, lr: 0.000100, Time: 3.78s
Clean ACC: 10329/10630 = 0.971684, Loss: 0.09640221297740936
ASR: 2874/10630 = 0.270367


<Backdoor Training> Train Epoch: 92 	Loss: 0.002337, lr: 0.000100, Time: 3.74s
Clean ACC: 10323/10630 = 0.971119, Loss: 0.09698857367038727
ASR: 2766/10630 = 0.260207


<Backdoor Training> Train Epoch: 93 	Loss: 0.000998, lr: 0.000100, Time: 3.71s
Clean ACC: 10326/10630 = 0.971402, Loss: 0.09763942658901215
ASR: 2776/10630 = 0.261148


<Backdoor Training> Train Epoch: 94 	Loss: 0.001042, lr: 0.000100, Time: 3.80s
Clean ACC: 10324/10630 = 0.971214, Loss: 0.09484509378671646
ASR: 2866/10630 = 0.269614


<Backdoor Training> Train Epoch: 95 	Loss: 0.001657, lr: 0.000100, Time: 3.73s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09581996500492096
ASR: 2770/10630 = 0.260583


<Backdoor Training> Train Epoch: 96 	Loss: 0.001178, lr: 0.000100, Time: 3.72s
Clean ACC: 10321/10630 = 0.970931, Loss: 0.09650277346372604
ASR: 2782/10630 = 0.261712


<Backdoor Training> Train Epoch: 97 	Loss: 0.011576, lr: 0.000100, Time: 3.77s
Clean ACC: 10319/10630 = 0.970743, Loss: 0.09727861732244492
ASR: 2871/10630 = 0.270085


<Backdoor Training> Train Epoch: 98 	Loss: 0.003571, lr: 0.000100, Time: 3.68s
Clean ACC: 10333/10630 = 0.972060, Loss: 0.09605160355567932
ASR: 2724/10630 = 0.256256


<Backdoor Training> Train Epoch: 99 	Loss: 0.000300, lr: 0.000100, Time: 3.77s
Clean ACC: 10325/10630 = 0.971308, Loss: 0.09553427249193192
ASR: 2870/10630 = 0.269991


<Backdoor Training> Train Epoch: 100 	Loss: 0.009321, lr: 0.000100, Time: 3.73s
Clean ACC: 10319/10630 = 0.970743, Loss: 0.10020723938941956
ASR: 2728/10630 = 0.256632


Testing the backdoor model...
Evaluating model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 10319/10630 = 0.970743, Loss: 0.10020723938941956
ASR: 2728/10630 = 0.256632

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10319/10630 = 0.970743, Loss: 0.10020018368959427
ASR: 142/10332 = 0.013744

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.633326, poison_dis: 17.592314
Silhouette Score: 0.4991171
Saved figure at assets/pca_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10319/10630 = 0.970743, Loss: 0.10020018368959427
ASR: 142/10332 = 0.013744

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.633326, poison_dis: 17.592314
Silhouette Score: 0.4991171
Saved figure at assets/tsne_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10319/10630 = 0.970743, Loss: 0.10020018368959427
ASR: 142/10332 = 0.013744

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.633326, poison_dis: 17.592314
Silhouette Score: 0.4991171
SVM Accuracy: 1.0
Saved figure at assets/oracle_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/badnet_patch_32.png
trigger_mask_path: ./triggers/mask_badnet_patch_32.png
Evaluating model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 97.0743179321289
asr: 25.78937339782715
target label: tensor([9], device='cuda:0')
start_index: 11
TPR: 7.14
FPR: 12.38
AUC: 0.2009
f1 score: 0.11948051948051948
Elapsed time: 20.24s
Experiment for GTSRB with badnet_all_to_all completed.
