Creating poisoned training set for blend on GTSRB...
[target class : 2]
Poisoned set directory 'poisoned_train_set/gtsrb/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/gtsrb/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/imgs
Will save to 'poisoned_train_set/gtsrb/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'.
<Backdoor Training> Train Epoch: 1 	Loss: 0.226347, lr: 0.010000, Time: 6.52s
Clean ACC: 9320/10630 = 0.876764, Loss: 0.4545590281486511
ASR: 8246/10005 = 0.824188


<Backdoor Training> Train Epoch: 2 	Loss: 0.147346, lr: 0.010000, Time: 3.47s
Clean ACC: 9918/10630 = 0.933020, Loss: 0.23906241357326508
ASR: 8951/10005 = 0.894653


<Backdoor Training> Train Epoch: 3 	Loss: 0.027944, lr: 0.010000, Time: 3.42s
Clean ACC: 9980/10630 = 0.938852, Loss: 0.23954856395721436
ASR: 9723/10005 = 0.971814


<Backdoor Training> Train Epoch: 4 	Loss: 0.001592, lr: 0.010000, Time: 3.41s
Clean ACC: 10097/10630 = 0.949859, Loss: 0.1785576045513153
ASR: 9569/10005 = 0.956422


<Backdoor Training> Train Epoch: 5 	Loss: 0.005953, lr: 0.010000, Time: 3.39s
Clean ACC: 10181/10630 = 0.957761, Loss: 0.17128989100456238
ASR: 9836/10005 = 0.983108


<Backdoor Training> Train Epoch: 6 	Loss: 0.001813, lr: 0.010000, Time: 3.45s
Clean ACC: 10204/10630 = 0.959925, Loss: 0.16071514785289764
ASR: 9800/10005 = 0.979510


<Backdoor Training> Train Epoch: 7 	Loss: 0.002624, lr: 0.010000, Time: 3.42s
Clean ACC: 10249/10630 = 0.964158, Loss: 0.15107128024101257
ASR: 9627/10005 = 0.962219


<Backdoor Training> Train Epoch: 8 	Loss: 0.002791, lr: 0.010000, Time: 3.46s
Clean ACC: 10234/10630 = 0.962747, Loss: 0.14698241651058197
ASR: 9677/10005 = 0.967216


<Backdoor Training> Train Epoch: 9 	Loss: 0.014299, lr: 0.010000, Time: 3.47s
Clean ACC: 10229/10630 = 0.962277, Loss: 0.14479714632034302
ASR: 9766/10005 = 0.976112


<Backdoor Training> Train Epoch: 10 	Loss: 0.001861, lr: 0.010000, Time: 3.48s
Clean ACC: 10221/10630 = 0.961524, Loss: 0.16089017689228058
ASR: 9805/10005 = 0.980010


<Backdoor Training> Train Epoch: 11 	Loss: 0.012246, lr: 0.010000, Time: 3.45s
Clean ACC: 10169/10630 = 0.956632, Loss: 0.16632673144340515
ASR: 9654/10005 = 0.964918


<Backdoor Training> Train Epoch: 12 	Loss: 0.008302, lr: 0.010000, Time: 3.50s
Clean ACC: 10227/10630 = 0.962088, Loss: 0.150127574801445
ASR: 9765/10005 = 0.976012


<Backdoor Training> Train Epoch: 13 	Loss: 0.005094, lr: 0.010000, Time: 3.40s
Clean ACC: 10238/10630 = 0.963123, Loss: 0.14776456356048584
ASR: 9743/10005 = 0.973813


<Backdoor Training> Train Epoch: 14 	Loss: 0.000625, lr: 0.010000, Time: 3.44s
Clean ACC: 10243/10630 = 0.963594, Loss: 0.15101496875286102
ASR: 9723/10005 = 0.971814


<Backdoor Training> Train Epoch: 15 	Loss: 0.001477, lr: 0.010000, Time: 3.40s
Clean ACC: 10166/10630 = 0.956350, Loss: 0.16320554912090302
ASR: 9625/10005 = 0.962019


<Backdoor Training> Train Epoch: 16 	Loss: 0.000309, lr: 0.010000, Time: 3.45s
Clean ACC: 10257/10630 = 0.964911, Loss: 0.13704781234264374
ASR: 9642/10005 = 0.963718


<Backdoor Training> Train Epoch: 17 	Loss: 0.000915, lr: 0.010000, Time: 3.42s
Clean ACC: 10271/10630 = 0.966228, Loss: 0.1336447298526764
ASR: 9711/10005 = 0.970615


<Backdoor Training> Train Epoch: 18 	Loss: 0.000152, lr: 0.010000, Time: 3.47s
Clean ACC: 10264/10630 = 0.965569, Loss: 0.13909244537353516
ASR: 9693/10005 = 0.968816


<Backdoor Training> Train Epoch: 19 	Loss: 0.001992, lr: 0.010000, Time: 3.53s
Clean ACC: 10254/10630 = 0.964628, Loss: 0.14090098440647125
ASR: 9762/10005 = 0.975712


<Backdoor Training> Train Epoch: 20 	Loss: 0.028653, lr: 0.010000, Time: 3.49s
Clean ACC: 10188/10630 = 0.958420, Loss: 0.16562466323375702
ASR: 9387/10005 = 0.938231


<Backdoor Training> Train Epoch: 21 	Loss: 0.003199, lr: 0.010000, Time: 3.50s
Clean ACC: 10186/10630 = 0.958231, Loss: 0.15737198293209076
ASR: 9712/10005 = 0.970715


<Backdoor Training> Train Epoch: 22 	Loss: 0.017849, lr: 0.010000, Time: 3.54s
Clean ACC: 10202/10630 = 0.959737, Loss: 0.17012988030910492
ASR: 9772/10005 = 0.976712


<Backdoor Training> Train Epoch: 23 	Loss: 0.007180, lr: 0.010000, Time: 3.50s
Clean ACC: 10255/10630 = 0.964722, Loss: 0.13807040452957153
ASR: 9699/10005 = 0.969415


<Backdoor Training> Train Epoch: 24 	Loss: 0.000876, lr: 0.010000, Time: 3.48s
Clean ACC: 10252/10630 = 0.964440, Loss: 0.13819800317287445
ASR: 9675/10005 = 0.967016


<Backdoor Training> Train Epoch: 25 	Loss: 0.000996, lr: 0.010000, Time: 3.54s
Clean ACC: 10256/10630 = 0.964817, Loss: 0.13893261551856995
ASR: 9685/10005 = 0.968016


<Backdoor Training> Train Epoch: 26 	Loss: 0.000595, lr: 0.010000, Time: 3.46s
Clean ACC: 10258/10630 = 0.965005, Loss: 0.13766472041606903
ASR: 9719/10005 = 0.971414


<Backdoor Training> Train Epoch: 27 	Loss: 0.000891, lr: 0.010000, Time: 3.49s
Clean ACC: 10256/10630 = 0.964817, Loss: 0.13320060074329376
ASR: 9683/10005 = 0.967816


<Backdoor Training> Train Epoch: 28 	Loss: 0.007540, lr: 0.010000, Time: 3.52s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.12680669128894806
ASR: 9734/10005 = 0.972914


<Backdoor Training> Train Epoch: 29 	Loss: 0.000406, lr: 0.010000, Time: 3.46s
Clean ACC: 10273/10630 = 0.966416, Loss: 0.13100983202457428
ASR: 9697/10005 = 0.969215


<Backdoor Training> Train Epoch: 30 	Loss: 0.008512, lr: 0.010000, Time: 3.45s
Clean ACC: 10270/10630 = 0.966134, Loss: 0.1342080682516098
ASR: 9698/10005 = 0.969315


<Backdoor Training> Train Epoch: 31 	Loss: 0.023607, lr: 0.001000, Time: 3.47s
Clean ACC: 10276/10630 = 0.966698, Loss: 0.1364816129207611
ASR: 9777/10005 = 0.977211


<Backdoor Training> Train Epoch: 32 	Loss: 0.001374, lr: 0.001000, Time: 3.48s
Clean ACC: 10271/10630 = 0.966228, Loss: 0.13758735358715057
ASR: 9757/10005 = 0.975212


<Backdoor Training> Train Epoch: 33 	Loss: 0.000890, lr: 0.001000, Time: 3.48s
Clean ACC: 10272/10630 = 0.966322, Loss: 0.13408859074115753
ASR: 9748/10005 = 0.974313


<Backdoor Training> Train Epoch: 34 	Loss: 0.002270, lr: 0.001000, Time: 3.50s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.13089685142040253
ASR: 9724/10005 = 0.971914


<Backdoor Training> Train Epoch: 35 	Loss: 0.000290, lr: 0.001000, Time: 3.52s
Clean ACC: 10282/10630 = 0.967262, Loss: 0.1339019238948822
ASR: 9749/10005 = 0.974413


<Backdoor Training> Train Epoch: 36 	Loss: 0.005665, lr: 0.001000, Time: 3.45s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.13098163902759552
ASR: 9721/10005 = 0.971614


<Backdoor Training> Train Epoch: 37 	Loss: 0.001099, lr: 0.001000, Time: 3.54s
Clean ACC: 10279/10630 = 0.966980, Loss: 0.13233624398708344
ASR: 9669/10005 = 0.966417


<Backdoor Training> Train Epoch: 38 	Loss: 0.001406, lr: 0.001000, Time: 3.43s
Clean ACC: 10294/10630 = 0.968391, Loss: 0.13181175291538239
ASR: 9772/10005 = 0.976712


<Backdoor Training> Train Epoch: 39 	Loss: 0.000568, lr: 0.001000, Time: 3.56s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.12955746054649353
ASR: 9710/10005 = 0.970515


<Backdoor Training> Train Epoch: 40 	Loss: 0.000436, lr: 0.001000, Time: 3.49s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.1290750503540039
ASR: 9722/10005 = 0.971714


<Backdoor Training> Train Epoch: 41 	Loss: 0.000305, lr: 0.001000, Time: 3.44s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.131302148103714
ASR: 9727/10005 = 0.972214


<Backdoor Training> Train Epoch: 42 	Loss: 0.000700, lr: 0.001000, Time: 3.52s
Clean ACC: 10281/10630 = 0.967168, Loss: 0.13127043843269348
ASR: 9743/10005 = 0.973813


<Backdoor Training> Train Epoch: 43 	Loss: 0.001189, lr: 0.001000, Time: 3.52s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.13071101903915405
ASR: 9725/10005 = 0.972014


<Backdoor Training> Train Epoch: 44 	Loss: 0.002064, lr: 0.001000, Time: 3.55s
Clean ACC: 10296/10630 = 0.968579, Loss: 0.13052500784397125
ASR: 9718/10005 = 0.971314


<Backdoor Training> Train Epoch: 45 	Loss: 0.002572, lr: 0.001000, Time: 3.50s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.12902025878429413
ASR: 9706/10005 = 0.970115


<Backdoor Training> Train Epoch: 46 	Loss: 0.003434, lr: 0.001000, Time: 3.48s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.1308886557817459
ASR: 9748/10005 = 0.974313


<Backdoor Training> Train Epoch: 47 	Loss: 0.003962, lr: 0.001000, Time: 3.52s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.12773720920085907
ASR: 9702/10005 = 0.969715


<Backdoor Training> Train Epoch: 48 	Loss: 0.001484, lr: 0.001000, Time: 3.54s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.1305186003446579
ASR: 9739/10005 = 0.973413


<Backdoor Training> Train Epoch: 49 	Loss: 0.000211, lr: 0.001000, Time: 3.51s
Clean ACC: 10293/10630 = 0.968297, Loss: 0.1276007890701294
ASR: 9736/10005 = 0.973113


<Backdoor Training> Train Epoch: 50 	Loss: 0.000596, lr: 0.001000, Time: 3.53s
Clean ACC: 10293/10630 = 0.968297, Loss: 0.12890315055847168
ASR: 9708/10005 = 0.970315


<Backdoor Training> Train Epoch: 51 	Loss: 0.000450, lr: 0.001000, Time: 3.53s
Clean ACC: 10296/10630 = 0.968579, Loss: 0.12939171493053436
ASR: 9742/10005 = 0.973713


<Backdoor Training> Train Epoch: 52 	Loss: 0.000212, lr: 0.001000, Time: 3.51s
Clean ACC: 10295/10630 = 0.968485, Loss: 0.12897053360939026
ASR: 9723/10005 = 0.971814


<Backdoor Training> Train Epoch: 53 	Loss: 0.000196, lr: 0.001000, Time: 3.42s
Clean ACC: 10292/10630 = 0.968203, Loss: 0.12839406728744507
ASR: 9741/10005 = 0.973613


<Backdoor Training> Train Epoch: 54 	Loss: 0.000614, lr: 0.001000, Time: 3.53s
Clean ACC: 10298/10630 = 0.968768, Loss: 0.12926143407821655
ASR: 9757/10005 = 0.975212


<Backdoor Training> Train Epoch: 55 	Loss: 0.002596, lr: 0.001000, Time: 3.43s
Clean ACC: 10298/10630 = 0.968768, Loss: 0.1243545338511467
ASR: 9676/10005 = 0.967116


<Backdoor Training> Train Epoch: 56 	Loss: 0.000888, lr: 0.001000, Time: 3.48s
Clean ACC: 10301/10630 = 0.969050, Loss: 0.12607234716415405
ASR: 9757/10005 = 0.975212


<Backdoor Training> Train Epoch: 57 	Loss: 0.002649, lr: 0.001000, Time: 3.43s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.12996315956115723
ASR: 9714/10005 = 0.970915


<Backdoor Training> Train Epoch: 58 	Loss: 0.000689, lr: 0.001000, Time: 3.52s
Clean ACC: 10300/10630 = 0.968956, Loss: 0.12771888077259064
ASR: 9750/10005 = 0.974513


<Backdoor Training> Train Epoch: 59 	Loss: 0.000233, lr: 0.001000, Time: 3.44s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.12946569919586182
ASR: 9743/10005 = 0.973813


<Backdoor Training> Train Epoch: 60 	Loss: 0.001226, lr: 0.001000, Time: 3.51s
Clean ACC: 10293/10630 = 0.968297, Loss: 0.12612563371658325
ASR: 9654/10005 = 0.964918


<Backdoor Training> Train Epoch: 61 	Loss: 0.000435, lr: 0.000100, Time: 3.43s
Clean ACC: 10305/10630 = 0.969426, Loss: 0.1266711801290512
ASR: 9690/10005 = 0.968516


<Backdoor Training> Train Epoch: 62 	Loss: 0.001250, lr: 0.000100, Time: 3.51s
Clean ACC: 10295/10630 = 0.968485, Loss: 0.12634247541427612
ASR: 9752/10005 = 0.974713


<Backdoor Training> Train Epoch: 63 	Loss: 0.000274, lr: 0.000100, Time: 3.53s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.1272895336151123
ASR: 9733/10005 = 0.972814


<Backdoor Training> Train Epoch: 64 	Loss: 0.006118, lr: 0.000100, Time: 3.44s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.1282837688922882
ASR: 9701/10005 = 0.969615


<Backdoor Training> Train Epoch: 65 	Loss: 0.003292, lr: 0.000100, Time: 3.53s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.1268644779920578
ASR: 9732/10005 = 0.972714


<Backdoor Training> Train Epoch: 66 	Loss: 0.014046, lr: 0.000100, Time: 3.51s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.13143983483314514
ASR: 9751/10005 = 0.974613


<Backdoor Training> Train Epoch: 67 	Loss: 0.001859, lr: 0.000100, Time: 3.45s
Clean ACC: 10300/10630 = 0.968956, Loss: 0.12656745314598083
ASR: 9687/10005 = 0.968216


<Backdoor Training> Train Epoch: 68 	Loss: 0.000559, lr: 0.000100, Time: 3.47s
Clean ACC: 10298/10630 = 0.968768, Loss: 0.12725239992141724
ASR: 9714/10005 = 0.970915


<Backdoor Training> Train Epoch: 69 	Loss: 0.001995, lr: 0.000100, Time: 3.51s
Clean ACC: 10294/10630 = 0.968391, Loss: 0.1275033950805664
ASR: 9745/10005 = 0.974013


<Backdoor Training> Train Epoch: 70 	Loss: 0.005477, lr: 0.000100, Time: 3.50s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.12745223939418793
ASR: 9718/10005 = 0.971314


<Backdoor Training> Train Epoch: 71 	Loss: 0.014031, lr: 0.000100, Time: 3.49s
Clean ACC: 10293/10630 = 0.968297, Loss: 0.1292687952518463
ASR: 9743/10005 = 0.973813


<Backdoor Training> Train Epoch: 72 	Loss: 0.000255, lr: 0.000100, Time: 3.49s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.13073550164699554
ASR: 9744/10005 = 0.973913


<Backdoor Training> Train Epoch: 73 	Loss: 0.000186, lr: 0.000100, Time: 3.46s
Clean ACC: 10294/10630 = 0.968391, Loss: 0.1251697838306427
ASR: 9744/10005 = 0.973913


<Backdoor Training> Train Epoch: 74 	Loss: 0.000867, lr: 0.000100, Time: 3.44s
Clean ACC: 10303/10630 = 0.969238, Loss: 0.12625281512737274
ASR: 9740/10005 = 0.973513


<Backdoor Training> Train Epoch: 75 	Loss: 0.000720, lr: 0.000100, Time: 3.48s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.12796157598495483
ASR: 9705/10005 = 0.970015


<Backdoor Training> Train Epoch: 76 	Loss: 0.000507, lr: 0.000100, Time: 3.51s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.12771522998809814
ASR: 9715/10005 = 0.971014


<Backdoor Training> Train Epoch: 77 	Loss: 0.001081, lr: 0.000100, Time: 3.43s
Clean ACC: 10298/10630 = 0.968768, Loss: 0.12718206644058228
ASR: 9735/10005 = 0.973013


<Backdoor Training> Train Epoch: 78 	Loss: 0.001368, lr: 0.000100, Time: 3.52s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.1287362426519394
ASR: 9721/10005 = 0.971614


<Backdoor Training> Train Epoch: 79 	Loss: 0.000178, lr: 0.000100, Time: 3.48s
Clean ACC: 10299/10630 = 0.968862, Loss: 0.1258687824010849
ASR: 9714/10005 = 0.970915


<Backdoor Training> Train Epoch: 80 	Loss: 0.004923, lr: 0.000100, Time: 3.49s
Clean ACC: 10296/10630 = 0.968579, Loss: 0.12678110599517822
ASR: 9735/10005 = 0.973013


<Backdoor Training> Train Epoch: 81 	Loss: 0.000835, lr: 0.000100, Time: 3.46s
Clean ACC: 10300/10630 = 0.968956, Loss: 0.1264137327671051
ASR: 9713/10005 = 0.970815


<Backdoor Training> Train Epoch: 82 	Loss: 0.004909, lr: 0.000100, Time: 3.49s
Clean ACC: 10293/10630 = 0.968297, Loss: 0.12647221982479095
ASR: 9707/10005 = 0.970215


<Backdoor Training> Train Epoch: 83 	Loss: 0.000376, lr: 0.000100, Time: 3.53s
Clean ACC: 10296/10630 = 0.968579, Loss: 0.12724614143371582
ASR: 9714/10005 = 0.970915


<Backdoor Training> Train Epoch: 84 	Loss: 0.008864, lr: 0.000100, Time: 3.55s
Clean ACC: 10296/10630 = 0.968579, Loss: 0.12501020729541779
ASR: 9708/10005 = 0.970315


<Backdoor Training> Train Epoch: 85 	Loss: 0.000244, lr: 0.000100, Time: 3.52s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.12932591140270233
ASR: 9688/10005 = 0.968316


<Backdoor Training> Train Epoch: 86 	Loss: 0.000322, lr: 0.000100, Time: 3.47s
Clean ACC: 10298/10630 = 0.968768, Loss: 0.12672226130962372
ASR: 9697/10005 = 0.969215


<Backdoor Training> Train Epoch: 87 	Loss: 0.000162, lr: 0.000100, Time: 3.50s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.12960031628608704
ASR: 9746/10005 = 0.974113


<Backdoor Training> Train Epoch: 88 	Loss: 0.000079, lr: 0.000100, Time: 3.52s
Clean ACC: 10295/10630 = 0.968485, Loss: 0.12882056832313538
ASR: 9741/10005 = 0.973613


<Backdoor Training> Train Epoch: 89 	Loss: 0.001171, lr: 0.000100, Time: 3.44s
Clean ACC: 10293/10630 = 0.968297, Loss: 0.12745355069637299
ASR: 9732/10005 = 0.972714


<Backdoor Training> Train Epoch: 90 	Loss: 0.002138, lr: 0.000100, Time: 3.43s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.12885499000549316
ASR: 9729/10005 = 0.972414


<Backdoor Training> Train Epoch: 91 	Loss: 0.000102, lr: 0.000100, Time: 3.47s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.12955443561077118
ASR: 9663/10005 = 0.965817


<Backdoor Training> Train Epoch: 92 	Loss: 0.000522, lr: 0.000100, Time: 3.54s
Clean ACC: 10302/10630 = 0.969144, Loss: 0.12533541023731232
ASR: 9731/10005 = 0.972614


<Backdoor Training> Train Epoch: 93 	Loss: 0.005848, lr: 0.000100, Time: 3.55s
Clean ACC: 10295/10630 = 0.968485, Loss: 0.12655021250247955
ASR: 9756/10005 = 0.975112


<Backdoor Training> Train Epoch: 94 	Loss: 0.000126, lr: 0.000100, Time: 3.50s
Clean ACC: 10297/10630 = 0.968674, Loss: 0.12802088260650635
ASR: 9743/10005 = 0.973813


<Backdoor Training> Train Epoch: 95 	Loss: 0.000280, lr: 0.000100, Time: 3.43s
Clean ACC: 10294/10630 = 0.968391, Loss: 0.12637193500995636
ASR: 9736/10005 = 0.973113


<Backdoor Training> Train Epoch: 96 	Loss: 0.000366, lr: 0.000100, Time: 3.54s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.12897691130638123
ASR: 9733/10005 = 0.972814


<Backdoor Training> Train Epoch: 97 	Loss: 0.000795, lr: 0.000100, Time: 3.54s
Clean ACC: 10297/10630 = 0.968674, Loss: 0.1254800707101822
ASR: 9727/10005 = 0.972214


<Backdoor Training> Train Epoch: 98 	Loss: 0.001046, lr: 0.000100, Time: 3.49s
Clean ACC: 10297/10630 = 0.968674, Loss: 0.1251845359802246
ASR: 9703/10005 = 0.969815


<Backdoor Training> Train Epoch: 99 	Loss: 0.000740, lr: 0.000100, Time: 3.45s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.12835603952407837
ASR: 9714/10005 = 0.970915


<Backdoor Training> Train Epoch: 100 	Loss: 0.000233, lr: 0.000100, Time: 3.50s
Clean ACC: 10296/10630 = 0.968579, Loss: 0.12482297420501709
ASR: 9742/10005 = 0.973713


Testing the backdoor model...
Evaluating model 'poisoned_train_set/gtsrb/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 10296/10630 = 0.968579, Loss: 0.12482297420501709
ASR: 9742/10005 = 0.973713

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/gtsrb/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10296/10630 = 0.968579, Loss: 0.12482746690511703
ASR: 9742/10005 = 0.973713

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.038680, poison_dis: 11.000849
Silhouette Score: 0.2892821
Saved figure at assets/pca_gtsrb_blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10296/10630 = 0.968579, Loss: 0.12482746690511703
ASR: 9742/10005 = 0.973713

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.038680, poison_dis: 11.000849
Silhouette Score: 0.2892821
Saved figure at assets/tsne_gtsrb_blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Visualizing model 'poisoned_train_set/gtsrb/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10296/10630 = 0.968579, Loss: 0.12482746690511703
ASR: 9742/10005 = 0.973713

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.038680, poison_dis: 11.000849
Silhouette Score: 0.2892821
SVM Accuracy: 1.0
Saved figure at assets/oracle_gtsrb_blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/hellokitty_32.png
trigger_mask_path: ./triggers/mask_hellokitty_32.png
Evaluating model 'poisoned_train_set/gtsrb/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 96.85795593261719
asr: 97.51370239257812
target label: tensor([2], device='cuda:0')
start_index: 12
TPR: 0.44
FPR: 21.90
AUC: 0.2853
f1 score: 0.0072279892349096505
Elapsed time: 18.75s
Experiment for GTSRB with blend completed.
