Creating poisoned training set for SIG on cifar10...
[target class : 0]
Files already downloaded and verified
Poisoned set directory 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/imgs
Will save to 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt'.
Model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' already exists!
<Backdoor Training> Train Epoch: 1 	Loss: 1.681313, lr: 0.100000, Time: 9.59s
Clean ACC: 2895/8000 = 0.361875, Loss: 1.7065616846084595
ASR: 544/7193 = 0.075629


<Backdoor Training> Train Epoch: 2 	Loss: 1.320983, lr: 0.100000, Time: 6.34s
Clean ACC: 3859/8000 = 0.482375, Loss: 1.4201608896255493
ASR: 316/7193 = 0.043932


<Backdoor Training> Train Epoch: 3 	Loss: 1.240116, lr: 0.100000, Time: 6.43s
Clean ACC: 4734/8000 = 0.591750, Loss: 1.134914517402649
ASR: 1006/7193 = 0.139858


<Backdoor Training> Train Epoch: 4 	Loss: 1.040767, lr: 0.100000, Time: 6.53s
Clean ACC: 4768/8000 = 0.596000, Loss: 1.1401987075805664
ASR: 2236/7193 = 0.310858


<Backdoor Training> Train Epoch: 5 	Loss: 0.902150, lr: 0.100000, Time: 6.30s
Clean ACC: 5168/8000 = 0.646000, Loss: 0.9974446892738342
ASR: 2813/7193 = 0.391075


<Backdoor Training> Train Epoch: 6 	Loss: 0.862206, lr: 0.100000, Time: 6.35s
Clean ACC: 5731/8000 = 0.716375, Loss: 0.8200588822364807
ASR: 2809/7193 = 0.390519


<Backdoor Training> Train Epoch: 7 	Loss: 0.748977, lr: 0.100000, Time: 6.38s
Clean ACC: 5806/8000 = 0.725750, Loss: 0.808430016040802
ASR: 5353/7193 = 0.744196


<Backdoor Training> Train Epoch: 8 	Loss: 0.647283, lr: 0.100000, Time: 6.42s
Clean ACC: 5991/8000 = 0.748875, Loss: 0.7485414147377014
ASR: 5180/7193 = 0.720145


<Backdoor Training> Train Epoch: 9 	Loss: 0.728644, lr: 0.100000, Time: 6.36s
Clean ACC: 6275/8000 = 0.784375, Loss: 0.6269651055335999
ASR: 4122/7193 = 0.573057


<Backdoor Training> Train Epoch: 10 	Loss: 0.558434, lr: 0.100000, Time: 6.44s
Clean ACC: 6355/8000 = 0.794375, Loss: 0.6053168773651123
ASR: 5026/7193 = 0.698735


<Backdoor Training> Train Epoch: 11 	Loss: 0.819635, lr: 0.100000, Time: 6.49s
Clean ACC: 6455/8000 = 0.806875, Loss: 0.5845247507095337
ASR: 3977/7193 = 0.552899


<Backdoor Training> Train Epoch: 12 	Loss: 0.537125, lr: 0.100000, Time: 6.44s
Clean ACC: 6640/8000 = 0.830000, Loss: 0.5062850117683411
ASR: 3392/7193 = 0.471570


<Backdoor Training> Train Epoch: 13 	Loss: 0.445932, lr: 0.100000, Time: 6.62s
Clean ACC: 6637/8000 = 0.829625, Loss: 0.506413996219635
ASR: 2998/7193 = 0.416794


<Backdoor Training> Train Epoch: 14 	Loss: 0.357165, lr: 0.100000, Time: 6.29s
Clean ACC: 6704/8000 = 0.838000, Loss: 0.4780440032482147
ASR: 4066/7193 = 0.565272


<Backdoor Training> Train Epoch: 15 	Loss: 0.304876, lr: 0.100000, Time: 6.32s
Clean ACC: 6822/8000 = 0.852750, Loss: 0.4250180721282959
ASR: 5970/7193 = 0.829974


<Backdoor Training> Train Epoch: 16 	Loss: 0.442982, lr: 0.100000, Time: 6.43s
Clean ACC: 6844/8000 = 0.855500, Loss: 0.42626798152923584
ASR: 4807/7193 = 0.668289


<Backdoor Training> Train Epoch: 17 	Loss: 0.248294, lr: 0.100000, Time: 6.54s
Clean ACC: 6899/8000 = 0.862375, Loss: 0.415624737739563
ASR: 5502/7193 = 0.764910


<Backdoor Training> Train Epoch: 18 	Loss: 0.389218, lr: 0.100000, Time: 6.44s
Clean ACC: 6793/8000 = 0.849125, Loss: 0.4619213938713074
ASR: 3731/7193 = 0.518699


<Backdoor Training> Train Epoch: 19 	Loss: 0.250821, lr: 0.100000, Time: 6.38s
Clean ACC: 6882/8000 = 0.860250, Loss: 0.4168769121170044
ASR: 2650/7193 = 0.368414


<Backdoor Training> Train Epoch: 20 	Loss: 0.474942, lr: 0.100000, Time: 6.58s
Clean ACC: 6794/8000 = 0.849250, Loss: 0.4621184468269348
ASR: 4121/7193 = 0.572918


<Backdoor Training> Train Epoch: 21 	Loss: 0.410331, lr: 0.100000, Time: 6.39s
Clean ACC: 6865/8000 = 0.858125, Loss: 0.44311171770095825
ASR: 4649/7193 = 0.646323


<Backdoor Training> Train Epoch: 22 	Loss: 0.385901, lr: 0.100000, Time: 6.38s
Clean ACC: 6956/8000 = 0.869500, Loss: 0.40540528297424316
ASR: 5545/7193 = 0.770888


<Backdoor Training> Train Epoch: 23 	Loss: 0.231060, lr: 0.100000, Time: 6.46s
Clean ACC: 7014/8000 = 0.876750, Loss: 0.3811076283454895
ASR: 4321/7193 = 0.600723


<Backdoor Training> Train Epoch: 24 	Loss: 0.136265, lr: 0.100000, Time: 6.39s
Clean ACC: 6968/8000 = 0.871000, Loss: 0.4071672856807709
ASR: 2175/7193 = 0.302377


<Backdoor Training> Train Epoch: 25 	Loss: 0.249201, lr: 0.100000, Time: 6.41s
Clean ACC: 6995/8000 = 0.874375, Loss: 0.39364850521087646
ASR: 5065/7193 = 0.704157


<Backdoor Training> Train Epoch: 26 	Loss: 0.174704, lr: 0.100000, Time: 6.32s
Clean ACC: 6973/8000 = 0.871625, Loss: 0.4157809913158417
ASR: 4729/7193 = 0.657445


<Backdoor Training> Train Epoch: 27 	Loss: 0.188887, lr: 0.100000, Time: 6.34s
Clean ACC: 7028/8000 = 0.878500, Loss: 0.37842631340026855
ASR: 4389/7193 = 0.610177


<Backdoor Training> Train Epoch: 28 	Loss: 0.122639, lr: 0.100000, Time: 6.53s
Clean ACC: 7136/8000 = 0.892000, Loss: 0.3479551672935486
ASR: 4148/7193 = 0.576672


<Backdoor Training> Train Epoch: 29 	Loss: 0.157016, lr: 0.100000, Time: 6.55s
Clean ACC: 7072/8000 = 0.884000, Loss: 0.3765508234500885
ASR: 4567/7193 = 0.634923


<Backdoor Training> Train Epoch: 30 	Loss: 0.267257, lr: 0.100000, Time: 6.51s
Clean ACC: 6960/8000 = 0.870000, Loss: 0.44070255756378174
ASR: 4476/7193 = 0.622272


<Backdoor Training> Train Epoch: 31 	Loss: 0.217715, lr: 0.100000, Time: 6.34s
Clean ACC: 7074/8000 = 0.884250, Loss: 0.3802269995212555
ASR: 4813/7193 = 0.669123


<Backdoor Training> Train Epoch: 32 	Loss: 0.159047, lr: 0.100000, Time: 6.55s
Clean ACC: 6957/8000 = 0.869625, Loss: 0.4266792833805084
ASR: 5272/7193 = 0.732935


<Backdoor Training> Train Epoch: 33 	Loss: 0.116959, lr: 0.100000, Time: 6.50s
Clean ACC: 7020/8000 = 0.877500, Loss: 0.40376394987106323
ASR: 4788/7193 = 0.665647


<Backdoor Training> Train Epoch: 34 	Loss: 0.398886, lr: 0.100000, Time: 6.43s
Clean ACC: 7066/8000 = 0.883250, Loss: 0.3766232132911682
ASR: 5665/7193 = 0.787571


<Backdoor Training> Train Epoch: 35 	Loss: 0.218216, lr: 0.100000, Time: 6.59s
Clean ACC: 7052/8000 = 0.881500, Loss: 0.4071444571018219
ASR: 3383/7193 = 0.470318


<Backdoor Training> Train Epoch: 36 	Loss: 0.154174, lr: 0.100000, Time: 6.42s
Clean ACC: 7108/8000 = 0.888500, Loss: 0.3625450134277344
ASR: 4642/7193 = 0.645350


<Backdoor Training> Train Epoch: 37 	Loss: 0.103765, lr: 0.100000, Time: 6.39s
Clean ACC: 7089/8000 = 0.886125, Loss: 0.3785040080547333
ASR: 5163/7193 = 0.717781


<Backdoor Training> Train Epoch: 38 	Loss: 0.195718, lr: 0.100000, Time: 6.38s
Clean ACC: 7061/8000 = 0.882625, Loss: 0.38482949137687683
ASR: 6110/7193 = 0.849437


<Backdoor Training> Train Epoch: 39 	Loss: 0.136024, lr: 0.100000, Time: 6.47s
Clean ACC: 7146/8000 = 0.893250, Loss: 0.3519915044307709
ASR: 3961/7193 = 0.550674


<Backdoor Training> Train Epoch: 40 	Loss: 0.138518, lr: 0.100000, Time: 6.59s
Clean ACC: 7151/8000 = 0.893875, Loss: 0.3827035129070282
ASR: 4929/7193 = 0.685250


<Backdoor Training> Train Epoch: 41 	Loss: 0.113742, lr: 0.100000, Time: 6.26s
Clean ACC: 7043/8000 = 0.880375, Loss: 0.41205552220344543
ASR: 4368/7193 = 0.607257


<Backdoor Training> Train Epoch: 42 	Loss: 0.160455, lr: 0.100000, Time: 6.54s
Clean ACC: 7064/8000 = 0.883000, Loss: 0.371893048286438
ASR: 5203/7193 = 0.723342


<Backdoor Training> Train Epoch: 43 	Loss: 0.102233, lr: 0.100000, Time: 6.44s
Clean ACC: 7115/8000 = 0.889375, Loss: 0.38964328169822693
ASR: 4687/7193 = 0.651606


<Backdoor Training> Train Epoch: 44 	Loss: 0.107994, lr: 0.100000, Time: 6.59s
Clean ACC: 7119/8000 = 0.889875, Loss: 0.38152891397476196
ASR: 3032/7193 = 0.421521


<Backdoor Training> Train Epoch: 45 	Loss: 0.252899, lr: 0.100000, Time: 6.54s
Clean ACC: 7163/8000 = 0.895375, Loss: 0.34507739543914795
ASR: 5018/7193 = 0.697623


<Backdoor Training> Train Epoch: 46 	Loss: 0.161358, lr: 0.100000, Time: 6.46s
Clean ACC: 7129/8000 = 0.891125, Loss: 0.3665292263031006
ASR: 5221/7193 = 0.725845


<Backdoor Training> Train Epoch: 47 	Loss: 0.116524, lr: 0.100000, Time: 6.34s
Clean ACC: 7086/8000 = 0.885750, Loss: 0.41330868005752563
ASR: 3888/7193 = 0.540526


<Backdoor Training> Train Epoch: 48 	Loss: 0.180194, lr: 0.100000, Time: 6.47s
Clean ACC: 7088/8000 = 0.886000, Loss: 0.38812997937202454
ASR: 4639/7193 = 0.644933


<Backdoor Training> Train Epoch: 49 	Loss: 0.076260, lr: 0.100000, Time: 6.44s
Clean ACC: 7030/8000 = 0.878750, Loss: 0.4287746846675873
ASR: 4096/7193 = 0.569443


<Backdoor Training> Train Epoch: 50 	Loss: 0.113241, lr: 0.100000, Time: 6.59s
Clean ACC: 7142/8000 = 0.892750, Loss: 0.3873291611671448
ASR: 3198/7193 = 0.444599


<Backdoor Training> Train Epoch: 51 	Loss: 0.064308, lr: 0.010000, Time: 6.50s
Clean ACC: 7425/8000 = 0.928125, Loss: 0.2501796782016754
ASR: 4063/7193 = 0.564855


<Backdoor Training> Train Epoch: 52 	Loss: 0.015155, lr: 0.010000, Time: 6.47s
Clean ACC: 7452/8000 = 0.931500, Loss: 0.2421804517507553
ASR: 4433/7193 = 0.616294


<Backdoor Training> Train Epoch: 53 	Loss: 0.044637, lr: 0.010000, Time: 6.41s
Clean ACC: 7450/8000 = 0.931250, Loss: 0.24064719676971436
ASR: 4486/7193 = 0.623662


<Backdoor Training> Train Epoch: 54 	Loss: 0.007972, lr: 0.010000, Time: 6.46s
Clean ACC: 7461/8000 = 0.932625, Loss: 0.2450011819601059
ASR: 4718/7193 = 0.655915


<Backdoor Training> Train Epoch: 55 	Loss: 0.010080, lr: 0.010000, Time: 6.44s
Clean ACC: 7469/8000 = 0.933625, Loss: 0.2477906197309494
ASR: 4686/7193 = 0.651467


<Backdoor Training> Train Epoch: 56 	Loss: 0.005642, lr: 0.010000, Time: 6.48s
Clean ACC: 7464/8000 = 0.933000, Loss: 0.2520717680454254
ASR: 4915/7193 = 0.683303


<Backdoor Training> Train Epoch: 57 	Loss: 0.004385, lr: 0.010000, Time: 6.51s
Clean ACC: 7473/8000 = 0.934125, Loss: 0.25286391377449036
ASR: 4513/7193 = 0.627416


<Backdoor Training> Train Epoch: 58 	Loss: 0.016671, lr: 0.010000, Time: 6.44s
Clean ACC: 7469/8000 = 0.933625, Loss: 0.2573789954185486
ASR: 5315/7193 = 0.738913


<Backdoor Training> Train Epoch: 59 	Loss: 0.006425, lr: 0.010000, Time: 6.50s
Clean ACC: 7468/8000 = 0.933500, Loss: 0.25997912883758545
ASR: 5143/7193 = 0.715001


<Backdoor Training> Train Epoch: 60 	Loss: 0.012556, lr: 0.010000, Time: 6.45s
Clean ACC: 7475/8000 = 0.934375, Loss: 0.2643106281757355
ASR: 5029/7193 = 0.699152


<Backdoor Training> Train Epoch: 61 	Loss: 0.026994, lr: 0.010000, Time: 6.42s
Clean ACC: 7475/8000 = 0.934375, Loss: 0.2625077962875366
ASR: 4823/7193 = 0.670513


<Backdoor Training> Train Epoch: 62 	Loss: 0.002512, lr: 0.010000, Time: 6.48s
Clean ACC: 7479/8000 = 0.934875, Loss: 0.26449620723724365
ASR: 4954/7193 = 0.688725


<Backdoor Training> Train Epoch: 63 	Loss: 0.004229, lr: 0.010000, Time: 6.73s
Clean ACC: 7489/8000 = 0.936125, Loss: 0.2663419246673584
ASR: 4842/7193 = 0.673154


<Backdoor Training> Train Epoch: 64 	Loss: 0.005519, lr: 0.010000, Time: 6.48s
Clean ACC: 7483/8000 = 0.935375, Loss: 0.27119576930999756
ASR: 4005/7193 = 0.556791


<Backdoor Training> Train Epoch: 65 	Loss: 0.001637, lr: 0.010000, Time: 6.58s
Clean ACC: 7487/8000 = 0.935875, Loss: 0.27177560329437256
ASR: 4538/7193 = 0.630891


<Backdoor Training> Train Epoch: 66 	Loss: 0.016666, lr: 0.010000, Time: 6.52s
Clean ACC: 7492/8000 = 0.936500, Loss: 0.272792249917984
ASR: 4754/7193 = 0.660920


<Backdoor Training> Train Epoch: 67 	Loss: 0.004477, lr: 0.010000, Time: 6.68s
Clean ACC: 7477/8000 = 0.934625, Loss: 0.27500733733177185
ASR: 4932/7193 = 0.685667


<Backdoor Training> Train Epoch: 68 	Loss: 0.028016, lr: 0.010000, Time: 6.47s
Clean ACC: 7481/8000 = 0.935125, Loss: 0.27364471554756165
ASR: 4712/7193 = 0.655081


<Backdoor Training> Train Epoch: 69 	Loss: 0.016076, lr: 0.010000, Time: 6.64s
Clean ACC: 7478/8000 = 0.934750, Loss: 0.2740984857082367
ASR: 4783/7193 = 0.664952


<Backdoor Training> Train Epoch: 70 	Loss: 0.015419, lr: 0.010000, Time: 6.80s
Clean ACC: 7477/8000 = 0.934625, Loss: 0.2816219627857208
ASR: 4648/7193 = 0.646184


<Backdoor Training> Train Epoch: 71 	Loss: 0.003028, lr: 0.010000, Time: 6.67s
Clean ACC: 7490/8000 = 0.936250, Loss: 0.2807994782924652
ASR: 4827/7193 = 0.671069


<Backdoor Training> Train Epoch: 72 	Loss: 0.001281, lr: 0.010000, Time: 6.65s
Clean ACC: 7473/8000 = 0.934125, Loss: 0.2820945680141449
ASR: 4883/7193 = 0.678854


<Backdoor Training> Train Epoch: 73 	Loss: 0.070047, lr: 0.010000, Time: 6.43s
Clean ACC: 7471/8000 = 0.933875, Loss: 0.2813182473182678
ASR: 5179/7193 = 0.720006


<Backdoor Training> Train Epoch: 74 	Loss: 0.012135, lr: 0.010000, Time: 6.84s
Clean ACC: 7478/8000 = 0.934750, Loss: 0.28351277112960815
ASR: 4819/7193 = 0.669957


<Backdoor Training> Train Epoch: 75 	Loss: 0.001544, lr: 0.010000, Time: 6.60s
Clean ACC: 7479/8000 = 0.934875, Loss: 0.2809363305568695
ASR: 5062/7193 = 0.703740


<Backdoor Training> Train Epoch: 76 	Loss: 0.006814, lr: 0.001000, Time: 6.64s
Clean ACC: 7480/8000 = 0.935000, Loss: 0.28151655197143555
ASR: 4943/7193 = 0.687196


<Backdoor Training> Train Epoch: 77 	Loss: 0.002407, lr: 0.001000, Time: 6.72s
Clean ACC: 7484/8000 = 0.935500, Loss: 0.2773929834365845
ASR: 4962/7193 = 0.689837


<Backdoor Training> Train Epoch: 78 	Loss: 0.001723, lr: 0.001000, Time: 6.59s
Clean ACC: 7483/8000 = 0.935375, Loss: 0.2804218828678131
ASR: 4967/7193 = 0.690532


<Backdoor Training> Train Epoch: 79 	Loss: 0.025791, lr: 0.001000, Time: 6.54s
Clean ACC: 7488/8000 = 0.936000, Loss: 0.2777612507343292
ASR: 5053/7193 = 0.702489


<Backdoor Training> Train Epoch: 80 	Loss: 0.001237, lr: 0.001000, Time: 6.62s
Clean ACC: 7483/8000 = 0.935375, Loss: 0.2809469699859619
ASR: 5174/7193 = 0.719310


<Backdoor Training> Train Epoch: 81 	Loss: 0.020775, lr: 0.001000, Time: 6.43s
Clean ACC: 7495/8000 = 0.936875, Loss: 0.27887749671936035
ASR: 4944/7193 = 0.687335


<Backdoor Training> Train Epoch: 82 	Loss: 0.006698, lr: 0.001000, Time: 6.40s
Clean ACC: 7492/8000 = 0.936500, Loss: 0.2768738269805908
ASR: 4854/7193 = 0.674823


<Backdoor Training> Train Epoch: 83 	Loss: 0.009361, lr: 0.001000, Time: 6.38s
Clean ACC: 7490/8000 = 0.936250, Loss: 0.2783466875553131
ASR: 5099/7193 = 0.708884


<Backdoor Training> Train Epoch: 84 	Loss: 0.001151, lr: 0.001000, Time: 6.33s
Clean ACC: 7490/8000 = 0.936250, Loss: 0.279504656791687
ASR: 4636/7193 = 0.644516


<Backdoor Training> Train Epoch: 85 	Loss: 0.008815, lr: 0.001000, Time: 6.51s
Clean ACC: 7490/8000 = 0.936250, Loss: 0.2766633629798889
ASR: 5229/7193 = 0.726957


<Backdoor Training> Train Epoch: 86 	Loss: 0.002953, lr: 0.001000, Time: 6.54s
Clean ACC: 7497/8000 = 0.937125, Loss: 0.27650582790374756
ASR: 4942/7193 = 0.687057


<Backdoor Training> Train Epoch: 87 	Loss: 0.004898, lr: 0.001000, Time: 6.45s
Clean ACC: 7504/8000 = 0.938000, Loss: 0.2762773036956787
ASR: 5186/7193 = 0.720979


<Backdoor Training> Train Epoch: 88 	Loss: 0.007982, lr: 0.001000, Time: 6.51s
Clean ACC: 7501/8000 = 0.937625, Loss: 0.279109925031662
ASR: 4842/7193 = 0.673154


<Backdoor Training> Train Epoch: 89 	Loss: 0.014054, lr: 0.001000, Time: 6.59s
Clean ACC: 7496/8000 = 0.937000, Loss: 0.2772735357284546
ASR: 5005/7193 = 0.695815


<Backdoor Training> Train Epoch: 90 	Loss: 0.001379, lr: 0.001000, Time: 6.52s
Clean ACC: 7495/8000 = 0.936875, Loss: 0.27759692072868347
ASR: 5237/7193 = 0.728069


<Backdoor Training> Train Epoch: 91 	Loss: 0.003610, lr: 0.001000, Time: 6.48s
Clean ACC: 7494/8000 = 0.936750, Loss: 0.2767942547798157
ASR: 5133/7193 = 0.713610


<Backdoor Training> Train Epoch: 92 	Loss: 0.000794, lr: 0.001000, Time: 6.54s
Clean ACC: 7501/8000 = 0.937625, Loss: 0.2764977812767029
ASR: 5163/7193 = 0.717781


<Backdoor Training> Train Epoch: 93 	Loss: 0.000757, lr: 0.001000, Time: 6.44s
Clean ACC: 7498/8000 = 0.937250, Loss: 0.277911901473999
ASR: 5088/7193 = 0.707354


<Backdoor Training> Train Epoch: 94 	Loss: 0.001427, lr: 0.001000, Time: 6.40s
Clean ACC: 7496/8000 = 0.937000, Loss: 0.2748537063598633
ASR: 4940/7193 = 0.686779


<Backdoor Training> Train Epoch: 95 	Loss: 0.003508, lr: 0.001000, Time: 6.38s
Clean ACC: 7497/8000 = 0.937125, Loss: 0.27574652433395386
ASR: 5106/7193 = 0.709857


<Backdoor Training> Train Epoch: 96 	Loss: 0.000935, lr: 0.001000, Time: 6.38s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.2779170274734497
ASR: 4977/7193 = 0.691923


<Backdoor Training> Train Epoch: 97 	Loss: 0.000307, lr: 0.001000, Time: 6.55s
Clean ACC: 7490/8000 = 0.936250, Loss: 0.27539223432540894
ASR: 4780/7193 = 0.664535


<Backdoor Training> Train Epoch: 98 	Loss: 0.007492, lr: 0.001000, Time: 6.51s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.27770981192588806
ASR: 4805/7193 = 0.668011


<Backdoor Training> Train Epoch: 99 	Loss: 0.001592, lr: 0.001000, Time: 6.46s
Clean ACC: 7500/8000 = 0.937500, Loss: 0.27585846185684204
ASR: 4872/7193 = 0.677325


<Backdoor Training> Train Epoch: 100 	Loss: 0.011953, lr: 0.001000, Time: 6.33s
Clean ACC: 7506/8000 = 0.938250, Loss: 0.27420318126678467
ASR: 5089/7193 = 0.707493


Testing the backdoor model...
Evaluating model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 7506/8000 = 0.938250, Loss: 0.27420318126678467
ASR: 5089/7193 = 0.707493

Visualizing the model's latent space...
Using method: pca
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
Saved figure at assets/pca_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Using method: tsne
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
Saved figure at assets/tsne_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Using method: umap
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
Saved figure at assets/umap_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Using method: oracle
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
SVM Accuracy: 1.0
Saved figure at assets/oracle_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Using method: mean_diff
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
Mean L2 distance between poison and clean: 4.536364555358887
Saved figure at assets/mean_diff_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Using method: SS
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
torch.Size([5000])
Saved figure at assets/SS_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Using method: isomap
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
Saved figure at assets/isomap_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Using method: lle
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
Saved figure at assets/lle_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Using method: kpca
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
Saved figure at assets/kpca_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Using method: spectral
Visualizing model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27420738339424133
ASR: 5089/7193 = 0.707493

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.644171, poison_dis: 5.138668
Saved figure at assets/spectral_cifar10_SIG_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/none
No trigger mask found! By default masking all black pixels...
Evaluating model 'poisoned_train_set/cifar10/SIG_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 93.82500457763672
asr: 70.74933624267578
target label: tensor([0], device='cuda:0')
start_index: 10
TPR: 9.71
FPR: 6.79
AUC: 0.6137
f1 score: 0.1667381974248927
Elapsed time: 18.73s
Experiment for cifar10 with SIG completed.
