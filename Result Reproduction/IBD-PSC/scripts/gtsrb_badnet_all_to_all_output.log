Creating poisoned training set for badnet_all_to_all on gtsrb...
[target class : 2]
Poisoned set directory 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/imgs
Will save to 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt'.
Model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' already exists!
<Backdoor Training> Train Epoch: 1 	Loss: 0.159216, lr: 0.010000, Time: 8.23s
Clean ACC: 9422/10630 = 0.886359, Loss: 0.39793339371681213
ASR: 122/10630 = 0.011477


<Backdoor Training> Train Epoch: 2 	Loss: 0.088507, lr: 0.010000, Time: 3.65s
Clean ACC: 9862/10630 = 0.927752, Loss: 0.2687062919139862
ASR: 102/10630 = 0.009595


<Backdoor Training> Train Epoch: 3 	Loss: 0.029045, lr: 0.010000, Time: 3.35s
Clean ACC: 10037/10630 = 0.944214, Loss: 0.19029437005519867
ASR: 86/10630 = 0.008090


<Backdoor Training> Train Epoch: 4 	Loss: 0.076835, lr: 0.010000, Time: 3.49s
Clean ACC: 9984/10630 = 0.939229, Loss: 0.21917755901813507
ASR: 67/10630 = 0.006303


<Backdoor Training> Train Epoch: 5 	Loss: 0.052387, lr: 0.010000, Time: 3.53s
Clean ACC: 10126/10630 = 0.952587, Loss: 0.17157284915447235
ASR: 72/10630 = 0.006773


<Backdoor Training> Train Epoch: 6 	Loss: 0.032732, lr: 0.010000, Time: 3.54s
Clean ACC: 10040/10630 = 0.944497, Loss: 0.2184426337480545
ASR: 82/10630 = 0.007714


<Backdoor Training> Train Epoch: 7 	Loss: 0.010929, lr: 0.010000, Time: 3.56s
Clean ACC: 10140/10630 = 0.953904, Loss: 0.15848714113235474
ASR: 70/10630 = 0.006585


<Backdoor Training> Train Epoch: 8 	Loss: 0.094557, lr: 0.010000, Time: 3.52s
Clean ACC: 10189/10630 = 0.958514, Loss: 0.15152955055236816
ASR: 72/10630 = 0.006773


<Backdoor Training> Train Epoch: 9 	Loss: 0.036147, lr: 0.010000, Time: 3.54s
Clean ACC: 10199/10630 = 0.959454, Loss: 0.14812180399894714
ASR: 72/10630 = 0.006773


<Backdoor Training> Train Epoch: 10 	Loss: 0.028188, lr: 0.010000, Time: 3.55s
Clean ACC: 10149/10630 = 0.954751, Loss: 0.16004599630832672
ASR: 95/10630 = 0.008937


<Backdoor Training> Train Epoch: 11 	Loss: 0.024229, lr: 0.010000, Time: 3.52s
Clean ACC: 10141/10630 = 0.953998, Loss: 0.17199261486530304
ASR: 62/10630 = 0.005833


<Backdoor Training> Train Epoch: 12 	Loss: 0.013241, lr: 0.010000, Time: 3.56s
Clean ACC: 10105/10630 = 0.950611, Loss: 0.18244369328022003
ASR: 68/10630 = 0.006397


<Backdoor Training> Train Epoch: 13 	Loss: 0.051101, lr: 0.010000, Time: 3.57s
Clean ACC: 10131/10630 = 0.953057, Loss: 0.17107383906841278
ASR: 115/10630 = 0.010818


<Backdoor Training> Train Epoch: 14 	Loss: 0.291371, lr: 0.010000, Time: 3.49s
Clean ACC: 10170/10630 = 0.956726, Loss: 0.1634090095758438
ASR: 409/10630 = 0.038476


<Backdoor Training> Train Epoch: 15 	Loss: 0.004312, lr: 0.010000, Time: 3.44s
Clean ACC: 10241/10630 = 0.963405, Loss: 0.1242087185382843
ASR: 303/10630 = 0.028504


<Backdoor Training> Train Epoch: 16 	Loss: 0.072285, lr: 0.010000, Time: 3.49s
Clean ACC: 10189/10630 = 0.958514, Loss: 0.14344356954097748
ASR: 608/10630 = 0.057197


<Backdoor Training> Train Epoch: 17 	Loss: 0.023679, lr: 0.010000, Time: 3.55s
Clean ACC: 10203/10630 = 0.959831, Loss: 0.14406996965408325
ASR: 804/10630 = 0.075635


<Backdoor Training> Train Epoch: 18 	Loss: 0.027267, lr: 0.010000, Time: 3.62s
Clean ACC: 10068/10630 = 0.947131, Loss: 0.1901235282421112
ASR: 747/10630 = 0.070273


<Backdoor Training> Train Epoch: 19 	Loss: 0.006651, lr: 0.010000, Time: 3.49s
Clean ACC: 10159/10630 = 0.955691, Loss: 0.16513800621032715
ASR: 747/10630 = 0.070273


<Backdoor Training> Train Epoch: 20 	Loss: 0.019303, lr: 0.010000, Time: 3.55s
Clean ACC: 10254/10630 = 0.964628, Loss: 0.1315622180700302
ASR: 828/10630 = 0.077893


<Backdoor Training> Train Epoch: 21 	Loss: 0.017455, lr: 0.010000, Time: 3.53s
Clean ACC: 10231/10630 = 0.962465, Loss: 0.1280076950788498
ASR: 1434/10630 = 0.134901


<Backdoor Training> Train Epoch: 22 	Loss: 0.064968, lr: 0.010000, Time: 3.56s
Clean ACC: 10210/10630 = 0.960489, Loss: 0.1476210653781891
ASR: 956/10630 = 0.089934


<Backdoor Training> Train Epoch: 23 	Loss: 0.018020, lr: 0.010000, Time: 3.49s
Clean ACC: 10184/10630 = 0.958043, Loss: 0.15322066843509674
ASR: 1806/10630 = 0.169897


<Backdoor Training> Train Epoch: 24 	Loss: 0.019012, lr: 0.010000, Time: 3.53s
Clean ACC: 10161/10630 = 0.955880, Loss: 0.15302687883377075
ASR: 2245/10630 = 0.211195


<Backdoor Training> Train Epoch: 25 	Loss: 0.005075, lr: 0.010000, Time: 3.46s
Clean ACC: 10227/10630 = 0.962088, Loss: 0.13639788329601288
ASR: 2114/10630 = 0.198871


<Backdoor Training> Train Epoch: 26 	Loss: 0.001132, lr: 0.010000, Time: 3.54s
Clean ACC: 10237/10630 = 0.963029, Loss: 0.13114427030086517
ASR: 2216/10630 = 0.208467


<Backdoor Training> Train Epoch: 27 	Loss: 0.024089, lr: 0.010000, Time: 3.49s
Clean ACC: 10231/10630 = 0.962465, Loss: 0.13905715942382812
ASR: 2226/10630 = 0.209407


<Backdoor Training> Train Epoch: 28 	Loss: 0.002755, lr: 0.010000, Time: 3.55s
Clean ACC: 10218/10630 = 0.961242, Loss: 0.14196355640888214
ASR: 2341/10630 = 0.220226


<Backdoor Training> Train Epoch: 29 	Loss: 0.097863, lr: 0.010000, Time: 3.56s
Clean ACC: 10240/10630 = 0.963311, Loss: 0.1331794112920761
ASR: 2601/10630 = 0.244685


<Backdoor Training> Train Epoch: 30 	Loss: 0.020260, lr: 0.010000, Time: 3.56s
Clean ACC: 10221/10630 = 0.961524, Loss: 0.1380472332239151
ASR: 2438/10630 = 0.229351


<Backdoor Training> Train Epoch: 31 	Loss: 0.003490, lr: 0.001000, Time: 3.56s
Clean ACC: 10230/10630 = 0.962371, Loss: 0.134566068649292
ASR: 2751/10630 = 0.258796


<Backdoor Training> Train Epoch: 32 	Loss: 0.002659, lr: 0.001000, Time: 3.54s
Clean ACC: 10259/10630 = 0.965099, Loss: 0.12642443180084229
ASR: 2849/10630 = 0.268015


<Backdoor Training> Train Epoch: 33 	Loss: 0.002399, lr: 0.001000, Time: 3.53s
Clean ACC: 10236/10630 = 0.962935, Loss: 0.13024701178073883
ASR: 2724/10630 = 0.256256


<Backdoor Training> Train Epoch: 34 	Loss: 0.001087, lr: 0.001000, Time: 3.49s
Clean ACC: 10260/10630 = 0.965193, Loss: 0.12478999048471451
ASR: 2994/10630 = 0.281656


<Backdoor Training> Train Epoch: 35 	Loss: 0.001990, lr: 0.001000, Time: 3.58s
Clean ACC: 10265/10630 = 0.965663, Loss: 0.12650735676288605
ASR: 2923/10630 = 0.274976


<Backdoor Training> Train Epoch: 36 	Loss: 0.000671, lr: 0.001000, Time: 3.55s
Clean ACC: 10268/10630 = 0.965945, Loss: 0.1231544092297554
ASR: 2874/10630 = 0.270367


<Backdoor Training> Train Epoch: 37 	Loss: 0.003978, lr: 0.001000, Time: 3.46s
Clean ACC: 10264/10630 = 0.965569, Loss: 0.123116135597229
ASR: 2945/10630 = 0.277046


<Backdoor Training> Train Epoch: 38 	Loss: 0.008136, lr: 0.001000, Time: 3.57s
Clean ACC: 10259/10630 = 0.965099, Loss: 0.1219915822148323
ASR: 2914/10630 = 0.274130


<Backdoor Training> Train Epoch: 39 	Loss: 0.002623, lr: 0.001000, Time: 3.43s
Clean ACC: 10266/10630 = 0.965757, Loss: 0.12000929564237595
ASR: 2793/10630 = 0.262747


<Backdoor Training> Train Epoch: 40 	Loss: 0.002141, lr: 0.001000, Time: 3.53s
Clean ACC: 10268/10630 = 0.965945, Loss: 0.12120023369789124
ASR: 2867/10630 = 0.269708


<Backdoor Training> Train Epoch: 41 	Loss: 0.005289, lr: 0.001000, Time: 3.49s
Clean ACC: 10258/10630 = 0.965005, Loss: 0.12298549711704254
ASR: 2810/10630 = 0.264346


<Backdoor Training> Train Epoch: 42 	Loss: 0.012290, lr: 0.001000, Time: 3.57s
Clean ACC: 10266/10630 = 0.965757, Loss: 0.12110398709774017
ASR: 2873/10630 = 0.270273


<Backdoor Training> Train Epoch: 43 	Loss: 0.001177, lr: 0.001000, Time: 3.40s
Clean ACC: 10268/10630 = 0.965945, Loss: 0.11878520995378494
ASR: 2830/10630 = 0.266228


<Backdoor Training> Train Epoch: 44 	Loss: 0.002249, lr: 0.001000, Time: 3.52s
Clean ACC: 10272/10630 = 0.966322, Loss: 0.11859915405511856
ASR: 2666/10630 = 0.250800


<Backdoor Training> Train Epoch: 45 	Loss: 0.000935, lr: 0.001000, Time: 3.50s
Clean ACC: 10277/10630 = 0.966792, Loss: 0.1175195649266243
ASR: 2841/10630 = 0.267262


<Backdoor Training> Train Epoch: 46 	Loss: 0.050918, lr: 0.001000, Time: 3.47s
Clean ACC: 10265/10630 = 0.965663, Loss: 0.11998610943555832
ASR: 2686/10630 = 0.252681


<Backdoor Training> Train Epoch: 47 	Loss: 0.002351, lr: 0.001000, Time: 3.54s
Clean ACC: 10263/10630 = 0.965475, Loss: 0.12155281007289886
ASR: 2806/10630 = 0.263970


<Backdoor Training> Train Epoch: 48 	Loss: 0.003502, lr: 0.001000, Time: 3.50s
Clean ACC: 10273/10630 = 0.966416, Loss: 0.12022418528795242
ASR: 2726/10630 = 0.256444


<Backdoor Training> Train Epoch: 49 	Loss: 0.000326, lr: 0.001000, Time: 3.57s
Clean ACC: 10274/10630 = 0.966510, Loss: 0.12020458281040192
ASR: 2658/10630 = 0.250047


<Backdoor Training> Train Epoch: 50 	Loss: 0.122393, lr: 0.001000, Time: 3.55s
Clean ACC: 10277/10630 = 0.966792, Loss: 0.11710277944803238
ASR: 2556/10630 = 0.240452


<Backdoor Training> Train Epoch: 51 	Loss: 0.000397, lr: 0.001000, Time: 3.52s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.11608083546161652
ASR: 2750/10630 = 0.258702


<Backdoor Training> Train Epoch: 52 	Loss: 0.001653, lr: 0.001000, Time: 3.48s
Clean ACC: 10279/10630 = 0.966980, Loss: 0.11590984463691711
ASR: 2666/10630 = 0.250800


<Backdoor Training> Train Epoch: 53 	Loss: 0.006183, lr: 0.001000, Time: 3.57s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.1160784363746643
ASR: 2633/10630 = 0.247695


<Backdoor Training> Train Epoch: 54 	Loss: 0.000335, lr: 0.001000, Time: 3.45s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11679669469594955
ASR: 2716/10630 = 0.255503


<Backdoor Training> Train Epoch: 55 	Loss: 0.000502, lr: 0.001000, Time: 3.55s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.11523900926113129
ASR: 2774/10630 = 0.260960


<Backdoor Training> Train Epoch: 56 	Loss: 0.002947, lr: 0.001000, Time: 3.49s
Clean ACC: 10281/10630 = 0.967168, Loss: 0.11861253529787064
ASR: 2657/10630 = 0.249953


<Backdoor Training> Train Epoch: 57 	Loss: 0.001444, lr: 0.001000, Time: 3.47s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.11648823320865631
ASR: 2728/10630 = 0.256632


<Backdoor Training> Train Epoch: 58 	Loss: 0.000950, lr: 0.001000, Time: 3.49s
Clean ACC: 10279/10630 = 0.966980, Loss: 0.11649323999881744
ASR: 2616/10630 = 0.246096


<Backdoor Training> Train Epoch: 59 	Loss: 0.005155, lr: 0.001000, Time: 3.51s
Clean ACC: 10277/10630 = 0.966792, Loss: 0.11642757058143616
ASR: 2632/10630 = 0.247601


<Backdoor Training> Train Epoch: 60 	Loss: 0.000762, lr: 0.001000, Time: 3.45s
Clean ACC: 10279/10630 = 0.966980, Loss: 0.11707297712564468
ASR: 2661/10630 = 0.250329


<Backdoor Training> Train Epoch: 61 	Loss: 0.015773, lr: 0.000100, Time: 3.50s
Clean ACC: 10277/10630 = 0.966792, Loss: 0.11905953288078308
ASR: 2710/10630 = 0.254939


<Backdoor Training> Train Epoch: 62 	Loss: 0.004399, lr: 0.000100, Time: 3.56s
Clean ACC: 10266/10630 = 0.965757, Loss: 0.11927753686904907
ASR: 2644/10630 = 0.248730


<Backdoor Training> Train Epoch: 63 	Loss: 0.006690, lr: 0.000100, Time: 3.38s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.11622293293476105
ASR: 2694/10630 = 0.253434


<Backdoor Training> Train Epoch: 64 	Loss: 0.001191, lr: 0.000100, Time: 3.53s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.11560013145208359
ASR: 2631/10630 = 0.247507


<Backdoor Training> Train Epoch: 65 	Loss: 0.082484, lr: 0.000100, Time: 3.49s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11695799231529236
ASR: 2602/10630 = 0.244779


<Backdoor Training> Train Epoch: 66 	Loss: 0.000591, lr: 0.000100, Time: 3.59s
Clean ACC: 10277/10630 = 0.966792, Loss: 0.11626850813627243
ASR: 2669/10630 = 0.251082


<Backdoor Training> Train Epoch: 67 	Loss: 0.006109, lr: 0.000100, Time: 3.56s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.11684417724609375
ASR: 2631/10630 = 0.247507


<Backdoor Training> Train Epoch: 68 	Loss: 0.009381, lr: 0.000100, Time: 3.46s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.11562765389680862
ASR: 2690/10630 = 0.253057


<Backdoor Training> Train Epoch: 69 	Loss: 0.002489, lr: 0.000100, Time: 3.58s
Clean ACC: 10276/10630 = 0.966698, Loss: 0.11706225574016571
ASR: 2583/10630 = 0.242992


<Backdoor Training> Train Epoch: 70 	Loss: 0.003915, lr: 0.000100, Time: 3.55s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.11429234594106674
ASR: 2645/10630 = 0.248824


<Backdoor Training> Train Epoch: 71 	Loss: 0.000390, lr: 0.000100, Time: 3.58s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11598144471645355
ASR: 2614/10630 = 0.245908


<Backdoor Training> Train Epoch: 72 	Loss: 0.000680, lr: 0.000100, Time: 3.48s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.11498948931694031
ASR: 2640/10630 = 0.248354


<Backdoor Training> Train Epoch: 73 	Loss: 0.002793, lr: 0.000100, Time: 3.55s
Clean ACC: 10282/10630 = 0.967262, Loss: 0.11699997633695602
ASR: 2598/10630 = 0.244403


<Backdoor Training> Train Epoch: 74 	Loss: 0.002721, lr: 0.000100, Time: 3.44s
Clean ACC: 10276/10630 = 0.966698, Loss: 0.11571124941110611
ASR: 2603/10630 = 0.244873


<Backdoor Training> Train Epoch: 75 	Loss: 0.000493, lr: 0.000100, Time: 3.53s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.11330986768007278
ASR: 2637/10630 = 0.248071


<Backdoor Training> Train Epoch: 76 	Loss: 0.000516, lr: 0.000100, Time: 3.53s
Clean ACC: 10277/10630 = 0.966792, Loss: 0.11491930484771729
ASR: 2602/10630 = 0.244779


<Backdoor Training> Train Epoch: 77 	Loss: 0.000813, lr: 0.000100, Time: 3.55s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.1145990714430809
ASR: 2550/10630 = 0.239887


<Backdoor Training> Train Epoch: 78 	Loss: 0.003273, lr: 0.000100, Time: 3.54s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.11463126540184021
ASR: 2633/10630 = 0.247695


<Backdoor Training> Train Epoch: 79 	Loss: 0.000512, lr: 0.000100, Time: 3.59s
Clean ACC: 10292/10630 = 0.968203, Loss: 0.1138964369893074
ASR: 2637/10630 = 0.248071


<Backdoor Training> Train Epoch: 80 	Loss: 0.002902, lr: 0.000100, Time: 3.64s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.11486828327178955
ASR: 2572/10630 = 0.241957


<Backdoor Training> Train Epoch: 81 	Loss: 0.003778, lr: 0.000100, Time: 3.49s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.1122160404920578
ASR: 2630/10630 = 0.247413


<Backdoor Training> Train Epoch: 82 	Loss: 0.000629, lr: 0.000100, Time: 3.64s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.11414952576160431
ASR: 2709/10630 = 0.254845


<Backdoor Training> Train Epoch: 83 	Loss: 0.006037, lr: 0.000100, Time: 3.58s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11381284892559052
ASR: 2631/10630 = 0.247507


<Backdoor Training> Train Epoch: 84 	Loss: 0.003025, lr: 0.000100, Time: 3.44s
Clean ACC: 10275/10630 = 0.966604, Loss: 0.11787551641464233
ASR: 2528/10630 = 0.237817


<Backdoor Training> Train Epoch: 85 	Loss: 0.001065, lr: 0.000100, Time: 3.47s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11754254251718521
ASR: 2666/10630 = 0.250800


<Backdoor Training> Train Epoch: 86 	Loss: 0.001011, lr: 0.000100, Time: 3.59s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.11271769553422928
ASR: 2645/10630 = 0.248824


<Backdoor Training> Train Epoch: 87 	Loss: 0.000883, lr: 0.000100, Time: 3.54s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.11589325964450836
ASR: 2580/10630 = 0.242709


<Backdoor Training> Train Epoch: 88 	Loss: 0.005536, lr: 0.000100, Time: 3.53s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.11609891057014465
ASR: 2541/10630 = 0.239040


<Backdoor Training> Train Epoch: 89 	Loss: 0.000527, lr: 0.000100, Time: 3.53s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.1146279126405716
ASR: 2666/10630 = 0.250800


<Backdoor Training> Train Epoch: 90 	Loss: 0.002424, lr: 0.000100, Time: 3.53s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.11396894603967667
ASR: 2616/10630 = 0.246096


<Backdoor Training> Train Epoch: 91 	Loss: 0.066582, lr: 0.000100, Time: 3.49s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11763499677181244
ASR: 2596/10630 = 0.244214


<Backdoor Training> Train Epoch: 92 	Loss: 0.005778, lr: 0.000100, Time: 3.48s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.11627652496099472
ASR: 2504/10630 = 0.235560


<Backdoor Training> Train Epoch: 93 	Loss: 0.005891, lr: 0.000100, Time: 3.55s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.11415868252515793
ASR: 2632/10630 = 0.247601


<Backdoor Training> Train Epoch: 94 	Loss: 0.001130, lr: 0.000100, Time: 3.54s
Clean ACC: 10282/10630 = 0.967262, Loss: 0.11578778177499771
ASR: 2539/10630 = 0.238852


<Backdoor Training> Train Epoch: 95 	Loss: 0.000901, lr: 0.000100, Time: 3.51s
Clean ACC: 10281/10630 = 0.967168, Loss: 0.11516159772872925
ASR: 2626/10630 = 0.247037


<Backdoor Training> Train Epoch: 96 	Loss: 0.004816, lr: 0.000100, Time: 3.60s
Clean ACC: 10282/10630 = 0.967262, Loss: 0.11979309469461441
ASR: 2578/10630 = 0.242521


<Backdoor Training> Train Epoch: 97 	Loss: 0.000644, lr: 0.000100, Time: 3.62s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.11441685259342194
ASR: 2619/10630 = 0.246378


<Backdoor Training> Train Epoch: 98 	Loss: 0.002636, lr: 0.000100, Time: 3.53s
Clean ACC: 10281/10630 = 0.967168, Loss: 0.11376682668924332
ASR: 2486/10630 = 0.233866


<Backdoor Training> Train Epoch: 99 	Loss: 0.001135, lr: 0.000100, Time: 3.52s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.1163187175989151
ASR: 2618/10630 = 0.246284


<Backdoor Training> Train Epoch: 100 	Loss: 0.009884, lr: 0.000100, Time: 3.52s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.11545515060424805
ASR: 2533/10630 = 0.238288


Testing the backdoor model...
Evaluating model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 10285/10630 = 0.967545, Loss: 0.11545515060424805
ASR: 2533/10630 = 0.238288

Visualizing the model's latent space...
Using method: pca
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
Saved figure at assets/pca_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: tsne
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
Saved figure at assets/tsne_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: umap
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
Saved figure at assets/umap_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: oracle
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
SVM Accuracy: 1.0
Saved figure at assets/oracle_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: mean_diff
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
Mean L2 distance between poison and clean: 12.960942268371582
Saved figure at assets/mean_diff_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: SS
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
torch.Size([1495])
Saved figure at assets/SS_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: isomap
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
Saved figure at assets/isomap_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: lle
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
Saved figure at assets/lle_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: kpca
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
Saved figure at assets/kpca_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: spectral
Visualizing model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10284/10630 = 0.967451, Loss: 0.11545570194721222
ASR: 155/10332 = 0.015002

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 6.769262, poison_dis: 14.246153
Saved figure at assets/spectral_gtsrb_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/badnet_patch_32.png
trigger_mask_path: ./triggers/mask_badnet_patch_32.png
Evaluating model 'poisoned_train_set/gtsrb/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 96.75447082519531
asr: 23.936471939086914
target label: tensor([2], device='cuda:0')
start_index: 11
TPR: 2.94
FPR: 6.54
AUC: 0.3280
f1 score: 0.05378931087815776
Elapsed time: 18.30s
Experiment for gtsrb with badnet_all_to_all completed.
