Creating poisoned training set for trojan on gtsrb...
[target class : 2]
Poisoned set directory 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/imgs
Will save to 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt'.
Model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' already exists!
<Backdoor Training> Train Epoch: 1 	Loss: 0.254352, lr: 0.010000, Time: 7.37s
Clean ACC: 8780/10630 = 0.825964, Loss: 0.7552739381790161
ASR: 8138/10005 = 0.813393


<Backdoor Training> Train Epoch: 2 	Loss: 0.010704, lr: 0.010000, Time: 3.38s
Clean ACC: 10025/10630 = 0.943086, Loss: 0.19787092506885529
ASR: 9889/10005 = 0.988406


<Backdoor Training> Train Epoch: 3 	Loss: 0.025936, lr: 0.010000, Time: 3.54s
Clean ACC: 9941/10630 = 0.935183, Loss: 0.223189577460289
ASR: 10004/10005 = 0.999900


<Backdoor Training> Train Epoch: 4 	Loss: 0.006308, lr: 0.010000, Time: 3.55s
Clean ACC: 10164/10630 = 0.956162, Loss: 0.15237970650196075
ASR: 9971/10005 = 0.996602


<Backdoor Training> Train Epoch: 5 	Loss: 0.014307, lr: 0.010000, Time: 3.61s
Clean ACC: 10176/10630 = 0.957291, Loss: 0.14165107905864716
ASR: 9928/10005 = 0.992304


<Backdoor Training> Train Epoch: 6 	Loss: 0.009374, lr: 0.010000, Time: 3.51s
Clean ACC: 10164/10630 = 0.956162, Loss: 0.1539107859134674
ASR: 9997/10005 = 0.999200


<Backdoor Training> Train Epoch: 7 	Loss: 0.010062, lr: 0.010000, Time: 3.55s
Clean ACC: 10197/10630 = 0.959266, Loss: 0.13698455691337585
ASR: 9996/10005 = 0.999100


<Backdoor Training> Train Epoch: 8 	Loss: 0.008180, lr: 0.010000, Time: 3.49s
Clean ACC: 10214/10630 = 0.960865, Loss: 0.1293429136276245
ASR: 9988/10005 = 0.998301


<Backdoor Training> Train Epoch: 9 	Loss: 0.004583, lr: 0.010000, Time: 3.53s
Clean ACC: 10251/10630 = 0.964346, Loss: 0.12184759229421616
ASR: 9990/10005 = 0.998501


<Backdoor Training> Train Epoch: 10 	Loss: 0.015466, lr: 0.010000, Time: 3.54s
Clean ACC: 10233/10630 = 0.962653, Loss: 0.11481650173664093
ASR: 9969/10005 = 0.996402


<Backdoor Training> Train Epoch: 11 	Loss: 0.118651, lr: 0.010000, Time: 3.57s
Clean ACC: 10194/10630 = 0.958984, Loss: 0.1543964147567749
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 12 	Loss: 0.017925, lr: 0.010000, Time: 3.56s
Clean ACC: 10182/10630 = 0.957855, Loss: 0.14175379276275635
ASR: 10003/10005 = 0.999800


<Backdoor Training> Train Epoch: 13 	Loss: 0.006042, lr: 0.010000, Time: 3.51s
Clean ACC: 10237/10630 = 0.963029, Loss: 0.13025552034378052
ASR: 10001/10005 = 0.999600


<Backdoor Training> Train Epoch: 14 	Loss: 0.000312, lr: 0.010000, Time: 3.61s
Clean ACC: 10259/10630 = 0.965099, Loss: 0.12238127738237381
ASR: 9997/10005 = 0.999200


<Backdoor Training> Train Epoch: 15 	Loss: 0.001977, lr: 0.010000, Time: 3.52s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.11229795962572098
ASR: 10001/10005 = 0.999600


<Backdoor Training> Train Epoch: 16 	Loss: 0.005586, lr: 0.010000, Time: 3.50s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.11489278078079224
ASR: 10004/10005 = 0.999900


<Backdoor Training> Train Epoch: 17 	Loss: 0.001458, lr: 0.010000, Time: 3.42s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.10929711908102036
ASR: 10000/10005 = 0.999500


<Backdoor Training> Train Epoch: 18 	Loss: 0.000921, lr: 0.010000, Time: 3.54s
Clean ACC: 10273/10630 = 0.966416, Loss: 0.11529010534286499
ASR: 10004/10005 = 0.999900


<Backdoor Training> Train Epoch: 19 	Loss: 0.000262, lr: 0.010000, Time: 3.50s
Clean ACC: 10293/10630 = 0.968297, Loss: 0.10698547214269638
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 20 	Loss: 0.008139, lr: 0.010000, Time: 3.58s
Clean ACC: 10298/10630 = 0.968768, Loss: 0.1067197173833847
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 21 	Loss: 0.000754, lr: 0.010000, Time: 3.44s
Clean ACC: 10293/10630 = 0.968297, Loss: 0.10514727234840393
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 22 	Loss: 0.000928, lr: 0.010000, Time: 3.49s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.10516208410263062
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 23 	Loss: 0.001409, lr: 0.010000, Time: 3.56s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.10537692904472351
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 24 	Loss: 0.001698, lr: 0.010000, Time: 3.46s
Clean ACC: 10308/10630 = 0.969708, Loss: 0.10566854476928711
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 25 	Loss: 0.001046, lr: 0.010000, Time: 3.37s
Clean ACC: 10309/10630 = 0.969802, Loss: 0.10118678212165833
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 26 	Loss: 0.000274, lr: 0.010000, Time: 3.53s
Clean ACC: 10325/10630 = 0.971308, Loss: 0.1000598892569542
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 27 	Loss: 0.011775, lr: 0.010000, Time: 3.59s
Clean ACC: 10306/10630 = 0.969520, Loss: 0.10037331283092499
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 28 	Loss: 0.006136, lr: 0.010000, Time: 3.50s
Clean ACC: 10316/10630 = 0.970461, Loss: 0.09799476712942123
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 29 	Loss: 0.001658, lr: 0.010000, Time: 3.41s
Clean ACC: 10310/10630 = 0.969897, Loss: 0.09821777790784836
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 30 	Loss: 0.000465, lr: 0.010000, Time: 3.50s
Clean ACC: 10311/10630 = 0.969991, Loss: 0.09766621887683868
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 31 	Loss: 0.000906, lr: 0.001000, Time: 3.50s
Clean ACC: 10310/10630 = 0.969897, Loss: 0.09884265810251236
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 32 	Loss: 0.000209, lr: 0.001000, Time: 3.52s
Clean ACC: 10317/10630 = 0.970555, Loss: 0.09792878478765488
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 33 	Loss: 0.000926, lr: 0.001000, Time: 3.41s
Clean ACC: 10308/10630 = 0.969708, Loss: 0.09649141877889633
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 34 	Loss: 0.005718, lr: 0.001000, Time: 3.46s
Clean ACC: 10319/10630 = 0.970743, Loss: 0.097783662378788
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 35 	Loss: 0.003058, lr: 0.001000, Time: 3.52s
Clean ACC: 10312/10630 = 0.970085, Loss: 0.09834546595811844
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 36 	Loss: 0.001360, lr: 0.001000, Time: 3.50s
Clean ACC: 10317/10630 = 0.970555, Loss: 0.09660806506872177
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 37 	Loss: 0.000364, lr: 0.001000, Time: 3.48s
Clean ACC: 10314/10630 = 0.970273, Loss: 0.09920406341552734
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 38 	Loss: 0.016253, lr: 0.001000, Time: 3.42s
Clean ACC: 10314/10630 = 0.970273, Loss: 0.09923797845840454
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 39 	Loss: 0.002588, lr: 0.001000, Time: 3.66s
Clean ACC: 10300/10630 = 0.968956, Loss: 0.09760613739490509
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 40 	Loss: 0.000410, lr: 0.001000, Time: 3.76s
Clean ACC: 10313/10630 = 0.970179, Loss: 0.09707396477460861
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 41 	Loss: 0.000886, lr: 0.001000, Time: 3.72s
Clean ACC: 10315/10630 = 0.970367, Loss: 0.09804195165634155
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 42 	Loss: 0.000228, lr: 0.001000, Time: 3.80s
Clean ACC: 10311/10630 = 0.969991, Loss: 0.09888897091150284
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 43 	Loss: 0.008095, lr: 0.001000, Time: 3.76s
Clean ACC: 10328/10630 = 0.971590, Loss: 0.09517177939414978
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 44 	Loss: 0.000212, lr: 0.001000, Time: 3.66s
Clean ACC: 10324/10630 = 0.971214, Loss: 0.09537414461374283
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 45 	Loss: 0.000107, lr: 0.001000, Time: 3.75s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09737521409988403
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 46 	Loss: 0.002226, lr: 0.001000, Time: 3.79s
Clean ACC: 10308/10630 = 0.969708, Loss: 0.0974527895450592
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 47 	Loss: 0.000677, lr: 0.001000, Time: 3.78s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09626840054988861
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 48 	Loss: 0.001292, lr: 0.001000, Time: 3.69s
Clean ACC: 10330/10630 = 0.971778, Loss: 0.09582900255918503
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 49 	Loss: 0.001321, lr: 0.001000, Time: 3.71s
Clean ACC: 10308/10630 = 0.969708, Loss: 0.09653837233781815
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 50 	Loss: 0.000353, lr: 0.001000, Time: 3.69s
Clean ACC: 10318/10630 = 0.970649, Loss: 0.09843574464321136
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 51 	Loss: 0.003443, lr: 0.001000, Time: 3.71s
Clean ACC: 10320/10630 = 0.970837, Loss: 0.09440556913614273
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 52 	Loss: 0.001721, lr: 0.001000, Time: 3.67s
Clean ACC: 10324/10630 = 0.971214, Loss: 0.0946546420454979
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 53 	Loss: 0.007859, lr: 0.001000, Time: 3.52s
Clean ACC: 10315/10630 = 0.970367, Loss: 0.09688510745763779
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 54 	Loss: 0.000706, lr: 0.001000, Time: 3.51s
Clean ACC: 10316/10630 = 0.970461, Loss: 0.09701130539178848
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 55 	Loss: 0.002247, lr: 0.001000, Time: 3.54s
Clean ACC: 10311/10630 = 0.969991, Loss: 0.09801886230707169
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 56 	Loss: 0.006357, lr: 0.001000, Time: 3.53s
Clean ACC: 10326/10630 = 0.971402, Loss: 0.09605199843645096
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 57 	Loss: 0.001276, lr: 0.001000, Time: 3.39s
Clean ACC: 10312/10630 = 0.970085, Loss: 0.09872757643461227
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 58 	Loss: 0.000142, lr: 0.001000, Time: 3.50s
Clean ACC: 10336/10630 = 0.972342, Loss: 0.0940944105386734
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 59 	Loss: 0.000676, lr: 0.001000, Time: 3.56s
Clean ACC: 10328/10630 = 0.971590, Loss: 0.09491658955812454
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 60 	Loss: 0.000857, lr: 0.001000, Time: 3.50s
Clean ACC: 10327/10630 = 0.971496, Loss: 0.09610210359096527
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 61 	Loss: 0.000588, lr: 0.000100, Time: 3.55s
Clean ACC: 10325/10630 = 0.971308, Loss: 0.0964483916759491
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 62 	Loss: 0.017457, lr: 0.000100, Time: 3.53s
Clean ACC: 10329/10630 = 0.971684, Loss: 0.0961587205529213
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 63 	Loss: 0.001304, lr: 0.000100, Time: 3.54s
Clean ACC: 10335/10630 = 0.972248, Loss: 0.09506966918706894
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 64 	Loss: 0.001407, lr: 0.000100, Time: 3.51s
Clean ACC: 10311/10630 = 0.969991, Loss: 0.09792617708444595
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 65 	Loss: 0.000492, lr: 0.000100, Time: 3.56s
Clean ACC: 10335/10630 = 0.972248, Loss: 0.09357000887393951
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 66 	Loss: 0.001051, lr: 0.000100, Time: 3.56s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.094239242374897
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 67 	Loss: 0.002248, lr: 0.000100, Time: 3.48s
Clean ACC: 10320/10630 = 0.970837, Loss: 0.09501095861196518
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 68 	Loss: 0.000807, lr: 0.000100, Time: 3.53s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09534118324518204
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 69 	Loss: 0.000492, lr: 0.000100, Time: 3.59s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09516458213329315
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 70 	Loss: 0.001090, lr: 0.000100, Time: 3.50s
Clean ACC: 10330/10630 = 0.971778, Loss: 0.09494733065366745
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 71 	Loss: 0.003606, lr: 0.000100, Time: 3.53s
Clean ACC: 10310/10630 = 0.969897, Loss: 0.09818591922521591
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 72 	Loss: 0.001848, lr: 0.000100, Time: 3.49s
Clean ACC: 10330/10630 = 0.971778, Loss: 0.09541455656290054
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 73 	Loss: 0.000450, lr: 0.000100, Time: 3.45s
Clean ACC: 10323/10630 = 0.971119, Loss: 0.09632980078458786
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 74 	Loss: 0.000353, lr: 0.000100, Time: 3.53s
Clean ACC: 10329/10630 = 0.971684, Loss: 0.09540878981351852
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 75 	Loss: 0.000180, lr: 0.000100, Time: 3.44s
Clean ACC: 10328/10630 = 0.971590, Loss: 0.09618381410837173
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 76 	Loss: 0.001065, lr: 0.000100, Time: 3.48s
Clean ACC: 10328/10630 = 0.971590, Loss: 0.09649564325809479
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 77 	Loss: 0.000932, lr: 0.000100, Time: 3.44s
Clean ACC: 10319/10630 = 0.970743, Loss: 0.09595901519060135
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 78 	Loss: 0.000806, lr: 0.000100, Time: 3.55s
Clean ACC: 10319/10630 = 0.970743, Loss: 0.09672527015209198
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 79 	Loss: 0.000734, lr: 0.000100, Time: 3.50s
Clean ACC: 10327/10630 = 0.971496, Loss: 0.09631980210542679
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 80 	Loss: 0.000961, lr: 0.000100, Time: 3.54s
Clean ACC: 10317/10630 = 0.970555, Loss: 0.09696096926927567
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 81 	Loss: 0.005189, lr: 0.000100, Time: 3.55s
Clean ACC: 10322/10630 = 0.971025, Loss: 0.09587342292070389
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 82 	Loss: 0.001300, lr: 0.000100, Time: 3.50s
Clean ACC: 10335/10630 = 0.972248, Loss: 0.09510394185781479
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 83 	Loss: 0.001851, lr: 0.000100, Time: 3.39s
Clean ACC: 10329/10630 = 0.971684, Loss: 0.09615147858858109
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 84 	Loss: 0.000237, lr: 0.000100, Time: 3.44s
Clean ACC: 10335/10630 = 0.972248, Loss: 0.09417643398046494
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 85 	Loss: 0.000318, lr: 0.000100, Time: 3.44s
Clean ACC: 10338/10630 = 0.972531, Loss: 0.09612344205379486
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 86 	Loss: 0.015169, lr: 0.000100, Time: 3.45s
Clean ACC: 10320/10630 = 0.970837, Loss: 0.09614749252796173
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 87 	Loss: 0.003017, lr: 0.000100, Time: 3.39s
Clean ACC: 10321/10630 = 0.970931, Loss: 0.09716480225324631
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 88 	Loss: 0.005604, lr: 0.000100, Time: 3.56s
Clean ACC: 10318/10630 = 0.970649, Loss: 0.0950106829404831
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 89 	Loss: 0.000086, lr: 0.000100, Time: 3.43s
Clean ACC: 10340/10630 = 0.972719, Loss: 0.09407902508974075
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 90 	Loss: 0.000371, lr: 0.000100, Time: 3.53s
Clean ACC: 10330/10630 = 0.971778, Loss: 0.09463884681463242
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 91 	Loss: 0.000556, lr: 0.000100, Time: 3.57s
Clean ACC: 10324/10630 = 0.971214, Loss: 0.09615092724561691
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 92 	Loss: 0.000896, lr: 0.000100, Time: 3.50s
Clean ACC: 10315/10630 = 0.970367, Loss: 0.09592624008655548
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 93 	Loss: 0.000619, lr: 0.000100, Time: 3.52s
Clean ACC: 10333/10630 = 0.972060, Loss: 0.0945616066455841
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 94 	Loss: 0.078904, lr: 0.000100, Time: 3.54s
Clean ACC: 10317/10630 = 0.970555, Loss: 0.09449629485607147
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 95 	Loss: 0.000636, lr: 0.000100, Time: 3.59s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09294109046459198
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 96 	Loss: 0.000400, lr: 0.000100, Time: 3.48s
Clean ACC: 10334/10630 = 0.972154, Loss: 0.09510708600282669
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 97 	Loss: 0.000284, lr: 0.000100, Time: 3.47s
Clean ACC: 10332/10630 = 0.971966, Loss: 0.09412022680044174
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 98 	Loss: 0.000578, lr: 0.000100, Time: 3.48s
Clean ACC: 10323/10630 = 0.971119, Loss: 0.09629461169242859
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 99 	Loss: 0.002129, lr: 0.000100, Time: 3.57s
Clean ACC: 10328/10630 = 0.971590, Loss: 0.0965263843536377
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 100 	Loss: 0.000745, lr: 0.000100, Time: 3.64s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000


Testing the backdoor model...
Evaluating model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Visualizing the model's latent space...
Using method: pca
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
Saved figure at assets/pca_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: tsne
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
Saved figure at assets/tsne_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: umap
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
Saved figure at assets/umap_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: oracle
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
SVM Accuracy: 1.0
Saved figure at assets/oracle_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: mean_diff
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
Mean L2 distance between poison and clean: 12.175341606140137
Saved figure at assets/mean_diff_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: SS
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
torch.Size([1751])
Saved figure at assets/SS_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: isomap
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
Saved figure at assets/isomap_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: lle
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
Saved figure at assets/lle_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: kpca
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
Saved figure at assets/kpca_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Using method: spectral
Visualizing model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09327629208564758
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
torch.Size([512])
clean_dis: 5.784309, poison_dis: 15.862736
Saved figure at assets/spectral_gtsrb_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/trojan_square_32.png
trigger_mask_path: ./triggers/mask_trojan_square_32.png
Evaluating model 'poisoned_train_set/gtsrb/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 97.24365234375
asr: 100.0
target label: tensor([2], device='cuda:0')
start_index: 15
TPR: 100.00
FPR: 2.31
AUC: 0.9948
f1 score: 0.98856133172138
Elapsed time: 19.41s
Experiment for gtsrb with trojan completed.
