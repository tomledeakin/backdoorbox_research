Creating poisoned training set for WaNet on gtsrb...
[target class : 2]
Poisoned set directory 'poisoned_train_set/gtsrb/WaNet_0.010_cover=0.000_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/gtsrb/WaNet_0.010_cover=0.000_poison_seed=0/imgs
Will save to 'poisoned_train_set/gtsrb/WaNet_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt'.
Model 'poisoned_train_set/gtsrb/WaNet_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt' already exists!
<Backdoor Training> Train Epoch: 1 	Loss: 0.156699, lr: 0.010000, Time: 5.79s
Clean ACC: 9686/10630 = 0.911195, Loss: 0.3441115915775299
ASR: 166/10005 = 0.016592


<Backdoor Training> Train Epoch: 2 	Loss: 0.102151, lr: 0.010000, Time: 3.48s
Clean ACC: 9770/10630 = 0.919097, Loss: 0.28571704030036926
ASR: 415/10005 = 0.041479


<Backdoor Training> Train Epoch: 3 	Loss: 0.050299, lr: 0.010000, Time: 3.45s
Clean ACC: 9973/10630 = 0.938194, Loss: 0.22675472497940063
ASR: 130/10005 = 0.012994


<Backdoor Training> Train Epoch: 4 	Loss: 0.302453, lr: 0.010000, Time: 3.54s
Clean ACC: 9963/10630 = 0.937253, Loss: 0.24469080567359924
ASR: 87/10005 = 0.008696


<Backdoor Training> Train Epoch: 5 	Loss: 0.239556, lr: 0.010000, Time: 3.46s
Clean ACC: 9982/10630 = 0.939040, Loss: 0.23020674288272858
ASR: 68/10005 = 0.006797


<Backdoor Training> Train Epoch: 6 	Loss: 0.020379, lr: 0.010000, Time: 3.47s
Clean ACC: 10108/10630 = 0.950894, Loss: 0.18294823169708252
ASR: 104/10005 = 0.010395


<Backdoor Training> Train Epoch: 7 	Loss: 0.010795, lr: 0.010000, Time: 3.41s
Clean ACC: 10079/10630 = 0.948166, Loss: 0.19532130658626556
ASR: 145/10005 = 0.014493


<Backdoor Training> Train Epoch: 8 	Loss: 0.096989, lr: 0.010000, Time: 3.60s
Clean ACC: 9971/10630 = 0.938006, Loss: 0.24084989726543427
ASR: 484/10005 = 0.048376


<Backdoor Training> Train Epoch: 9 	Loss: 0.059969, lr: 0.010000, Time: 3.52s
Clean ACC: 10058/10630 = 0.946190, Loss: 0.20316405594348907
ASR: 349/10005 = 0.034883


<Backdoor Training> Train Epoch: 10 	Loss: 0.013958, lr: 0.010000, Time: 3.52s
Clean ACC: 10091/10630 = 0.949294, Loss: 0.1995849460363388
ASR: 294/10005 = 0.029385


<Backdoor Training> Train Epoch: 11 	Loss: 0.364614, lr: 0.010000, Time: 3.39s
Clean ACC: 10206/10630 = 0.960113, Loss: 0.15589888393878937
ASR: 250/10005 = 0.024988


<Backdoor Training> Train Epoch: 12 	Loss: 0.024738, lr: 0.010000, Time: 3.61s
Clean ACC: 10147/10630 = 0.954563, Loss: 0.17176735401153564
ASR: 358/10005 = 0.035782


<Backdoor Training> Train Epoch: 13 	Loss: 0.029919, lr: 0.010000, Time: 3.52s
Clean ACC: 10128/10630 = 0.952775, Loss: 0.18536053597927094
ASR: 216/10005 = 0.021589


<Backdoor Training> Train Epoch: 14 	Loss: 0.011349, lr: 0.010000, Time: 3.44s
Clean ACC: 10059/10630 = 0.946284, Loss: 0.21004195511341095
ASR: 883/10005 = 0.088256


<Backdoor Training> Train Epoch: 15 	Loss: 0.091966, lr: 0.010000, Time: 3.53s
Clean ACC: 10191/10630 = 0.958702, Loss: 0.16377027332782745
ASR: 180/10005 = 0.017991


<Backdoor Training> Train Epoch: 16 	Loss: 0.006020, lr: 0.010000, Time: 3.53s
Clean ACC: 10127/10630 = 0.952681, Loss: 0.18061262369155884
ASR: 592/10005 = 0.059170


<Backdoor Training> Train Epoch: 17 	Loss: 0.014807, lr: 0.010000, Time: 3.56s
Clean ACC: 10170/10630 = 0.956726, Loss: 0.1603173017501831
ASR: 446/10005 = 0.044578


<Backdoor Training> Train Epoch: 18 	Loss: 0.002249, lr: 0.010000, Time: 3.57s
Clean ACC: 10189/10630 = 0.958514, Loss: 0.16218289732933044
ASR: 332/10005 = 0.033183


<Backdoor Training> Train Epoch: 19 	Loss: 0.142343, lr: 0.010000, Time: 3.55s
Clean ACC: 9903/10630 = 0.931609, Loss: 0.23779821395874023
ASR: 1581/10005 = 0.158021


<Backdoor Training> Train Epoch: 20 	Loss: 0.003225, lr: 0.010000, Time: 3.52s
Clean ACC: 10170/10630 = 0.956726, Loss: 0.16438500583171844
ASR: 114/10005 = 0.011394


<Backdoor Training> Train Epoch: 21 	Loss: 0.015735, lr: 0.010000, Time: 3.55s
Clean ACC: 10079/10630 = 0.948166, Loss: 0.19038361310958862
ASR: 813/10005 = 0.081259


<Backdoor Training> Train Epoch: 22 	Loss: 0.009927, lr: 0.010000, Time: 3.53s
Clean ACC: 10144/10630 = 0.954280, Loss: 0.16156497597694397
ASR: 508/10005 = 0.050775


<Backdoor Training> Train Epoch: 23 	Loss: 0.005061, lr: 0.010000, Time: 3.49s
Clean ACC: 10145/10630 = 0.954374, Loss: 0.16668052971363068
ASR: 251/10005 = 0.025087


<Backdoor Training> Train Epoch: 24 	Loss: 0.007897, lr: 0.010000, Time: 3.48s
Clean ACC: 10190/10630 = 0.958608, Loss: 0.15287186205387115
ASR: 532/10005 = 0.053173


<Backdoor Training> Train Epoch: 25 	Loss: 0.003536, lr: 0.010000, Time: 3.49s
Clean ACC: 10172/10630 = 0.956914, Loss: 0.16758590936660767
ASR: 341/10005 = 0.034083


<Backdoor Training> Train Epoch: 26 	Loss: 0.006478, lr: 0.010000, Time: 3.40s
Clean ACC: 10166/10630 = 0.956350, Loss: 0.15947431325912476
ASR: 1043/10005 = 0.104248


<Backdoor Training> Train Epoch: 27 	Loss: 0.001529, lr: 0.010000, Time: 3.60s
Clean ACC: 10213/10630 = 0.960771, Loss: 0.1515568494796753
ASR: 869/10005 = 0.086857


<Backdoor Training> Train Epoch: 28 	Loss: 0.018660, lr: 0.010000, Time: 3.59s
Clean ACC: 10259/10630 = 0.965099, Loss: 0.12775824964046478
ASR: 325/10005 = 0.032484


<Backdoor Training> Train Epoch: 29 	Loss: 0.000468, lr: 0.010000, Time: 3.52s
Clean ACC: 10187/10630 = 0.958325, Loss: 0.16479940712451935
ASR: 387/10005 = 0.038681


<Backdoor Training> Train Epoch: 30 	Loss: 0.001225, lr: 0.010000, Time: 3.50s
Clean ACC: 10209/10630 = 0.960395, Loss: 0.14591708779335022
ASR: 1136/10005 = 0.113543


<Backdoor Training> Train Epoch: 31 	Loss: 0.001023, lr: 0.001000, Time: 3.52s
Clean ACC: 10267/10630 = 0.965851, Loss: 0.12795406579971313
ASR: 538/10005 = 0.053773


<Backdoor Training> Train Epoch: 32 	Loss: 0.002945, lr: 0.001000, Time: 3.63s
Clean ACC: 10264/10630 = 0.965569, Loss: 0.1263521909713745
ASR: 596/10005 = 0.059570


<Backdoor Training> Train Epoch: 33 	Loss: 0.003869, lr: 0.001000, Time: 3.47s
Clean ACC: 10282/10630 = 0.967262, Loss: 0.12477767467498779
ASR: 554/10005 = 0.055372


<Backdoor Training> Train Epoch: 34 	Loss: 0.002384, lr: 0.001000, Time: 3.49s
Clean ACC: 10275/10630 = 0.966604, Loss: 0.12589430809020996
ASR: 550/10005 = 0.054973


<Backdoor Training> Train Epoch: 35 	Loss: 0.000039, lr: 0.001000, Time: 3.56s
Clean ACC: 10279/10630 = 0.966980, Loss: 0.12448200583457947
ASR: 588/10005 = 0.058771


<Backdoor Training> Train Epoch: 36 	Loss: 0.012194, lr: 0.001000, Time: 3.48s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.12219546735286713
ASR: 608/10005 = 0.060770


<Backdoor Training> Train Epoch: 37 	Loss: 0.001304, lr: 0.001000, Time: 3.50s
Clean ACC: 10279/10630 = 0.966980, Loss: 0.12529633939266205
ASR: 615/10005 = 0.061469


<Backdoor Training> Train Epoch: 38 	Loss: 0.000672, lr: 0.001000, Time: 3.48s
Clean ACC: 10274/10630 = 0.966510, Loss: 0.12402385473251343
ASR: 644/10005 = 0.064368


<Backdoor Training> Train Epoch: 39 	Loss: 0.000287, lr: 0.001000, Time: 3.51s
Clean ACC: 10276/10630 = 0.966698, Loss: 0.12203515321016312
ASR: 637/10005 = 0.063668


<Backdoor Training> Train Epoch: 40 	Loss: 0.000567, lr: 0.001000, Time: 3.56s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.12050517648458481
ASR: 591/10005 = 0.059070


<Backdoor Training> Train Epoch: 41 	Loss: 0.017823, lr: 0.001000, Time: 3.57s
Clean ACC: 10275/10630 = 0.966604, Loss: 0.12153656035661697
ASR: 589/10005 = 0.058871


<Backdoor Training> Train Epoch: 42 	Loss: 0.000481, lr: 0.001000, Time: 3.56s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.11963631957769394
ASR: 561/10005 = 0.056072


<Backdoor Training> Train Epoch: 43 	Loss: 0.000818, lr: 0.001000, Time: 3.51s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.1199532300233841
ASR: 570/10005 = 0.056972


<Backdoor Training> Train Epoch: 44 	Loss: 0.006454, lr: 0.001000, Time: 3.51s
Clean ACC: 10290/10630 = 0.968015, Loss: 0.11906890571117401
ASR: 673/10005 = 0.067266


<Backdoor Training> Train Epoch: 45 	Loss: 0.001124, lr: 0.001000, Time: 3.49s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.12331544607877731
ASR: 638/10005 = 0.063768


<Backdoor Training> Train Epoch: 46 	Loss: 0.000315, lr: 0.001000, Time: 3.50s
Clean ACC: 10292/10630 = 0.968203, Loss: 0.12067895382642746
ASR: 548/10005 = 0.054773


<Backdoor Training> Train Epoch: 47 	Loss: 0.005968, lr: 0.001000, Time: 3.54s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.1197562962770462
ASR: 608/10005 = 0.060770


<Backdoor Training> Train Epoch: 48 	Loss: 0.002980, lr: 0.001000, Time: 3.55s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.12148258835077286
ASR: 565/10005 = 0.056472


<Backdoor Training> Train Epoch: 49 	Loss: 0.000357, lr: 0.001000, Time: 3.51s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.12031453847885132
ASR: 694/10005 = 0.069365


<Backdoor Training> Train Epoch: 50 	Loss: 0.000178, lr: 0.001000, Time: 3.53s
Clean ACC: 10274/10630 = 0.966510, Loss: 0.12005305290222168
ASR: 607/10005 = 0.060670


<Backdoor Training> Train Epoch: 51 	Loss: 0.000672, lr: 0.001000, Time: 3.55s
Clean ACC: 10282/10630 = 0.967262, Loss: 0.12110390514135361
ASR: 635/10005 = 0.063468


<Backdoor Training> Train Epoch: 52 	Loss: 0.001992, lr: 0.001000, Time: 3.50s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.12059289962053299
ASR: 602/10005 = 0.060170


<Backdoor Training> Train Epoch: 53 	Loss: 0.001643, lr: 0.001000, Time: 3.46s
Clean ACC: 10281/10630 = 0.967168, Loss: 0.1196107417345047
ASR: 633/10005 = 0.063268


<Backdoor Training> Train Epoch: 54 	Loss: 0.002153, lr: 0.001000, Time: 3.49s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.12026675045490265
ASR: 633/10005 = 0.063268


<Backdoor Training> Train Epoch: 55 	Loss: 0.000233, lr: 0.001000, Time: 3.49s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.12037219852209091
ASR: 598/10005 = 0.059770


<Backdoor Training> Train Epoch: 56 	Loss: 0.026733, lr: 0.001000, Time: 3.59s
Clean ACC: 10292/10630 = 0.968203, Loss: 0.11799552291631699
ASR: 633/10005 = 0.063268


<Backdoor Training> Train Epoch: 57 	Loss: 0.004984, lr: 0.001000, Time: 3.61s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.12056319415569305
ASR: 604/10005 = 0.060370


<Backdoor Training> Train Epoch: 58 	Loss: 0.001474, lr: 0.001000, Time: 3.58s
Clean ACC: 10297/10630 = 0.968674, Loss: 0.11674652248620987
ASR: 616/10005 = 0.061569


<Backdoor Training> Train Epoch: 59 	Loss: 0.001236, lr: 0.001000, Time: 3.53s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.12198075652122498
ASR: 615/10005 = 0.061469


<Backdoor Training> Train Epoch: 60 	Loss: 0.018569, lr: 0.001000, Time: 3.42s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.11895032227039337
ASR: 642/10005 = 0.064168


<Backdoor Training> Train Epoch: 61 	Loss: 0.000195, lr: 0.000100, Time: 3.54s
Clean ACC: 10282/10630 = 0.967262, Loss: 0.12060044705867767
ASR: 593/10005 = 0.059270


<Backdoor Training> Train Epoch: 62 	Loss: 0.001339, lr: 0.000100, Time: 3.48s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.11951996386051178
ASR: 616/10005 = 0.061569


<Backdoor Training> Train Epoch: 63 	Loss: 0.000224, lr: 0.000100, Time: 3.47s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.11941471695899963
ASR: 577/10005 = 0.057671


<Backdoor Training> Train Epoch: 64 	Loss: 0.007321, lr: 0.000100, Time: 3.63s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.12169211357831955
ASR: 612/10005 = 0.061169


<Backdoor Training> Train Epoch: 65 	Loss: 0.001093, lr: 0.000100, Time: 3.58s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.12092364579439163
ASR: 551/10005 = 0.055072


<Backdoor Training> Train Epoch: 66 	Loss: 0.000833, lr: 0.000100, Time: 3.57s
Clean ACC: 10279/10630 = 0.966980, Loss: 0.1226385161280632
ASR: 632/10005 = 0.063168


<Backdoor Training> Train Epoch: 67 	Loss: 0.001645, lr: 0.000100, Time: 3.55s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.12067816406488419
ASR: 677/10005 = 0.067666


<Backdoor Training> Train Epoch: 68 	Loss: 0.005011, lr: 0.000100, Time: 3.42s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.120507150888443
ASR: 543/10005 = 0.054273


<Backdoor Training> Train Epoch: 69 	Loss: 0.001667, lr: 0.000100, Time: 3.50s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.12067286670207977
ASR: 626/10005 = 0.062569


<Backdoor Training> Train Epoch: 70 	Loss: 0.000829, lr: 0.000100, Time: 3.52s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.11973552405834198
ASR: 634/10005 = 0.063368


<Backdoor Training> Train Epoch: 71 	Loss: 0.006082, lr: 0.000100, Time: 3.46s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.11738014221191406
ASR: 648/10005 = 0.064768


<Backdoor Training> Train Epoch: 72 	Loss: 0.007511, lr: 0.000100, Time: 3.39s
Clean ACC: 10292/10630 = 0.968203, Loss: 0.11967723071575165
ASR: 517/10005 = 0.051674


<Backdoor Training> Train Epoch: 73 	Loss: 0.000393, lr: 0.000100, Time: 3.51s
Clean ACC: 10276/10630 = 0.966698, Loss: 0.11999589204788208
ASR: 555/10005 = 0.055472


<Backdoor Training> Train Epoch: 74 	Loss: 0.012319, lr: 0.000100, Time: 3.58s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.1193699985742569
ASR: 605/10005 = 0.060470


<Backdoor Training> Train Epoch: 75 	Loss: 0.000777, lr: 0.000100, Time: 3.52s
Clean ACC: 10294/10630 = 0.968391, Loss: 0.11940978467464447
ASR: 607/10005 = 0.060670


<Backdoor Training> Train Epoch: 76 	Loss: 0.000729, lr: 0.000100, Time: 3.51s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.11912611126899719
ASR: 582/10005 = 0.058171


<Backdoor Training> Train Epoch: 77 	Loss: 0.001257, lr: 0.000100, Time: 3.49s
Clean ACC: 10275/10630 = 0.966604, Loss: 0.12155476212501526
ASR: 678/10005 = 0.067766


<Backdoor Training> Train Epoch: 78 	Loss: 0.002122, lr: 0.000100, Time: 3.52s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.12052832543849945
ASR: 614/10005 = 0.061369


<Backdoor Training> Train Epoch: 79 	Loss: 0.000464, lr: 0.000100, Time: 3.57s
Clean ACC: 10279/10630 = 0.966980, Loss: 0.11986839026212692
ASR: 652/10005 = 0.065167


<Backdoor Training> Train Epoch: 80 	Loss: 0.011326, lr: 0.000100, Time: 3.57s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.11934202909469604
ASR: 588/10005 = 0.058771


<Backdoor Training> Train Epoch: 81 	Loss: 0.000530, lr: 0.000100, Time: 3.53s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.1190849244594574
ASR: 572/10005 = 0.057171


<Backdoor Training> Train Epoch: 82 	Loss: 0.000402, lr: 0.000100, Time: 3.55s
Clean ACC: 10281/10630 = 0.967168, Loss: 0.11854097992181778
ASR: 643/10005 = 0.064268


<Backdoor Training> Train Epoch: 83 	Loss: 0.001422, lr: 0.000100, Time: 3.47s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.12046612054109573
ASR: 613/10005 = 0.061269


<Backdoor Training> Train Epoch: 84 	Loss: 0.001550, lr: 0.000100, Time: 3.55s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.11885453760623932
ASR: 630/10005 = 0.062969


<Backdoor Training> Train Epoch: 85 	Loss: 0.000608, lr: 0.000100, Time: 3.49s
Clean ACC: 10281/10630 = 0.967168, Loss: 0.1215706542134285
ASR: 582/10005 = 0.058171


<Backdoor Training> Train Epoch: 86 	Loss: 0.000759, lr: 0.000100, Time: 3.45s
Clean ACC: 10295/10630 = 0.968485, Loss: 0.11721040308475494
ASR: 601/10005 = 0.060070


<Backdoor Training> Train Epoch: 87 	Loss: 0.000967, lr: 0.000100, Time: 3.45s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.1196446642279625
ASR: 484/10005 = 0.048376


<Backdoor Training> Train Epoch: 88 	Loss: 0.001218, lr: 0.000100, Time: 3.44s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.11856004595756531
ASR: 585/10005 = 0.058471


<Backdoor Training> Train Epoch: 89 	Loss: 0.002461, lr: 0.000100, Time: 3.55s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.12049174308776855
ASR: 601/10005 = 0.060070


<Backdoor Training> Train Epoch: 90 	Loss: 0.002513, lr: 0.000100, Time: 3.45s
Clean ACC: 10284/10630 = 0.967451, Loss: 0.12047049403190613
ASR: 598/10005 = 0.059770


<Backdoor Training> Train Epoch: 91 	Loss: 0.030946, lr: 0.000100, Time: 3.48s
Clean ACC: 10277/10630 = 0.966792, Loss: 0.12145549058914185
ASR: 600/10005 = 0.059970


<Backdoor Training> Train Epoch: 92 	Loss: 0.001813, lr: 0.000100, Time: 3.50s
Clean ACC: 10283/10630 = 0.967357, Loss: 0.11829611659049988
ASR: 583/10005 = 0.058271


<Backdoor Training> Train Epoch: 93 	Loss: 0.006891, lr: 0.000100, Time: 3.52s
Clean ACC: 10288/10630 = 0.967827, Loss: 0.12144365906715393
ASR: 541/10005 = 0.054073


<Backdoor Training> Train Epoch: 94 	Loss: 0.000888, lr: 0.000100, Time: 3.46s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.11945340782403946
ASR: 589/10005 = 0.058871


<Backdoor Training> Train Epoch: 95 	Loss: 0.000982, lr: 0.000100, Time: 3.59s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.11892583221197128
ASR: 621/10005 = 0.062069


<Backdoor Training> Train Epoch: 96 	Loss: 0.000447, lr: 0.000100, Time: 3.49s
Clean ACC: 10285/10630 = 0.967545, Loss: 0.11967778205871582
ASR: 634/10005 = 0.063368


<Backdoor Training> Train Epoch: 97 	Loss: 0.004314, lr: 0.000100, Time: 3.52s
Clean ACC: 10286/10630 = 0.967639, Loss: 0.11985990405082703
ASR: 626/10005 = 0.062569


<Backdoor Training> Train Epoch: 98 	Loss: 0.001021, lr: 0.000100, Time: 3.48s
Clean ACC: 10274/10630 = 0.966510, Loss: 0.12186513096094131
ASR: 614/10005 = 0.061369


<Backdoor Training> Train Epoch: 99 	Loss: 0.000405, lr: 0.000100, Time: 3.54s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.11995834112167358
ASR: 595/10005 = 0.059470


<Backdoor Training> Train Epoch: 100 	Loss: 0.000911, lr: 0.000100, Time: 3.54s
Clean ACC: 10278/10630 = 0.966886, Loss: 0.11979083716869354
ASR: 627/10005 = 0.062669


Testing the backdoor model...
Evaluating model 'poisoned_train_set/gtsrb/WaNet_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 10278/10630 = 0.966886, Loss: 0.11979083716869354
ASR: 627/10005 = 0.062669

Visualizing the model's latent space...
Using method: umap
Visualizing model 'poisoned_train_set/gtsrb/WaNet_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10278/10630 = 0.966886, Loss: 0.11980120092630386
ASR: 627/10005 = 0.062669

Total Clean: 26374
Total Poisoned: 266
Saved figure at umap_assets/umap_gtsrb_WaNet_0.010_cover=0.000_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Experiment for gtsrb with WaNet completed.
