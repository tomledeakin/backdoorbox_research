Creating poisoned training set for badnet on gtsrb...
[target class : 2]
Poisoned set directory 'poisoned_train_set/gtsrb/badnet_0.010_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/gtsrb/badnet_0.010_poison_seed=0/imgs
Will save to 'poisoned_train_set/gtsrb/badnet_0.010_poison_seed=0/full_base_aug_seed=2333.pt'.
Model 'poisoned_train_set/gtsrb/badnet_0.010_poison_seed=0/full_base_aug_seed=2333.pt' already exists!
<Backdoor Training> Train Epoch: 1 	Loss: 0.435403, lr: 0.010000, Time: 7.63s
Clean ACC: 9619/10630 = 0.904892, Loss: 0.3497524559497833
ASR: 30/10005 = 0.002999


<Backdoor Training> Train Epoch: 2 	Loss: 0.281886, lr: 0.010000, Time: 4.06s
Clean ACC: 9851/10630 = 0.926717, Loss: 0.2887764573097229
ASR: 215/10005 = 0.021489


<Backdoor Training> Train Epoch: 3 	Loss: 0.094895, lr: 0.010000, Time: 4.11s
Clean ACC: 9956/10630 = 0.936595, Loss: 0.23421074450016022
ASR: 111/10005 = 0.011094


<Backdoor Training> Train Epoch: 4 	Loss: 0.098874, lr: 0.010000, Time: 4.03s
Clean ACC: 10133/10630 = 0.953246, Loss: 0.1625359058380127
ASR: 208/10005 = 0.020790


<Backdoor Training> Train Epoch: 5 	Loss: 0.038014, lr: 0.010000, Time: 3.85s
Clean ACC: 10121/10630 = 0.952117, Loss: 0.19505876302719116
ASR: 95/10005 = 0.009495


<Backdoor Training> Train Epoch: 6 	Loss: 0.027315, lr: 0.010000, Time: 4.14s
Clean ACC: 10042/10630 = 0.944685, Loss: 0.20155136287212372
ASR: 4825/10005 = 0.482259


<Backdoor Training> Train Epoch: 7 	Loss: 0.007942, lr: 0.010000, Time: 4.00s
Clean ACC: 10201/10630 = 0.959643, Loss: 0.16037961840629578
ASR: 8931/10005 = 0.892654


<Backdoor Training> Train Epoch: 8 	Loss: 0.019847, lr: 0.010000, Time: 4.02s
Clean ACC: 10204/10630 = 0.959925, Loss: 0.14900697767734528
ASR: 9761/10005 = 0.975612


<Backdoor Training> Train Epoch: 9 	Loss: 0.032592, lr: 0.010000, Time: 4.01s
Clean ACC: 10279/10630 = 0.966980, Loss: 0.11475047469139099
ASR: 9986/10005 = 0.998101


<Backdoor Training> Train Epoch: 10 	Loss: 0.016065, lr: 0.010000, Time: 3.92s
Clean ACC: 10223/10630 = 0.961712, Loss: 0.15011391043663025
ASR: 9929/10005 = 0.992404


<Backdoor Training> Train Epoch: 11 	Loss: 0.010314, lr: 0.010000, Time: 3.91s
Clean ACC: 10220/10630 = 0.961430, Loss: 0.14144030213356018
ASR: 9991/10005 = 0.998601


<Backdoor Training> Train Epoch: 12 	Loss: 0.003221, lr: 0.010000, Time: 4.08s
Clean ACC: 10250/10630 = 0.964252, Loss: 0.12493602931499481
ASR: 9975/10005 = 0.997001


<Backdoor Training> Train Epoch: 13 	Loss: 0.125705, lr: 0.010000, Time: 4.01s
Clean ACC: 10208/10630 = 0.960301, Loss: 0.15949086844921112
ASR: 9937/10005 = 0.993203


<Backdoor Training> Train Epoch: 14 	Loss: 0.003654, lr: 0.010000, Time: 3.97s
Clean ACC: 10276/10630 = 0.966698, Loss: 0.12003112584352493
ASR: 9880/10005 = 0.987506


<Backdoor Training> Train Epoch: 15 	Loss: 0.000637, lr: 0.010000, Time: 3.91s
Clean ACC: 10304/10630 = 0.969332, Loss: 0.1005333811044693
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 16 	Loss: 0.017857, lr: 0.010000, Time: 3.93s
Clean ACC: 10333/10630 = 0.972060, Loss: 0.09964185208082199
ASR: 9958/10005 = 0.995302


<Backdoor Training> Train Epoch: 17 	Loss: 0.008949, lr: 0.010000, Time: 3.83s
Clean ACC: 10280/10630 = 0.967074, Loss: 0.12142166495323181
ASR: 10003/10005 = 0.999800


<Backdoor Training> Train Epoch: 18 	Loss: 0.003854, lr: 0.010000, Time: 3.85s
Clean ACC: 10314/10630 = 0.970273, Loss: 0.10550625622272491
ASR: 9875/10005 = 0.987006


<Backdoor Training> Train Epoch: 19 	Loss: 0.006723, lr: 0.010000, Time: 3.82s
Clean ACC: 10300/10630 = 0.968956, Loss: 0.11278122663497925
ASR: 9927/10005 = 0.992204


<Backdoor Training> Train Epoch: 20 	Loss: 0.003119, lr: 0.010000, Time: 3.77s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.10294154286384583
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 21 	Loss: 0.016039, lr: 0.010000, Time: 3.83s
Clean ACC: 10246/10630 = 0.963876, Loss: 0.13543939590454102
ASR: 10002/10005 = 0.999700


<Backdoor Training> Train Epoch: 22 	Loss: 0.005819, lr: 0.010000, Time: 3.95s
Clean ACC: 10324/10630 = 0.971214, Loss: 0.10649985074996948
ASR: 9933/10005 = 0.992804


<Backdoor Training> Train Epoch: 23 	Loss: 0.002880, lr: 0.010000, Time: 4.13s
Clean ACC: 10287/10630 = 0.967733, Loss: 0.11271867156028748
ASR: 9747/10005 = 0.974213


<Backdoor Training> Train Epoch: 24 	Loss: 0.001071, lr: 0.010000, Time: 4.08s
Clean ACC: 10334/10630 = 0.972154, Loss: 0.10311774909496307
ASR: 9985/10005 = 0.998001


<Backdoor Training> Train Epoch: 25 	Loss: 0.004987, lr: 0.010000, Time: 4.01s
Clean ACC: 10291/10630 = 0.968109, Loss: 0.1079668179154396
ASR: 10003/10005 = 0.999800


<Backdoor Training> Train Epoch: 26 	Loss: 0.073567, lr: 0.010000, Time: 4.02s
Clean ACC: 10312/10630 = 0.970085, Loss: 0.10238067060709
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 27 	Loss: 0.003366, lr: 0.010000, Time: 4.06s
Clean ACC: 10251/10630 = 0.964346, Loss: 0.12889064848423004
ASR: 9991/10005 = 0.998601


<Backdoor Training> Train Epoch: 28 	Loss: 0.001052, lr: 0.010000, Time: 4.20s
Clean ACC: 10333/10630 = 0.972060, Loss: 0.10224350541830063
ASR: 10000/10005 = 0.999500


<Backdoor Training> Train Epoch: 29 	Loss: 0.065990, lr: 0.010000, Time: 4.19s
Clean ACC: 10302/10630 = 0.969144, Loss: 0.11238383501768112
ASR: 9994/10005 = 0.998901


<Backdoor Training> Train Epoch: 30 	Loss: 0.004955, lr: 0.010000, Time: 4.13s
Clean ACC: 10289/10630 = 0.967921, Loss: 0.12188633531332016
ASR: 10001/10005 = 0.999600


<Backdoor Training> Train Epoch: 31 	Loss: 0.000945, lr: 0.001000, Time: 3.98s
Clean ACC: 10325/10630 = 0.971308, Loss: 0.1072198748588562
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 32 	Loss: 0.002210, lr: 0.001000, Time: 4.05s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.1050315871834755
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 33 	Loss: 0.026244, lr: 0.001000, Time: 4.16s
Clean ACC: 10332/10630 = 0.971966, Loss: 0.10339291393756866
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 34 	Loss: 0.001244, lr: 0.001000, Time: 3.83s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09877140820026398
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 35 	Loss: 0.003753, lr: 0.001000, Time: 3.95s
Clean ACC: 10349/10630 = 0.973565, Loss: 0.10066229850053787
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 36 	Loss: 0.004425, lr: 0.001000, Time: 3.74s
Clean ACC: 10338/10630 = 0.972531, Loss: 0.10128425806760788
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 37 	Loss: 0.001622, lr: 0.001000, Time: 4.02s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.09940352290868759
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 38 	Loss: 0.000980, lr: 0.001000, Time: 4.13s
Clean ACC: 10338/10630 = 0.972531, Loss: 0.09921959042549133
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 39 	Loss: 0.019088, lr: 0.001000, Time: 3.89s
Clean ACC: 10340/10630 = 0.972719, Loss: 0.09868263453245163
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 40 	Loss: 0.001184, lr: 0.001000, Time: 3.95s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.0960315391421318
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 41 	Loss: 0.001961, lr: 0.001000, Time: 3.81s
Clean ACC: 10346/10630 = 0.973283, Loss: 0.09610762447118759
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 42 	Loss: 0.004666, lr: 0.001000, Time: 3.80s
Clean ACC: 10347/10630 = 0.973377, Loss: 0.09758014976978302
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 43 	Loss: 0.001971, lr: 0.001000, Time: 3.90s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.09572245180606842
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 44 	Loss: 0.017406, lr: 0.001000, Time: 3.98s
Clean ACC: 10342/10630 = 0.972907, Loss: 0.09646506607532501
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 45 	Loss: 0.001115, lr: 0.001000, Time: 4.13s
Clean ACC: 10340/10630 = 0.972719, Loss: 0.09752687811851501
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 46 	Loss: 0.002019, lr: 0.001000, Time: 3.99s
Clean ACC: 10329/10630 = 0.971684, Loss: 0.0982622429728508
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 47 	Loss: 0.000670, lr: 0.001000, Time: 3.92s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09713611751794815
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 48 	Loss: 0.010804, lr: 0.001000, Time: 4.02s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.09683080017566681
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 49 	Loss: 0.000403, lr: 0.001000, Time: 3.92s
Clean ACC: 10338/10630 = 0.972531, Loss: 0.09688763320446014
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 50 	Loss: 0.004948, lr: 0.001000, Time: 3.99s
Clean ACC: 10341/10630 = 0.972813, Loss: 0.09591920673847198
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 51 	Loss: 0.001192, lr: 0.001000, Time: 4.02s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09703460335731506
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 52 	Loss: 0.003012, lr: 0.001000, Time: 3.97s
Clean ACC: 10340/10630 = 0.972719, Loss: 0.09691295772790909
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 53 	Loss: 0.001793, lr: 0.001000, Time: 3.84s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.09718921780586243
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 54 	Loss: 0.000399, lr: 0.001000, Time: 3.63s
Clean ACC: 10328/10630 = 0.971590, Loss: 0.09833866357803345
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 55 	Loss: 0.000087, lr: 0.001000, Time: 3.76s
Clean ACC: 10346/10630 = 0.973283, Loss: 0.09721699357032776
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 56 	Loss: 0.003065, lr: 0.001000, Time: 4.08s
Clean ACC: 10342/10630 = 0.972907, Loss: 0.09727286547422409
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 57 	Loss: 0.001442, lr: 0.001000, Time: 3.89s
Clean ACC: 10339/10630 = 0.972625, Loss: 0.09823055565357208
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 58 	Loss: 0.005095, lr: 0.001000, Time: 3.58s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.09553045779466629
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 59 	Loss: 0.016668, lr: 0.001000, Time: 3.91s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.09575700759887695
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 60 	Loss: 0.004146, lr: 0.001000, Time: 4.06s
Clean ACC: 10342/10630 = 0.972907, Loss: 0.09840510785579681
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 61 	Loss: 0.008177, lr: 0.000100, Time: 3.85s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.09631535410881042
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 62 	Loss: 0.001721, lr: 0.000100, Time: 3.86s
Clean ACC: 10354/10630 = 0.974036, Loss: 0.09617951512336731
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 63 	Loss: 0.002580, lr: 0.000100, Time: 3.64s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.09493274986743927
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 64 	Loss: 0.001097, lr: 0.000100, Time: 4.15s
Clean ACC: 10348/10630 = 0.973471, Loss: 0.09465628862380981
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 65 	Loss: 0.007513, lr: 0.000100, Time: 4.19s
Clean ACC: 10353/10630 = 0.973942, Loss: 0.09588436037302017
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 66 	Loss: 0.001286, lr: 0.000100, Time: 4.06s
Clean ACC: 10349/10630 = 0.973565, Loss: 0.09625484049320221
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 67 	Loss: 0.000799, lr: 0.000100, Time: 4.05s
Clean ACC: 10336/10630 = 0.972342, Loss: 0.0982031598687172
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 68 	Loss: 0.001796, lr: 0.000100, Time: 4.01s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.0957372784614563
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 69 	Loss: 0.006077, lr: 0.000100, Time: 4.09s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.0970100611448288
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 70 	Loss: 0.026303, lr: 0.000100, Time: 3.73s
Clean ACC: 10346/10630 = 0.973283, Loss: 0.09602595120668411
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 71 	Loss: 0.001094, lr: 0.000100, Time: 4.09s
Clean ACC: 10349/10630 = 0.973565, Loss: 0.0945294126868248
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 72 	Loss: 0.003336, lr: 0.000100, Time: 4.11s
Clean ACC: 10341/10630 = 0.972813, Loss: 0.09719322621822357
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 73 	Loss: 0.003176, lr: 0.000100, Time: 3.86s
Clean ACC: 10341/10630 = 0.972813, Loss: 0.09774243831634521
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 74 	Loss: 0.002400, lr: 0.000100, Time: 3.82s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.09632958471775055
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 75 	Loss: 0.004389, lr: 0.000100, Time: 3.96s
Clean ACC: 10348/10630 = 0.973471, Loss: 0.09607679396867752
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 76 	Loss: 0.004769, lr: 0.000100, Time: 3.86s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.09532727301120758
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 77 	Loss: 0.000226, lr: 0.000100, Time: 3.93s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.09620915353298187
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 78 	Loss: 0.002101, lr: 0.000100, Time: 3.77s
Clean ACC: 10339/10630 = 0.972625, Loss: 0.09560792148113251
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 79 	Loss: 0.003757, lr: 0.000100, Time: 3.90s
Clean ACC: 10341/10630 = 0.972813, Loss: 0.09688831120729446
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 80 	Loss: 0.001434, lr: 0.000100, Time: 3.94s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.09677907079458237
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 81 	Loss: 0.002888, lr: 0.000100, Time: 3.83s
Clean ACC: 10342/10630 = 0.972907, Loss: 0.09753728657960892
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 82 	Loss: 0.000488, lr: 0.000100, Time: 3.79s
Clean ACC: 10346/10630 = 0.973283, Loss: 0.09584458917379379
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 83 	Loss: 0.002930, lr: 0.000100, Time: 3.82s
Clean ACC: 10338/10630 = 0.972531, Loss: 0.0969107523560524
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 84 	Loss: 0.000514, lr: 0.000100, Time: 3.87s
Clean ACC: 10336/10630 = 0.972342, Loss: 0.09717404842376709
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 85 	Loss: 0.003587, lr: 0.000100, Time: 3.53s
Clean ACC: 10350/10630 = 0.973659, Loss: 0.09575124830007553
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 86 	Loss: 0.006088, lr: 0.000100, Time: 3.95s
Clean ACC: 10344/10630 = 0.973095, Loss: 0.09712589532136917
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 87 	Loss: 0.002889, lr: 0.000100, Time: 4.13s
Clean ACC: 10331/10630 = 0.971872, Loss: 0.09861241281032562
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 88 	Loss: 0.034774, lr: 0.000100, Time: 4.13s
Clean ACC: 10348/10630 = 0.973471, Loss: 0.09600788354873657
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 89 	Loss: 0.003357, lr: 0.000100, Time: 4.03s
Clean ACC: 10346/10630 = 0.973283, Loss: 0.09506027400493622
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 90 	Loss: 0.030041, lr: 0.000100, Time: 3.84s
Clean ACC: 10329/10630 = 0.971684, Loss: 0.09904942661523819
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 91 	Loss: 0.000644, lr: 0.000100, Time: 3.99s
Clean ACC: 10343/10630 = 0.973001, Loss: 0.09626730531454086
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 92 	Loss: 0.005731, lr: 0.000100, Time: 4.06s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.09710276871919632
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 93 	Loss: 0.002210, lr: 0.000100, Time: 4.09s
Clean ACC: 10334/10630 = 0.972154, Loss: 0.09893352538347244
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 94 	Loss: 0.001962, lr: 0.000100, Time: 3.73s
Clean ACC: 10341/10630 = 0.972813, Loss: 0.09640570729970932
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 95 	Loss: 0.002297, lr: 0.000100, Time: 3.78s
Clean ACC: 10339/10630 = 0.972625, Loss: 0.09688779711723328
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 96 	Loss: 0.002785, lr: 0.000100, Time: 3.97s
Clean ACC: 10341/10630 = 0.972813, Loss: 0.0965467244386673
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 97 	Loss: 0.001761, lr: 0.000100, Time: 3.96s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.09783820062875748
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 98 	Loss: 0.000720, lr: 0.000100, Time: 3.85s
Clean ACC: 10337/10630 = 0.972437, Loss: 0.096965491771698
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 99 	Loss: 0.001006, lr: 0.000100, Time: 3.76s
Clean ACC: 10345/10630 = 0.973189, Loss: 0.09736521542072296
ASR: 10005/10005 = 1.000000


<Backdoor Training> Train Epoch: 100 	Loss: 0.002004, lr: 0.000100, Time: 3.78s
Clean ACC: 10340/10630 = 0.972719, Loss: 0.09684901684522629
ASR: 10005/10005 = 1.000000


Testing the backdoor model...
Evaluating model 'poisoned_train_set/gtsrb/badnet_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 10340/10630 = 0.972719, Loss: 0.09684901684522629
ASR: 10005/10005 = 1.000000

Visualizing the model's latent space...
Using method: umap
Visualizing model 'poisoned_train_set/gtsrb/badnet_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on gtsrb...
[test]
Clean ACC: 10340/10630 = 0.972719, Loss: 0.09685050696134567
ASR: 10005/10005 = 1.000000

Total Clean: 26374
Total Poisoned: 266
Saved figure at umap_assets/umap_gtsrb_badnet_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=2.png
Experiment for gtsrb with badnet completed.
