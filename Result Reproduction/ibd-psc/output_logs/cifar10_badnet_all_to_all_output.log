Creating poisoned training set for badnet_all_to_all on cifar10...
[target class : 0]
Files already downloaded and verified
trigger: ./triggers/badnet_patch_32.png
poison_indicies :  [6, 116, 244, 495, 639, 643, 777, 919, 1478, 1528, 1537, 1641, 1687, 1730, 1854, 1878, 1881, 2370, 2516, 2530, 2978, 3035, 3102, 3616, 4017, 4384, 4537, 4771, 4827, 4949, 5109, 5160, 5380, 5389, 5420, 5616, 5930, 6002, 6043, 6128, 6328, 6335, 6432, 6463, 6690, 6743, 6783, 7018, 7098, 7267, 7393, 7421, 7462, 7492, 7502, 7580, 7684, 7775, 8038, 8088, 8101, 8152, 8170, 8254, 8312, 8396, 8420, 8510, 8606, 8625, 8988, 9026, 9096, 9322, 9345, 9362, 9408, 9412, 9434, 9840, 9863, 9895, 10010, 10011, 10022, 10032, 10147, 10154, 10310, 10371, 10417, 10595, 10720, 10733, 10754, 11146, 11253, 11263, 11294, 11296, 11350, 11420, 11424, 11655, 11831, 11895, 11958, 11973, 11995, 12173, 12229, 12523, 12561, 12645, 12691, 12730, 12804, 12931, 12948, 13132, 13315, 13448, 13480, 13640, 13699, 13704, 13811, 13877, 14005, 14018, 14053, 14123, 14231, 14404, 14493, 14549, 14650, 14776, 14833, 14950, 15039, 15195, 15321, 15326, 15330, 15876, 15886, 15920, 16017, 16020, 16087, 16116, 16268, 16270, 16280, 16385, 16520, 16585, 16643, 16853, 16893, 17205, 17248, 17348, 17503, 17532, 17766, 17824, 18065, 18132, 18493, 18591, 18701, 18703, 18795, 18843, 18910, 18937, 19018, 19109, 19186, 19202, 19450, 19453, 19456, 19503, 19823, 19881, 19887, 19970, 20073, 20135, 20232, 20388, 20465, 20600, 20980, 20997, 21377, 21440, 21555, 21816, 21834, 21849, 22016, 22018, 22019, 22045, 22238, 22248, 22304, 22336, 22360, 22392, 22785, 22935, 22996, 23231, 23247, 23253, 23290, 23396, 23523, 23574, 23662, 23860, 23903, 23994, 24111, 24147, 24299, 24342, 24442, 24570, 24801, 24917, 24961, 25035, 25085, 25183, 25279, 25300, 25304, 25435, 25520, 25554, 25815, 25957, 26207, 26237, 26301, 26360, 26390, 26464, 26605, 26668, 26773, 26930, 26996, 27651, 27688, 27696, 27710, 27902, 28123, 28159, 28283, 28338, 28346, 28382, 28384, 28412, 28470, 28612, 28649, 28734, 28785, 28821, 28872, 29210, 29235, 29463, 29626, 29693, 29899, 29996, 30051, 30089, 30167, 30479, 30491, 30544, 30559, 30586, 30587, 30628, 30770, 30851, 30878, 30931, 31004, 31035, 31041, 31075, 31268, 31277, 31357, 31570, 31572, 31610, 31815, 32207, 32324, 32352, 32388, 32493, 32572, 32584, 32972, 33115, 33243, 33393, 33405, 33411, 33424, 33522, 33664, 33680, 33727, 33734, 33788, 33806, 33879, 33938, 34210, 34286, 34290, 34305, 34307, 34380, 34392, 34660, 34665, 34683, 35026, 35087, 35143, 35167, 35217, 35241, 35319, 35399, 35410, 35609, 35625, 35689, 35756, 36055, 36098, 36273, 36298, 36382, 36465, 36481, 36509, 36585, 36677, 36824, 36832, 37105, 37127, 37144, 37177, 37179, 37544, 37576, 37771, 37822, 38051, 38095, 38108, 38130, 38144, 38394, 38450, 38521, 38641, 38756, 38806, 38983, 39126, 39168, 39185, 39244, 39281, 39289, 39416, 39440, 39557, 39577, 39584, 39663, 39675, 39800, 39916, 39991, 40241, 40309, 40407, 40598, 40600, 40616, 40646, 40748, 40795, 40890, 40974, 40975, 41036, 41071, 41236, 41321, 41458, 41708, 41805, 41921, 42009, 42071, 42176, 42282, 42355, 42359, 42404, 42812, 43356, 43378, 43496, 43525, 43540, 43592, 43612, 44561, 44571, 44594, 44682, 44716, 44768, 44850, 44895, 44993, 45015, 45036, 45049, 45254, 45274, 45282, 45524, 45534, 45578, 45821, 45924, 46062, 46374, 46598, 46602, 46721, 46865, 47034, 47061, 47068, 47122, 47139, 47245, 47268, 47428, 47813, 47904, 47981, 47996, 48071, 48072, 48167, 48178, 48271, 48314, 48356, 48412, 48416, 48570, 48757, 48900, 49116, 49146, 49208, 49444, 49525, 49592, 49703, 49770, 49882]
[Generate Poisoned Set] Save 50000 Images
[Generate Poisoned Set] Save poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/imgs
[Generate Poisoned Set] Save poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/labels
[Generate Poisoned Set] Save poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/poison_indices
Training the model on the poisoned dataset...
dataset : poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/imgs
Will save to 'poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt'.
<Backdoor Training> Train Epoch: 1 	Loss: 1.561367, lr: 0.100000, Time: 10.22s
Clean ACC: 3579/8000 = 0.447375, Loss: 1.489971399307251
ASR: 409/8000 = 0.051125


<Backdoor Training> Train Epoch: 2 	Loss: 1.186981, lr: 0.100000, Time: 6.68s
Clean ACC: 3875/8000 = 0.484375, Loss: 1.5265198945999146
ASR: 403/8000 = 0.050375


<Backdoor Training> Train Epoch: 3 	Loss: 0.986151, lr: 0.100000, Time: 6.72s
Clean ACC: 5237/8000 = 0.654625, Loss: 0.9824863076210022
ASR: 305/8000 = 0.038125


<Backdoor Training> Train Epoch: 4 	Loss: 0.687155, lr: 0.100000, Time: 6.55s
Clean ACC: 5442/8000 = 0.680250, Loss: 0.9221504330635071
ASR: 311/8000 = 0.038875


<Backdoor Training> Train Epoch: 5 	Loss: 0.733670, lr: 0.100000, Time: 6.72s
Clean ACC: 6116/8000 = 0.764500, Loss: 0.6636467576026917
ASR: 204/8000 = 0.025500


<Backdoor Training> Train Epoch: 6 	Loss: 0.435795, lr: 0.100000, Time: 6.75s
Clean ACC: 6098/8000 = 0.762250, Loss: 0.6755678653717041
ASR: 156/8000 = 0.019500


<Backdoor Training> Train Epoch: 7 	Loss: 0.634045, lr: 0.100000, Time: 6.63s
Clean ACC: 6422/8000 = 0.802750, Loss: 0.5758764147758484
ASR: 165/8000 = 0.020625


<Backdoor Training> Train Epoch: 8 	Loss: 0.423486, lr: 0.100000, Time: 6.43s
Clean ACC: 6427/8000 = 0.803375, Loss: 0.5807008147239685
ASR: 197/8000 = 0.024625


<Backdoor Training> Train Epoch: 9 	Loss: 0.377881, lr: 0.100000, Time: 6.30s
Clean ACC: 6711/8000 = 0.838875, Loss: 0.4828605055809021
ASR: 228/8000 = 0.028500


<Backdoor Training> Train Epoch: 10 	Loss: 0.415140, lr: 0.100000, Time: 6.23s
Clean ACC: 6813/8000 = 0.851625, Loss: 0.43202120065689087
ASR: 390/8000 = 0.048750


<Backdoor Training> Train Epoch: 11 	Loss: 0.244983, lr: 0.100000, Time: 6.48s
Clean ACC: 6788/8000 = 0.848500, Loss: 0.4842776954174042
ASR: 609/8000 = 0.076125


<Backdoor Training> Train Epoch: 12 	Loss: 0.443504, lr: 0.100000, Time: 6.73s
Clean ACC: 6738/8000 = 0.842250, Loss: 0.46203503012657166
ASR: 2713/8000 = 0.339125


<Backdoor Training> Train Epoch: 13 	Loss: 0.491037, lr: 0.100000, Time: 6.71s
Clean ACC: 6770/8000 = 0.846250, Loss: 0.45268359780311584
ASR: 4110/8000 = 0.513750


<Backdoor Training> Train Epoch: 14 	Loss: 0.158873, lr: 0.100000, Time: 6.68s
Clean ACC: 6759/8000 = 0.844875, Loss: 0.4822530448436737
ASR: 4666/8000 = 0.583250


<Backdoor Training> Train Epoch: 15 	Loss: 0.283271, lr: 0.100000, Time: 6.68s
Clean ACC: 6815/8000 = 0.851875, Loss: 0.44796258211135864
ASR: 4982/8000 = 0.622750


<Backdoor Training> Train Epoch: 16 	Loss: 0.363551, lr: 0.100000, Time: 6.74s
Clean ACC: 6910/8000 = 0.863750, Loss: 0.4191994071006775
ASR: 4508/8000 = 0.563500


<Backdoor Training> Train Epoch: 17 	Loss: 0.274278, lr: 0.100000, Time: 6.61s
Clean ACC: 6807/8000 = 0.850875, Loss: 0.4461100101470947
ASR: 5603/8000 = 0.700375


<Backdoor Training> Train Epoch: 18 	Loss: 0.322899, lr: 0.100000, Time: 6.63s
Clean ACC: 7020/8000 = 0.877500, Loss: 0.3598063886165619
ASR: 6261/8000 = 0.782625


<Backdoor Training> Train Epoch: 19 	Loss: 0.289329, lr: 0.100000, Time: 6.50s
Clean ACC: 6893/8000 = 0.861625, Loss: 0.4273240268230438
ASR: 6170/8000 = 0.771250


<Backdoor Training> Train Epoch: 20 	Loss: 0.204852, lr: 0.100000, Time: 6.40s
Clean ACC: 6949/8000 = 0.868625, Loss: 0.4158741235733032
ASR: 5016/8000 = 0.627000


<Backdoor Training> Train Epoch: 21 	Loss: 0.221536, lr: 0.100000, Time: 6.25s
Clean ACC: 7109/8000 = 0.888625, Loss: 0.3340676724910736
ASR: 6100/8000 = 0.762500


<Backdoor Training> Train Epoch: 22 	Loss: 0.158924, lr: 0.100000, Time: 6.40s
Clean ACC: 7068/8000 = 0.883500, Loss: 0.37483736872673035
ASR: 6607/8000 = 0.825875


<Backdoor Training> Train Epoch: 23 	Loss: 0.254276, lr: 0.100000, Time: 6.35s
Clean ACC: 6968/8000 = 0.871000, Loss: 0.39660951495170593
ASR: 5603/8000 = 0.700375


<Backdoor Training> Train Epoch: 24 	Loss: 0.119660, lr: 0.100000, Time: 6.88s
Clean ACC: 7093/8000 = 0.886625, Loss: 0.35846126079559326
ASR: 6615/8000 = 0.826875


<Backdoor Training> Train Epoch: 25 	Loss: 0.141047, lr: 0.100000, Time: 6.84s
Clean ACC: 7049/8000 = 0.881125, Loss: 0.3808799386024475
ASR: 6517/8000 = 0.814625


<Backdoor Training> Train Epoch: 26 	Loss: 0.149990, lr: 0.100000, Time: 6.63s
Clean ACC: 7090/8000 = 0.886250, Loss: 0.3577324151992798
ASR: 6533/8000 = 0.816625


<Backdoor Training> Train Epoch: 27 	Loss: 0.206343, lr: 0.100000, Time: 6.71s
Clean ACC: 7031/8000 = 0.878875, Loss: 0.3851923644542694
ASR: 6367/8000 = 0.795875


<Backdoor Training> Train Epoch: 28 	Loss: 0.274420, lr: 0.100000, Time: 6.70s
Clean ACC: 7073/8000 = 0.884125, Loss: 0.36937907338142395
ASR: 6679/8000 = 0.834875


<Backdoor Training> Train Epoch: 29 	Loss: 0.197172, lr: 0.100000, Time: 6.70s
Clean ACC: 7146/8000 = 0.893250, Loss: 0.33289822936058044
ASR: 6795/8000 = 0.849375


<Backdoor Training> Train Epoch: 30 	Loss: 0.171777, lr: 0.100000, Time: 6.57s
Clean ACC: 7072/8000 = 0.884000, Loss: 0.40043097734451294
ASR: 6196/8000 = 0.774500


<Backdoor Training> Train Epoch: 31 	Loss: 0.199723, lr: 0.100000, Time: 6.15s
Clean ACC: 7159/8000 = 0.894875, Loss: 0.3513818383216858
ASR: 6341/8000 = 0.792625


<Backdoor Training> Train Epoch: 32 	Loss: 0.282194, lr: 0.100000, Time: 6.20s
Clean ACC: 7167/8000 = 0.895875, Loss: 0.3312762975692749
ASR: 5770/8000 = 0.721250


<Backdoor Training> Train Epoch: 33 	Loss: 0.254552, lr: 0.100000, Time: 6.32s
Clean ACC: 6918/8000 = 0.864750, Loss: 0.46217241883277893
ASR: 5252/8000 = 0.656500


<Backdoor Training> Train Epoch: 34 	Loss: 0.173275, lr: 0.100000, Time: 6.38s
Clean ACC: 7072/8000 = 0.884000, Loss: 0.40164387226104736
ASR: 6275/8000 = 0.784375


<Backdoor Training> Train Epoch: 35 	Loss: 0.235744, lr: 0.100000, Time: 6.54s
Clean ACC: 6932/8000 = 0.866500, Loss: 0.47953152656555176
ASR: 6425/8000 = 0.803125


<Backdoor Training> Train Epoch: 36 	Loss: 0.359637, lr: 0.100000, Time: 6.79s
Clean ACC: 7062/8000 = 0.882750, Loss: 0.40042248368263245
ASR: 6394/8000 = 0.799250


<Backdoor Training> Train Epoch: 37 	Loss: 0.116521, lr: 0.100000, Time: 6.71s
Clean ACC: 7116/8000 = 0.889500, Loss: 0.3441385328769684
ASR: 6707/8000 = 0.838375


<Backdoor Training> Train Epoch: 38 	Loss: 0.152979, lr: 0.100000, Time: 6.69s
Clean ACC: 7124/8000 = 0.890500, Loss: 0.3792498707771301
ASR: 6628/8000 = 0.828500


<Backdoor Training> Train Epoch: 39 	Loss: 0.223276, lr: 0.100000, Time: 6.69s
Clean ACC: 6965/8000 = 0.870625, Loss: 0.46946829557418823
ASR: 6256/8000 = 0.782000


<Backdoor Training> Train Epoch: 40 	Loss: 0.226413, lr: 0.100000, Time: 6.58s
Clean ACC: 7157/8000 = 0.894625, Loss: 0.3402497172355652
ASR: 6315/8000 = 0.789375


<Backdoor Training> Train Epoch: 41 	Loss: 0.258879, lr: 0.100000, Time: 6.96s
Clean ACC: 7096/8000 = 0.887000, Loss: 0.3907693326473236
ASR: 6681/8000 = 0.835125


<Backdoor Training> Train Epoch: 42 	Loss: 0.092693, lr: 0.100000, Time: 6.40s
Clean ACC: 7180/8000 = 0.897500, Loss: 0.3389325737953186
ASR: 5410/8000 = 0.676250


<Backdoor Training> Train Epoch: 43 	Loss: 0.212488, lr: 0.100000, Time: 6.34s
Clean ACC: 7202/8000 = 0.900250, Loss: 0.3562372624874115
ASR: 6914/8000 = 0.864250


<Backdoor Training> Train Epoch: 44 	Loss: 0.248589, lr: 0.100000, Time: 6.23s
Clean ACC: 7242/8000 = 0.905250, Loss: 0.3165735602378845
ASR: 6837/8000 = 0.854625


<Backdoor Training> Train Epoch: 45 	Loss: 0.291490, lr: 0.100000, Time: 6.39s
Clean ACC: 7046/8000 = 0.880750, Loss: 0.4212486445903778
ASR: 5190/8000 = 0.648750


<Backdoor Training> Train Epoch: 46 	Loss: 0.117009, lr: 0.100000, Time: 6.41s
Clean ACC: 7096/8000 = 0.887000, Loss: 0.38372913002967834
ASR: 6746/8000 = 0.843250


<Backdoor Training> Train Epoch: 47 	Loss: 0.234088, lr: 0.100000, Time: 6.65s
Clean ACC: 7132/8000 = 0.891500, Loss: 0.3740904629230499
ASR: 6803/8000 = 0.850375


<Backdoor Training> Train Epoch: 48 	Loss: 0.255583, lr: 0.100000, Time: 6.74s
Clean ACC: 7151/8000 = 0.893875, Loss: 0.36415573954582214
ASR: 6770/8000 = 0.846250


<Backdoor Training> Train Epoch: 49 	Loss: 0.118512, lr: 0.100000, Time: 6.71s
Clean ACC: 7036/8000 = 0.879500, Loss: 0.4225654900074005
ASR: 6525/8000 = 0.815625


<Backdoor Training> Train Epoch: 50 	Loss: 0.097372, lr: 0.100000, Time: 6.77s
Clean ACC: 7140/8000 = 0.892500, Loss: 0.3570128381252289
ASR: 6543/8000 = 0.817875


<Backdoor Training> Train Epoch: 51 	Loss: 0.029338, lr: 0.010000, Time: 6.64s
Clean ACC: 7463/8000 = 0.932875, Loss: 0.2175959199666977
ASR: 7264/8000 = 0.908000


<Backdoor Training> Train Epoch: 52 	Loss: 0.020401, lr: 0.010000, Time: 6.82s
Clean ACC: 7483/8000 = 0.935375, Loss: 0.2195778787136078
ASR: 7326/8000 = 0.915750


<Backdoor Training> Train Epoch: 53 	Loss: 0.046399, lr: 0.010000, Time: 6.71s
Clean ACC: 7500/8000 = 0.937500, Loss: 0.22345921397209167
ASR: 7357/8000 = 0.919625


<Backdoor Training> Train Epoch: 54 	Loss: 0.009134, lr: 0.010000, Time: 6.26s
Clean ACC: 7503/8000 = 0.937875, Loss: 0.225358784198761
ASR: 7339/8000 = 0.917375


<Backdoor Training> Train Epoch: 55 	Loss: 0.035038, lr: 0.010000, Time: 6.25s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.23367907106876373
ASR: 7349/8000 = 0.918625


<Backdoor Training> Train Epoch: 56 	Loss: 0.068329, lr: 0.010000, Time: 6.39s
Clean ACC: 7506/8000 = 0.938250, Loss: 0.23596014082431793
ASR: 7340/8000 = 0.917500


<Backdoor Training> Train Epoch: 57 	Loss: 0.019836, lr: 0.010000, Time: 6.35s
Clean ACC: 7493/8000 = 0.936625, Loss: 0.23622611165046692
ASR: 7375/8000 = 0.921875


<Backdoor Training> Train Epoch: 58 	Loss: 0.135326, lr: 0.010000, Time: 6.41s
Clean ACC: 7512/8000 = 0.939000, Loss: 0.23860232532024384
ASR: 7370/8000 = 0.921250


<Backdoor Training> Train Epoch: 59 	Loss: 0.046674, lr: 0.010000, Time: 6.59s
Clean ACC: 7491/8000 = 0.936375, Loss: 0.24547630548477173
ASR: 7364/8000 = 0.920500


<Backdoor Training> Train Epoch: 60 	Loss: 0.010657, lr: 0.010000, Time: 6.75s
Clean ACC: 7502/8000 = 0.937750, Loss: 0.24302342534065247
ASR: 7372/8000 = 0.921500


<Backdoor Training> Train Epoch: 61 	Loss: 0.110864, lr: 0.010000, Time: 6.59s
Clean ACC: 7506/8000 = 0.938250, Loss: 0.24362754821777344
ASR: 7383/8000 = 0.922875


<Backdoor Training> Train Epoch: 62 	Loss: 0.010827, lr: 0.010000, Time: 6.60s
Clean ACC: 7494/8000 = 0.936750, Loss: 0.2492985874414444
ASR: 7364/8000 = 0.920500


<Backdoor Training> Train Epoch: 63 	Loss: 0.015365, lr: 0.010000, Time: 6.80s
Clean ACC: 7504/8000 = 0.938000, Loss: 0.25121718645095825
ASR: 7362/8000 = 0.920250


<Backdoor Training> Train Epoch: 64 	Loss: 0.037675, lr: 0.010000, Time: 6.72s
Clean ACC: 7509/8000 = 0.938625, Loss: 0.2552717328071594
ASR: 7358/8000 = 0.919750


<Backdoor Training> Train Epoch: 65 	Loss: 0.007737, lr: 0.010000, Time: 6.49s
Clean ACC: 7506/8000 = 0.938250, Loss: 0.254986435174942
ASR: 7334/8000 = 0.916750


<Backdoor Training> Train Epoch: 66 	Loss: 0.014864, lr: 0.010000, Time: 6.36s
Clean ACC: 7498/8000 = 0.937250, Loss: 0.2545074224472046
ASR: 7357/8000 = 0.919625


<Backdoor Training> Train Epoch: 67 	Loss: 0.005523, lr: 0.010000, Time: 6.34s
Clean ACC: 7511/8000 = 0.938875, Loss: 0.26077407598495483
ASR: 7369/8000 = 0.921125


<Backdoor Training> Train Epoch: 68 	Loss: 0.003626, lr: 0.010000, Time: 6.32s
Clean ACC: 7496/8000 = 0.937000, Loss: 0.267587274312973
ASR: 7351/8000 = 0.918875


<Backdoor Training> Train Epoch: 69 	Loss: 0.005751, lr: 0.010000, Time: 6.39s
Clean ACC: 7497/8000 = 0.937125, Loss: 0.26817670464515686
ASR: 7352/8000 = 0.919000


<Backdoor Training> Train Epoch: 70 	Loss: 0.002923, lr: 0.010000, Time: 6.79s
Clean ACC: 7511/8000 = 0.938875, Loss: 0.2681441605091095
ASR: 7316/8000 = 0.914500


<Backdoor Training> Train Epoch: 71 	Loss: 0.023759, lr: 0.010000, Time: 6.87s
Clean ACC: 7514/8000 = 0.939250, Loss: 0.2683332562446594
ASR: 7330/8000 = 0.916250


<Backdoor Training> Train Epoch: 72 	Loss: 0.005480, lr: 0.010000, Time: 6.72s
Clean ACC: 7507/8000 = 0.938375, Loss: 0.27029815316200256
ASR: 7344/8000 = 0.918000


<Backdoor Training> Train Epoch: 73 	Loss: 0.003351, lr: 0.010000, Time: 6.66s
Clean ACC: 7492/8000 = 0.936500, Loss: 0.2736755311489105
ASR: 7305/8000 = 0.913125


<Backdoor Training> Train Epoch: 74 	Loss: 0.012681, lr: 0.010000, Time: 6.61s
Clean ACC: 7505/8000 = 0.938125, Loss: 0.2748047709465027
ASR: 7303/8000 = 0.912875


<Backdoor Training> Train Epoch: 75 	Loss: 0.004863, lr: 0.010000, Time: 6.66s
Clean ACC: 7516/8000 = 0.939500, Loss: 0.2702663540840149
ASR: 7222/8000 = 0.902750


<Backdoor Training> Train Epoch: 76 	Loss: 0.004417, lr: 0.001000, Time: 6.71s
Clean ACC: 7504/8000 = 0.938000, Loss: 0.2714037597179413
ASR: 7299/8000 = 0.912375


<Backdoor Training> Train Epoch: 77 	Loss: 0.006278, lr: 0.001000, Time: 6.37s
Clean ACC: 7510/8000 = 0.938750, Loss: 0.2706229090690613
ASR: 7282/8000 = 0.910250


<Backdoor Training> Train Epoch: 78 	Loss: 0.007301, lr: 0.001000, Time: 6.31s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.27058902382850647
ASR: 7269/8000 = 0.908625


<Backdoor Training> Train Epoch: 79 	Loss: 0.069064, lr: 0.001000, Time: 6.18s
Clean ACC: 7512/8000 = 0.939000, Loss: 0.27049383521080017
ASR: 7282/8000 = 0.910250


<Backdoor Training> Train Epoch: 80 	Loss: 0.003984, lr: 0.001000, Time: 6.33s
Clean ACC: 7509/8000 = 0.938625, Loss: 0.27073943614959717
ASR: 7281/8000 = 0.910125


<Backdoor Training> Train Epoch: 81 	Loss: 0.006664, lr: 0.001000, Time: 6.42s
Clean ACC: 7508/8000 = 0.938500, Loss: 0.26840707659721375
ASR: 7287/8000 = 0.910875


<Backdoor Training> Train Epoch: 82 	Loss: 0.003517, lr: 0.001000, Time: 6.71s
Clean ACC: 7519/8000 = 0.939875, Loss: 0.27009323239326477
ASR: 7274/8000 = 0.909250


<Backdoor Training> Train Epoch: 83 	Loss: 0.002084, lr: 0.001000, Time: 6.73s
Clean ACC: 7503/8000 = 0.937875, Loss: 0.2707225978374481
ASR: 7263/8000 = 0.907875


<Backdoor Training> Train Epoch: 84 	Loss: 0.007105, lr: 0.001000, Time: 6.68s
Clean ACC: 7516/8000 = 0.939500, Loss: 0.2700555622577667
ASR: 7292/8000 = 0.911500


<Backdoor Training> Train Epoch: 85 	Loss: 0.005091, lr: 0.001000, Time: 6.86s
Clean ACC: 7502/8000 = 0.937750, Loss: 0.274075448513031
ASR: 7275/8000 = 0.909375


<Backdoor Training> Train Epoch: 86 	Loss: 0.007245, lr: 0.001000, Time: 6.68s
Clean ACC: 7508/8000 = 0.938500, Loss: 0.27237093448638916
ASR: 7277/8000 = 0.909625


<Backdoor Training> Train Epoch: 87 	Loss: 0.001681, lr: 0.001000, Time: 6.83s
Clean ACC: 7506/8000 = 0.938250, Loss: 0.2717163562774658
ASR: 7275/8000 = 0.909375


<Backdoor Training> Train Epoch: 88 	Loss: 0.070424, lr: 0.001000, Time: 6.45s
Clean ACC: 7511/8000 = 0.938875, Loss: 0.27055200934410095
ASR: 7275/8000 = 0.909375


<Backdoor Training> Train Epoch: 89 	Loss: 0.005997, lr: 0.001000, Time: 6.31s
Clean ACC: 7502/8000 = 0.937750, Loss: 0.2717168927192688
ASR: 7234/8000 = 0.904250


<Backdoor Training> Train Epoch: 90 	Loss: 0.026674, lr: 0.001000, Time: 6.36s
Clean ACC: 7505/8000 = 0.938125, Loss: 0.27188968658447266
ASR: 7246/8000 = 0.905750


<Backdoor Training> Train Epoch: 91 	Loss: 0.063688, lr: 0.001000, Time: 6.31s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.2724710702896118
ASR: 7228/8000 = 0.903500


<Backdoor Training> Train Epoch: 92 	Loss: 0.019743, lr: 0.001000, Time: 6.33s
Clean ACC: 7509/8000 = 0.938625, Loss: 0.27181121706962585
ASR: 7191/8000 = 0.898875


<Backdoor Training> Train Epoch: 93 	Loss: 0.010874, lr: 0.001000, Time: 6.70s
Clean ACC: 7512/8000 = 0.939000, Loss: 0.27303165197372437
ASR: 7224/8000 = 0.903000


<Backdoor Training> Train Epoch: 94 	Loss: 0.004956, lr: 0.001000, Time: 6.71s
Clean ACC: 7515/8000 = 0.939375, Loss: 0.2713439166545868
ASR: 7220/8000 = 0.902500


<Backdoor Training> Train Epoch: 95 	Loss: 0.001949, lr: 0.001000, Time: 6.76s
Clean ACC: 7502/8000 = 0.937750, Loss: 0.273539662361145
ASR: 7228/8000 = 0.903500


<Backdoor Training> Train Epoch: 96 	Loss: 0.013877, lr: 0.001000, Time: 6.61s
Clean ACC: 7514/8000 = 0.939250, Loss: 0.26969072222709656
ASR: 7208/8000 = 0.901000


<Backdoor Training> Train Epoch: 97 	Loss: 0.012021, lr: 0.001000, Time: 6.69s
Clean ACC: 7510/8000 = 0.938750, Loss: 0.2724842131137848
ASR: 7201/8000 = 0.900125


<Backdoor Training> Train Epoch: 98 	Loss: 0.006297, lr: 0.001000, Time: 6.62s
Clean ACC: 7517/8000 = 0.939625, Loss: 0.2723396420478821
ASR: 7201/8000 = 0.900125


<Backdoor Training> Train Epoch: 99 	Loss: 0.014612, lr: 0.001000, Time: 6.75s
Clean ACC: 7506/8000 = 0.938250, Loss: 0.27383145689964294
ASR: 7213/8000 = 0.901625


<Backdoor Training> Train Epoch: 100 	Loss: 0.030927, lr: 0.001000, Time: 6.40s
Clean ACC: 7503/8000 = 0.937875, Loss: 0.271363228559494
ASR: 7185/8000 = 0.898125


Testing the backdoor model...
Evaluating model 'poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 7503/8000 = 0.937875, Loss: 0.271363228559494
ASR: 7185/8000 = 0.898125

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7503/8000 = 0.937875, Loss: 0.2713717222213745
ASR: 848/7263 = 0.116756

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.062468, poison_dis: 11.246922
Silhouette Score: 0.6278863
Saved figure at assets/pca_cifar10_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7503/8000 = 0.937875, Loss: 0.2713717222213745
ASR: 848/7263 = 0.116756

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.062468, poison_dis: 11.246922
Silhouette Score: 0.6278863
Saved figure at assets/tsne_cifar10_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7503/8000 = 0.937875, Loss: 0.2713717222213745
ASR: 848/7263 = 0.116756

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.062468, poison_dis: 11.246922
Silhouette Score: 0.6278863
SVM Accuracy: 1.0
Saved figure at assets/oracle_cifar10_badnet_all_to_all_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/badnet_patch_32.png
trigger_mask_path: ./triggers/mask_badnet_patch_32.png
Evaluating model 'poisoned_train_set/cifar10/badnet_all_to_all_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 93.78750610351562
asr: 89.48978424072266
target label: tensor([6], device='cuda:0')
start_index: 10
TPR: 7.45
FPR: 6.01
AUC: 0.5382
f1 score: 0.131320921009144
Elapsed time: 19.47s
Experiment for cifar10 with badnet_all_to_all completed.
