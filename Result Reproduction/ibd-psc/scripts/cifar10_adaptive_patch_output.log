Creating poisoned training set for adaptive_patch on cifar10...
[target class : 0]
Files already downloaded and verified
Trigger #0: phoenix_corner_32.png
Trigger #1: firefox_corner_32.png
Trigger #2: badnet_patch4_32.png
Trigger #3: trojan_square_32.png
Poison indices: [6, 116, 244, 495, 639, 643, 777, 919, 1478, 1528, 1537, 1641, 1687, 1730, 1854, 1878, 1881, 2370, 2516, 2530, 2978, 3035, 3102, 3616, 4017, 4384, 4537, 4771, 4827, 4949, 5109, 5160, 5380, 5389, 5420, 5616, 5930, 6002, 6043, 6128, 6328, 6335, 6432, 6463, 6690, 6743, 6783, 7018, 7098, 7267, 7393, 7421, 7462, 7492, 7502, 7580, 7684, 7775, 8038, 8088, 8101, 8152, 8170, 8254, 8312, 8396, 8420, 8510, 8606, 8625, 8988, 9026, 9096, 9322, 9345, 9362, 9408, 9412, 9434, 9840, 9863, 9895, 10010, 10011, 10022, 10032, 10147, 10154, 10310, 10371, 10417, 10595, 10720, 10733, 10754, 11146, 11253, 11263, 11294, 11296, 11350, 11420, 11424, 11655, 11831, 11895, 11958, 11973, 11995, 12173, 12229, 12523, 12561, 12645, 12691, 12730, 12804, 12931, 12948, 13132, 13315, 13448, 13480, 13640, 13699, 13704, 13811, 13877, 14005, 14018, 14053, 14123, 14231, 14404, 14493, 14549, 14650, 14776, 14833, 14950, 15039, 15195, 15321, 15326, 15330, 15876, 15886, 15920, 16017, 16020, 16087, 16116, 16268, 16270, 16280, 16385, 16520, 16585, 16643, 16853, 16893, 17205, 17248, 17348, 17503, 17532, 17766, 17824, 18065, 18132, 18493, 18591, 18701, 18703, 18795, 18843, 18910, 18937, 19018, 19109, 19186, 19202, 19450, 19453, 19456, 19503, 19823, 19881, 19887, 19970, 20073, 20135, 20232, 20388, 20465, 20600, 20980, 20997, 21377, 21440, 21555, 21816, 21834, 21849, 22016, 22018, 22019, 22045, 22238, 22248, 22304, 22336, 22360, 22392, 22785, 22935, 22996, 23231, 23247, 23253, 23290, 23396, 23523, 23574, 23662, 23860, 23903, 23994, 24111, 24147, 24299, 24342, 24442, 24570, 24801, 24917, 24961, 25035, 25085, 25183, 25279, 25300, 25304, 25435, 25520, 25554, 25815, 25957, 26207, 26237, 26301, 26360, 26390, 26464, 26605, 26668, 26773, 26930, 26996, 27651, 27688, 27696, 27710, 27902, 28123, 28159, 28283, 28338, 28346, 28382, 28384, 28412, 28470, 28612, 28649, 28734, 28785, 28821, 28872, 29210, 29235, 29463, 29626, 29693, 29899, 29996, 30051, 30089, 30167, 30479, 30491, 30544, 30559, 30586, 30587, 30628, 30770, 30851, 30878, 30931, 31004, 31035, 31041, 31075, 31268, 31277, 31357, 31570, 31572, 31610, 31815, 32207, 32324, 32352, 32388, 32493, 32572, 32584, 32972, 33115, 33243, 33393, 33405, 33411, 33424, 33522, 33664, 33680, 33727, 33734, 33788, 33806, 33879, 33938, 34210, 34286, 34290, 34305, 34307, 34380, 34392, 34660, 34665, 34683, 35026, 35087, 35143, 35167, 35217, 35241, 35319, 35399, 35410, 35609, 35625, 35689, 35756, 36055, 36098, 36273, 36298, 36382, 36465, 36481, 36509, 36585, 36677, 36824, 36832, 37105, 37127, 37144, 37177, 37179, 37544, 37576, 37771, 37822, 38051, 38095, 38108, 38130, 38144, 38394, 38450, 38521, 38641, 38756, 38806, 38983, 39126, 39168, 39185, 39244, 39281, 39289, 39416, 39440, 39557, 39577, 39584, 39663, 39675, 39800, 39916, 39991, 40241, 40309, 40407, 40598, 40600, 40616, 40646, 40748, 40795, 40890, 40974, 40975, 41036, 41071, 41236, 41321, 41458, 41708, 41805, 41921, 42009, 42071, 42176, 42282, 42355, 42359, 42404, 42812, 43356, 43378, 43496, 43525, 43540, 43592, 43612, 44561, 44571, 44594, 44682, 44716, 44768, 44850, 44895, 44993, 45015, 45036, 45049, 45254, 45274, 45282, 45524, 45534, 45578, 45821, 45924, 46062, 46374, 46598, 46602, 46721, 46865, 47034, 47061, 47068, 47122, 47139, 47245, 47268, 47428, 47813, 47904, 47981, 47996, 48071, 48072, 48167, 48178, 48271, 48314, 48356, 48412, 48416, 48570, 48757, 48900, 49116, 49146, 49208, 49444, 49525, 49592, 49703, 49770, 49882]
Cover indices: []
[Generate Poisoned Set] Save 50000 Images
[Generate Poisoned Set] Save poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/cover_indices
[Generate Poisoned Set] Save poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/imgs
[Generate Poisoned Set] Save poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/labels
[Generate Poisoned Set] Save poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/poison_indices
Training the model on the poisoned dataset...
dataset : poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/imgs
Will save to 'poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt'.
<Backdoor Training> Train Epoch: 1 	Loss: 1.689814, lr: 0.100000, Time: 7.58s
Clean ACC: 2912/8000 = 0.364000, Loss: 1.6834893226623535
ASR: 1180/7193 = 0.164048


<Backdoor Training> Train Epoch: 2 	Loss: 1.324304, lr: 0.100000, Time: 6.69s
Clean ACC: 3747/8000 = 0.468375, Loss: 1.4765032529830933
ASR: 322/7193 = 0.044766


<Backdoor Training> Train Epoch: 3 	Loss: 1.402205, lr: 0.100000, Time: 6.73s
Clean ACC: 4326/8000 = 0.540750, Loss: 1.2662532329559326
ASR: 610/7193 = 0.084805


<Backdoor Training> Train Epoch: 4 	Loss: 1.082775, lr: 0.100000, Time: 6.65s
Clean ACC: 4852/8000 = 0.606500, Loss: 1.1028047800064087
ASR: 344/7193 = 0.047824


<Backdoor Training> Train Epoch: 5 	Loss: 0.889646, lr: 0.100000, Time: 6.65s
Clean ACC: 5369/8000 = 0.671125, Loss: 0.9432169795036316
ASR: 593/7193 = 0.082441


<Backdoor Training> Train Epoch: 6 	Loss: 1.035331, lr: 0.100000, Time: 6.79s
Clean ACC: 5732/8000 = 0.716500, Loss: 0.8406531810760498
ASR: 465/7193 = 0.064646


<Backdoor Training> Train Epoch: 7 	Loss: 0.767842, lr: 0.100000, Time: 6.34s
Clean ACC: 6000/8000 = 0.750000, Loss: 0.7064394354820251
ASR: 59/7193 = 0.008202


<Backdoor Training> Train Epoch: 8 	Loss: 0.623121, lr: 0.100000, Time: 6.37s
Clean ACC: 6118/8000 = 0.764750, Loss: 0.6772370934486389
ASR: 369/7193 = 0.051300


<Backdoor Training> Train Epoch: 9 	Loss: 0.583862, lr: 0.100000, Time: 6.48s
Clean ACC: 6063/8000 = 0.757875, Loss: 0.7055720090866089
ASR: 167/7193 = 0.023217


<Backdoor Training> Train Epoch: 10 	Loss: 0.486732, lr: 0.100000, Time: 6.30s
Clean ACC: 6283/8000 = 0.785375, Loss: 0.6339960098266602
ASR: 121/7193 = 0.016822


<Backdoor Training> Train Epoch: 11 	Loss: 0.351320, lr: 0.100000, Time: 6.26s
Clean ACC: 6576/8000 = 0.822000, Loss: 0.509999692440033
ASR: 153/7193 = 0.021271


<Backdoor Training> Train Epoch: 12 	Loss: 0.440666, lr: 0.100000, Time: 6.72s
Clean ACC: 6509/8000 = 0.813625, Loss: 0.5607256293296814
ASR: 401/7193 = 0.055749


<Backdoor Training> Train Epoch: 13 	Loss: 0.301177, lr: 0.100000, Time: 6.78s
Clean ACC: 6590/8000 = 0.823750, Loss: 0.5205934643745422
ASR: 526/7193 = 0.073127


<Backdoor Training> Train Epoch: 14 	Loss: 0.520439, lr: 0.100000, Time: 6.67s
Clean ACC: 6654/8000 = 0.831750, Loss: 0.5069975852966309
ASR: 1027/7193 = 0.142778


<Backdoor Training> Train Epoch: 15 	Loss: 0.455872, lr: 0.100000, Time: 6.60s
Clean ACC: 6688/8000 = 0.836000, Loss: 0.5044398903846741
ASR: 1150/7193 = 0.159878


<Backdoor Training> Train Epoch: 16 	Loss: 0.347305, lr: 0.100000, Time: 6.72s
Clean ACC: 6807/8000 = 0.850875, Loss: 0.4574272632598877
ASR: 6326/7193 = 0.879466


<Backdoor Training> Train Epoch: 17 	Loss: 0.402541, lr: 0.100000, Time: 6.81s
Clean ACC: 6677/8000 = 0.834625, Loss: 0.5113598108291626
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 18 	Loss: 0.269319, lr: 0.100000, Time: 6.68s
Clean ACC: 6787/8000 = 0.848375, Loss: 0.4701475501060486
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 19 	Loss: 0.213122, lr: 0.100000, Time: 6.39s
Clean ACC: 6886/8000 = 0.860750, Loss: 0.4211522042751312
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 20 	Loss: 0.318618, lr: 0.100000, Time: 6.33s
Clean ACC: 6978/8000 = 0.872250, Loss: 0.3986370265483856
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 21 	Loss: 0.325252, lr: 0.100000, Time: 6.27s
Clean ACC: 6917/8000 = 0.864625, Loss: 0.41007500886917114
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 22 	Loss: 0.082889, lr: 0.100000, Time: 6.39s
Clean ACC: 6919/8000 = 0.864875, Loss: 0.4296886920928955
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 23 	Loss: 0.217582, lr: 0.100000, Time: 6.68s
Clean ACC: 6865/8000 = 0.858125, Loss: 0.45380228757858276
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 24 	Loss: 0.309779, lr: 0.100000, Time: 6.61s
Clean ACC: 6832/8000 = 0.854000, Loss: 0.44798603653907776
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 25 	Loss: 0.211186, lr: 0.100000, Time: 6.70s
Clean ACC: 6956/8000 = 0.869500, Loss: 0.4031209945678711
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 26 	Loss: 0.225301, lr: 0.100000, Time: 6.68s
Clean ACC: 6987/8000 = 0.873375, Loss: 0.3954799175262451
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 27 	Loss: 0.363625, lr: 0.100000, Time: 6.78s
Clean ACC: 7053/8000 = 0.881625, Loss: 0.367823988199234
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 28 	Loss: 0.224860, lr: 0.100000, Time: 6.84s
Clean ACC: 7100/8000 = 0.887500, Loss: 0.35112279653549194
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 29 	Loss: 0.171675, lr: 0.100000, Time: 6.73s
Clean ACC: 7020/8000 = 0.877500, Loss: 0.38856449723243713
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 30 	Loss: 0.167560, lr: 0.100000, Time: 6.45s
Clean ACC: 6959/8000 = 0.869875, Loss: 0.4269975423812866
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 31 	Loss: 0.204233, lr: 0.100000, Time: 6.29s
Clean ACC: 7020/8000 = 0.877500, Loss: 0.40552589297294617
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 32 	Loss: 0.229308, lr: 0.100000, Time: 6.36s
Clean ACC: 7091/8000 = 0.886375, Loss: 0.3442040979862213
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 33 	Loss: 0.071502, lr: 0.100000, Time: 6.31s
Clean ACC: 7100/8000 = 0.887500, Loss: 0.35572710633277893
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 34 	Loss: 0.148241, lr: 0.100000, Time: 6.49s
Clean ACC: 6914/8000 = 0.864250, Loss: 0.45458102226257324
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 35 	Loss: 0.161987, lr: 0.100000, Time: 6.61s
Clean ACC: 6979/8000 = 0.872375, Loss: 0.41556623578071594
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 36 	Loss: 0.121112, lr: 0.100000, Time: 6.72s
Clean ACC: 7023/8000 = 0.877875, Loss: 0.4020257592201233
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 37 	Loss: 0.256232, lr: 0.100000, Time: 6.69s
Clean ACC: 7083/8000 = 0.885375, Loss: 0.3715631365776062
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 38 	Loss: 0.210889, lr: 0.100000, Time: 6.78s
Clean ACC: 7109/8000 = 0.888625, Loss: 0.3626241981983185
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 39 	Loss: 0.311216, lr: 0.100000, Time: 6.76s
Clean ACC: 7059/8000 = 0.882375, Loss: 0.39412248134613037
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 40 	Loss: 0.208405, lr: 0.100000, Time: 6.62s
Clean ACC: 7072/8000 = 0.884000, Loss: 0.38846534490585327
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 41 	Loss: 0.108080, lr: 0.100000, Time: 6.37s
Clean ACC: 7104/8000 = 0.888000, Loss: 0.39233535528182983
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 42 	Loss: 0.113368, lr: 0.100000, Time: 6.28s
Clean ACC: 7048/8000 = 0.881000, Loss: 0.3807867169380188
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 43 	Loss: 0.219988, lr: 0.100000, Time: 6.43s
Clean ACC: 7145/8000 = 0.893125, Loss: 0.36676025390625
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 44 	Loss: 0.095625, lr: 0.100000, Time: 6.28s
Clean ACC: 6946/8000 = 0.868250, Loss: 0.468342125415802
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 45 	Loss: 0.143114, lr: 0.100000, Time: 6.23s
Clean ACC: 7150/8000 = 0.893750, Loss: 0.3724362850189209
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 46 	Loss: 0.209647, lr: 0.100000, Time: 6.75s
Clean ACC: 7002/8000 = 0.875250, Loss: 0.43474793434143066
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 47 	Loss: 0.205310, lr: 0.100000, Time: 6.76s
Clean ACC: 7149/8000 = 0.893625, Loss: 0.36575520038604736
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 48 	Loss: 0.077791, lr: 0.100000, Time: 6.63s
Clean ACC: 7158/8000 = 0.894750, Loss: 0.3524535596370697
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 49 	Loss: 0.124249, lr: 0.100000, Time: 6.69s
Clean ACC: 7172/8000 = 0.896500, Loss: 0.34667956829071045
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 50 	Loss: 0.080461, lr: 0.100000, Time: 6.75s
Clean ACC: 7105/8000 = 0.888125, Loss: 0.402789831161499
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 51 	Loss: 0.024147, lr: 0.010000, Time: 6.70s
Clean ACC: 7404/8000 = 0.925500, Loss: 0.25704312324523926
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 52 	Loss: 0.019002, lr: 0.010000, Time: 6.53s
Clean ACC: 7435/8000 = 0.929375, Loss: 0.2521461248397827
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 53 	Loss: 0.052487, lr: 0.010000, Time: 6.47s
Clean ACC: 7451/8000 = 0.931375, Loss: 0.2514006197452545
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 54 	Loss: 0.008366, lr: 0.010000, Time: 6.27s
Clean ACC: 7444/8000 = 0.930500, Loss: 0.25367456674575806
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 55 	Loss: 0.026450, lr: 0.010000, Time: 6.38s
Clean ACC: 7443/8000 = 0.930375, Loss: 0.25693953037261963
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 56 	Loss: 0.014396, lr: 0.010000, Time: 6.42s
Clean ACC: 7454/8000 = 0.931750, Loss: 0.25408029556274414
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 57 	Loss: 0.037504, lr: 0.010000, Time: 6.64s
Clean ACC: 7459/8000 = 0.932375, Loss: 0.2597956955432892
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 58 	Loss: 0.007876, lr: 0.010000, Time: 6.76s
Clean ACC: 7450/8000 = 0.931250, Loss: 0.26273730397224426
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 59 	Loss: 0.004622, lr: 0.010000, Time: 6.68s
Clean ACC: 7458/8000 = 0.932250, Loss: 0.2622215747833252
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 60 	Loss: 0.002307, lr: 0.010000, Time: 6.65s
Clean ACC: 7461/8000 = 0.932625, Loss: 0.26626914739608765
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 61 	Loss: 0.004558, lr: 0.010000, Time: 6.70s
Clean ACC: 7473/8000 = 0.934125, Loss: 0.26201364398002625
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 62 	Loss: 0.019297, lr: 0.010000, Time: 6.60s
Clean ACC: 7476/8000 = 0.934500, Loss: 0.2649954557418823
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 63 	Loss: 0.011467, lr: 0.010000, Time: 6.79s
Clean ACC: 7475/8000 = 0.934375, Loss: 0.26782137155532837
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 64 	Loss: 0.012218, lr: 0.010000, Time: 6.32s
Clean ACC: 7461/8000 = 0.932625, Loss: 0.2660025656223297
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 65 	Loss: 0.036019, lr: 0.010000, Time: 6.16s
Clean ACC: 7472/8000 = 0.934000, Loss: 0.269395112991333
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 66 	Loss: 0.003599, lr: 0.010000, Time: 6.38s
Clean ACC: 7469/8000 = 0.933625, Loss: 0.2703918516635895
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 67 	Loss: 0.005248, lr: 0.010000, Time: 6.39s
Clean ACC: 7476/8000 = 0.934500, Loss: 0.27159634232521057
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 68 	Loss: 0.001767, lr: 0.010000, Time: 6.48s
Clean ACC: 7482/8000 = 0.935250, Loss: 0.27183642983436584
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 69 	Loss: 0.000988, lr: 0.010000, Time: 6.67s
Clean ACC: 7470/8000 = 0.933750, Loss: 0.2778857350349426
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 70 	Loss: 0.007554, lr: 0.010000, Time: 6.75s
Clean ACC: 7470/8000 = 0.933750, Loss: 0.2760224938392639
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 71 	Loss: 0.004865, lr: 0.010000, Time: 6.74s
Clean ACC: 7484/8000 = 0.935500, Loss: 0.2777298092842102
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 72 	Loss: 0.002551, lr: 0.010000, Time: 6.71s
Clean ACC: 7478/8000 = 0.934750, Loss: 0.2764837145805359
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 73 	Loss: 0.001189, lr: 0.010000, Time: 6.69s
Clean ACC: 7476/8000 = 0.934500, Loss: 0.2776171863079071
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 74 	Loss: 0.004372, lr: 0.010000, Time: 6.66s
Clean ACC: 7480/8000 = 0.935000, Loss: 0.2778242528438568
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 75 	Loss: 0.007419, lr: 0.010000, Time: 6.48s
Clean ACC: 7492/8000 = 0.936500, Loss: 0.27810755372047424
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 76 	Loss: 0.059141, lr: 0.001000, Time: 6.16s
Clean ACC: 7483/8000 = 0.935375, Loss: 0.2754471004009247
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 77 	Loss: 0.004028, lr: 0.001000, Time: 6.44s
Clean ACC: 7488/8000 = 0.936000, Loss: 0.2762250602245331
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 78 	Loss: 0.004851, lr: 0.001000, Time: 6.33s
Clean ACC: 7486/8000 = 0.935750, Loss: 0.27526095509529114
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 79 	Loss: 0.002014, lr: 0.001000, Time: 6.32s
Clean ACC: 7480/8000 = 0.935000, Loss: 0.27689963579177856
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 80 	Loss: 0.002927, lr: 0.001000, Time: 6.65s
Clean ACC: 7485/8000 = 0.935625, Loss: 0.2748335599899292
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 81 	Loss: 0.003823, lr: 0.001000, Time: 6.65s
Clean ACC: 7484/8000 = 0.935500, Loss: 0.27538493275642395
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 82 	Loss: 0.001727, lr: 0.001000, Time: 6.70s
Clean ACC: 7488/8000 = 0.936000, Loss: 0.27511081099510193
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 83 	Loss: 0.001195, lr: 0.001000, Time: 6.82s
Clean ACC: 7484/8000 = 0.935500, Loss: 0.27577492594718933
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 84 	Loss: 0.003989, lr: 0.001000, Time: 6.69s
Clean ACC: 7487/8000 = 0.935875, Loss: 0.27539971470832825
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 85 	Loss: 0.008041, lr: 0.001000, Time: 6.78s
Clean ACC: 7479/8000 = 0.934875, Loss: 0.2766155004501343
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 86 	Loss: 0.001531, lr: 0.001000, Time: 6.47s
Clean ACC: 7486/8000 = 0.935750, Loss: 0.27634111046791077
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 87 	Loss: 0.007725, lr: 0.001000, Time: 6.35s
Clean ACC: 7490/8000 = 0.936250, Loss: 0.27563241124153137
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 88 	Loss: 0.002872, lr: 0.001000, Time: 6.39s
Clean ACC: 7489/8000 = 0.936125, Loss: 0.2760387361049652
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 89 	Loss: 0.014161, lr: 0.001000, Time: 6.39s
Clean ACC: 7488/8000 = 0.936000, Loss: 0.2757714092731476
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 90 	Loss: 0.000600, lr: 0.001000, Time: 6.32s
Clean ACC: 7489/8000 = 0.936125, Loss: 0.2766469419002533
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 91 	Loss: 0.007228, lr: 0.001000, Time: 6.82s
Clean ACC: 7490/8000 = 0.936250, Loss: 0.27421829104423523
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 92 	Loss: 0.000957, lr: 0.001000, Time: 6.70s
Clean ACC: 7483/8000 = 0.935375, Loss: 0.276980459690094
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 93 	Loss: 0.001782, lr: 0.001000, Time: 6.72s
Clean ACC: 7486/8000 = 0.935750, Loss: 0.2777101993560791
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 94 	Loss: 0.001799, lr: 0.001000, Time: 6.67s
Clean ACC: 7479/8000 = 0.934875, Loss: 0.27711957693099976
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 95 	Loss: 0.104835, lr: 0.001000, Time: 6.59s
Clean ACC: 7486/8000 = 0.935750, Loss: 0.2761029303073883
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 96 	Loss: 0.023995, lr: 0.001000, Time: 6.75s
Clean ACC: 7486/8000 = 0.935750, Loss: 0.2767130136489868
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 97 	Loss: 0.001183, lr: 0.001000, Time: 6.52s
Clean ACC: 7487/8000 = 0.935875, Loss: 0.2757565975189209
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 98 	Loss: 0.006672, lr: 0.001000, Time: 6.37s
Clean ACC: 7483/8000 = 0.935375, Loss: 0.2765342593193054
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 99 	Loss: 0.001051, lr: 0.001000, Time: 6.29s
Clean ACC: 7485/8000 = 0.935625, Loss: 0.2758936882019043
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 100 	Loss: 0.000753, lr: 0.001000, Time: 6.31s
Clean ACC: 7482/8000 = 0.935250, Loss: 0.27645519375801086
ASR: 7193/7193 = 1.000000


Testing the backdoor model...
Evaluating model 'poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 7482/8000 = 0.935250, Loss: 0.27645519375801086
ASR: 7193/7193 = 1.000000

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7482/8000 = 0.935250, Loss: 0.27645930647850037
ASR: 7193/7193 = 1.000000

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.451318, poison_dis: 8.469252
Silhouette Score: 0.45662692
Saved figure at assets/pca_cifar10_adaptive_patch_0.010_cover=0.000_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7482/8000 = 0.935250, Loss: 0.27645930647850037
ASR: 7193/7193 = 1.000000

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.451318, poison_dis: 8.469252
Silhouette Score: 0.45662692
Saved figure at assets/tsne_cifar10_adaptive_patch_0.010_cover=0.000_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7482/8000 = 0.935250, Loss: 0.27645930647850037
ASR: 7193/7193 = 1.000000

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.451318, poison_dis: 8.469252
Silhouette Score: 0.45662692
SVM Accuracy: 1.0
Saved figure at assets/oracle_cifar10_adaptive_patch_0.010_cover=0.000_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/none
No trigger mask found! By default masking all black pixels...
Evaluating model 'poisoned_train_set/cifar10/adaptive_patch_0.010_cover=0.000_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 93.5250015258789
asr: 100.0
target label: tensor([0], device='cuda:0')
start_index: 7
TPR: 100.00
FPR: 9.44
AUC: 0.9938
f1 score: 0.9549388242315726
Elapsed time: 34.51s
Experiment for cifar10 with adaptive_patch completed.
