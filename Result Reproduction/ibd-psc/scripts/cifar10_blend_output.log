Creating poisoned training set for blend on cifar10...
[target class : 0]
Files already downloaded and verified
Poisoned set directory 'poisoned_train_set/cifar10/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0' to be created is not empty! Exiting...
Training the model on the poisoned dataset...
dataset : poisoned_train_set/cifar10/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/imgs
Will save to 'poisoned_train_set/cifar10/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'.
Model 'poisoned_train_set/cifar10/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' already exists!
<Backdoor Training> Train Epoch: 1 	Loss: 1.556411, lr: 0.100000, Time: 7.73s
Clean ACC: 3458/8000 = 0.432250, Loss: 1.521122694015503
ASR: 466/7193 = 0.064785


<Backdoor Training> Train Epoch: 2 	Loss: 0.977199, lr: 0.100000, Time: 6.40s
Clean ACC: 4558/8000 = 0.569750, Loss: 1.2375491857528687
ASR: 1300/7193 = 0.180731


<Backdoor Training> Train Epoch: 3 	Loss: 0.955055, lr: 0.100000, Time: 6.32s
Clean ACC: 5073/8000 = 0.634125, Loss: 1.0391103029251099
ASR: 787/7193 = 0.109412


<Backdoor Training> Train Epoch: 4 	Loss: 0.781021, lr: 0.100000, Time: 6.34s
Clean ACC: 5669/8000 = 0.708625, Loss: 0.835563063621521
ASR: 5001/7193 = 0.695259


<Backdoor Training> Train Epoch: 5 	Loss: 0.765471, lr: 0.100000, Time: 6.33s
Clean ACC: 6144/8000 = 0.768000, Loss: 0.6695514917373657
ASR: 5924/7193 = 0.823578


<Backdoor Training> Train Epoch: 6 	Loss: 0.605038, lr: 0.100000, Time: 6.35s
Clean ACC: 6391/8000 = 0.798875, Loss: 0.5999608039855957
ASR: 5931/7193 = 0.824552


<Backdoor Training> Train Epoch: 7 	Loss: 0.367150, lr: 0.100000, Time: 6.58s
Clean ACC: 6341/8000 = 0.792625, Loss: 0.6246499419212341
ASR: 6757/7193 = 0.939386


<Backdoor Training> Train Epoch: 8 	Loss: 0.355362, lr: 0.100000, Time: 6.67s
Clean ACC: 6364/8000 = 0.795500, Loss: 0.6199938058853149
ASR: 6984/7193 = 0.970944


<Backdoor Training> Train Epoch: 9 	Loss: 0.515172, lr: 0.100000, Time: 6.70s
Clean ACC: 6600/8000 = 0.825000, Loss: 0.5087350010871887
ASR: 6826/7193 = 0.948978


<Backdoor Training> Train Epoch: 10 	Loss: 0.430803, lr: 0.100000, Time: 6.64s
Clean ACC: 6781/8000 = 0.847625, Loss: 0.4468482434749603
ASR: 6771/7193 = 0.941332


<Backdoor Training> Train Epoch: 11 	Loss: 0.313315, lr: 0.100000, Time: 6.59s
Clean ACC: 6442/8000 = 0.805250, Loss: 0.5834965109825134
ASR: 6267/7193 = 0.871264


<Backdoor Training> Train Epoch: 12 	Loss: 0.337841, lr: 0.100000, Time: 6.68s
Clean ACC: 6703/8000 = 0.837875, Loss: 0.4853888154029846
ASR: 7009/7193 = 0.974420


<Backdoor Training> Train Epoch: 13 	Loss: 0.201591, lr: 0.100000, Time: 6.76s
Clean ACC: 6779/8000 = 0.847375, Loss: 0.4637007415294647
ASR: 6939/7193 = 0.964688


<Backdoor Training> Train Epoch: 14 	Loss: 0.295053, lr: 0.100000, Time: 6.37s
Clean ACC: 6794/8000 = 0.849250, Loss: 0.45960304141044617
ASR: 6730/7193 = 0.935632


<Backdoor Training> Train Epoch: 15 	Loss: 0.255611, lr: 0.100000, Time: 6.42s
Clean ACC: 6781/8000 = 0.847625, Loss: 0.45710447430610657
ASR: 6979/7193 = 0.970249


<Backdoor Training> Train Epoch: 16 	Loss: 0.318399, lr: 0.100000, Time: 6.19s
Clean ACC: 6970/8000 = 0.871250, Loss: 0.3837684988975525
ASR: 6852/7193 = 0.952593


<Backdoor Training> Train Epoch: 17 	Loss: 0.299461, lr: 0.100000, Time: 6.34s
Clean ACC: 6996/8000 = 0.874500, Loss: 0.37410175800323486
ASR: 6666/7193 = 0.926734


<Backdoor Training> Train Epoch: 18 	Loss: 0.216091, lr: 0.100000, Time: 6.50s
Clean ACC: 7028/8000 = 0.878500, Loss: 0.3734467029571533
ASR: 6757/7193 = 0.939386


<Backdoor Training> Train Epoch: 19 	Loss: 0.284637, lr: 0.100000, Time: 6.74s
Clean ACC: 7038/8000 = 0.879750, Loss: 0.3579235374927521
ASR: 7033/7193 = 0.977756


<Backdoor Training> Train Epoch: 20 	Loss: 0.225630, lr: 0.100000, Time: 6.71s
Clean ACC: 6951/8000 = 0.868875, Loss: 0.4029524624347687
ASR: 6424/7193 = 0.893091


<Backdoor Training> Train Epoch: 21 	Loss: 0.109909, lr: 0.100000, Time: 6.58s
Clean ACC: 6886/8000 = 0.860750, Loss: 0.4493943750858307
ASR: 6606/7193 = 0.918393


<Backdoor Training> Train Epoch: 22 	Loss: 0.286552, lr: 0.100000, Time: 6.69s
Clean ACC: 7070/8000 = 0.883750, Loss: 0.3669736385345459
ASR: 6839/7193 = 0.950785


<Backdoor Training> Train Epoch: 23 	Loss: 0.114214, lr: 0.100000, Time: 6.63s
Clean ACC: 7072/8000 = 0.884000, Loss: 0.37316128611564636
ASR: 6762/7193 = 0.940081


<Backdoor Training> Train Epoch: 24 	Loss: 0.221832, lr: 0.100000, Time: 6.72s
Clean ACC: 6900/8000 = 0.862500, Loss: 0.46652546525001526
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 25 	Loss: 0.193126, lr: 0.100000, Time: 6.28s
Clean ACC: 7074/8000 = 0.884250, Loss: 0.37597018480300903
ASR: 7012/7193 = 0.974837


<Backdoor Training> Train Epoch: 26 	Loss: 0.090289, lr: 0.100000, Time: 6.20s
Clean ACC: 7134/8000 = 0.891750, Loss: 0.34542611241340637
ASR: 6994/7193 = 0.972334


<Backdoor Training> Train Epoch: 27 	Loss: 0.130152, lr: 0.100000, Time: 6.33s
Clean ACC: 7060/8000 = 0.882500, Loss: 0.38421761989593506
ASR: 6713/7193 = 0.933268


<Backdoor Training> Train Epoch: 28 	Loss: 0.100131, lr: 0.100000, Time: 6.34s
Clean ACC: 7035/8000 = 0.879375, Loss: 0.40609535574913025
ASR: 6370/7193 = 0.885583


<Backdoor Training> Train Epoch: 29 	Loss: 0.191155, lr: 0.100000, Time: 6.24s
Clean ACC: 7032/8000 = 0.879000, Loss: 0.4133467972278595
ASR: 7149/7193 = 0.993883


<Backdoor Training> Train Epoch: 30 	Loss: 0.132598, lr: 0.100000, Time: 6.80s
Clean ACC: 7128/8000 = 0.891000, Loss: 0.35210859775543213
ASR: 7096/7193 = 0.986515


<Backdoor Training> Train Epoch: 31 	Loss: 0.067639, lr: 0.100000, Time: 6.84s
Clean ACC: 7155/8000 = 0.894375, Loss: 0.3488704562187195
ASR: 7130/7193 = 0.991241


<Backdoor Training> Train Epoch: 32 	Loss: 0.068835, lr: 0.100000, Time: 6.65s
Clean ACC: 7238/8000 = 0.904750, Loss: 0.33551520109176636
ASR: 6975/7193 = 0.969693


<Backdoor Training> Train Epoch: 33 	Loss: 0.097760, lr: 0.100000, Time: 6.69s
Clean ACC: 7130/8000 = 0.891250, Loss: 0.36904120445251465
ASR: 6943/7193 = 0.965244


<Backdoor Training> Train Epoch: 34 	Loss: 0.088916, lr: 0.100000, Time: 6.68s
Clean ACC: 7154/8000 = 0.894250, Loss: 0.33143165707588196
ASR: 6952/7193 = 0.966495


<Backdoor Training> Train Epoch: 35 	Loss: 0.144460, lr: 0.100000, Time: 6.66s
Clean ACC: 7160/8000 = 0.895000, Loss: 0.34045785665512085
ASR: 6893/7193 = 0.958293


<Backdoor Training> Train Epoch: 36 	Loss: 0.197635, lr: 0.100000, Time: 6.53s
Clean ACC: 7144/8000 = 0.893000, Loss: 0.372927725315094
ASR: 7010/7193 = 0.974559


<Backdoor Training> Train Epoch: 37 	Loss: 0.138575, lr: 0.100000, Time: 6.37s
Clean ACC: 7139/8000 = 0.892375, Loss: 0.3682681620121002
ASR: 6559/7193 = 0.911859


<Backdoor Training> Train Epoch: 38 	Loss: 0.109953, lr: 0.100000, Time: 6.27s
Clean ACC: 7197/8000 = 0.899625, Loss: 0.3450584411621094
ASR: 6488/7193 = 0.901988


<Backdoor Training> Train Epoch: 39 	Loss: 0.132781, lr: 0.100000, Time: 6.33s
Clean ACC: 7208/8000 = 0.901000, Loss: 0.32740798592567444
ASR: 6957/7193 = 0.967190


<Backdoor Training> Train Epoch: 40 	Loss: 0.101374, lr: 0.100000, Time: 6.28s
Clean ACC: 7216/8000 = 0.902000, Loss: 0.33505237102508545
ASR: 7024/7193 = 0.976505


<Backdoor Training> Train Epoch: 41 	Loss: 0.113945, lr: 0.100000, Time: 6.68s
Clean ACC: 7136/8000 = 0.892000, Loss: 0.36901918053627014
ASR: 6778/7193 = 0.942305


<Backdoor Training> Train Epoch: 42 	Loss: 0.135802, lr: 0.100000, Time: 6.73s
Clean ACC: 7165/8000 = 0.895625, Loss: 0.34419262409210205
ASR: 7150/7193 = 0.994022


<Backdoor Training> Train Epoch: 43 	Loss: 0.129751, lr: 0.100000, Time: 6.65s
Clean ACC: 7091/8000 = 0.886375, Loss: 0.38984543085098267
ASR: 7051/7193 = 0.980259


<Backdoor Training> Train Epoch: 44 	Loss: 0.214037, lr: 0.100000, Time: 6.54s
Clean ACC: 7135/8000 = 0.891875, Loss: 0.37416377663612366
ASR: 7110/7193 = 0.988461


<Backdoor Training> Train Epoch: 45 	Loss: 0.204503, lr: 0.100000, Time: 6.83s
Clean ACC: 7143/8000 = 0.892875, Loss: 0.35950767993927
ASR: 6932/7193 = 0.963715


<Backdoor Training> Train Epoch: 46 	Loss: 0.147665, lr: 0.100000, Time: 6.81s
Clean ACC: 7132/8000 = 0.891500, Loss: 0.36881497502326965
ASR: 7101/7193 = 0.987210


<Backdoor Training> Train Epoch: 47 	Loss: 0.131082, lr: 0.100000, Time: 6.72s
Clean ACC: 7118/8000 = 0.889750, Loss: 0.37664705514907837
ASR: 6852/7193 = 0.952593


<Backdoor Training> Train Epoch: 48 	Loss: 0.152177, lr: 0.100000, Time: 6.35s
Clean ACC: 7263/8000 = 0.907875, Loss: 0.31562137603759766
ASR: 6983/7193 = 0.970805


<Backdoor Training> Train Epoch: 49 	Loss: 0.071299, lr: 0.100000, Time: 6.13s
Clean ACC: 7149/8000 = 0.893625, Loss: 0.3535767197608948
ASR: 6964/7193 = 0.968163


<Backdoor Training> Train Epoch: 50 	Loss: 0.157920, lr: 0.100000, Time: 6.43s
Clean ACC: 7030/8000 = 0.878750, Loss: 0.4385097622871399
ASR: 7007/7193 = 0.974142


<Backdoor Training> Train Epoch: 51 	Loss: 0.080980, lr: 0.010000, Time: 6.35s
Clean ACC: 7442/8000 = 0.930250, Loss: 0.23548737168312073
ASR: 7080/7193 = 0.984290


<Backdoor Training> Train Epoch: 52 	Loss: 0.015685, lr: 0.010000, Time: 6.47s
Clean ACC: 7461/8000 = 0.932625, Loss: 0.23597551882266998
ASR: 7103/7193 = 0.987488


<Backdoor Training> Train Epoch: 53 	Loss: 0.012795, lr: 0.010000, Time: 6.68s
Clean ACC: 7476/8000 = 0.934500, Loss: 0.23571710288524628
ASR: 7096/7193 = 0.986515


<Backdoor Training> Train Epoch: 54 	Loss: 0.014320, lr: 0.010000, Time: 6.71s
Clean ACC: 7473/8000 = 0.934125, Loss: 0.24078813195228577
ASR: 7093/7193 = 0.986098


<Backdoor Training> Train Epoch: 55 	Loss: 0.030436, lr: 0.010000, Time: 6.77s
Clean ACC: 7467/8000 = 0.933375, Loss: 0.2487127035856247
ASR: 7103/7193 = 0.987488


<Backdoor Training> Train Epoch: 56 	Loss: 0.006486, lr: 0.010000, Time: 6.90s
Clean ACC: 7467/8000 = 0.933375, Loss: 0.2527226507663727
ASR: 7110/7193 = 0.988461


<Backdoor Training> Train Epoch: 57 	Loss: 0.006300, lr: 0.010000, Time: 6.65s
Clean ACC: 7468/8000 = 0.933500, Loss: 0.25291645526885986
ASR: 7086/7193 = 0.985124


<Backdoor Training> Train Epoch: 58 	Loss: 0.007073, lr: 0.010000, Time: 6.76s
Clean ACC: 7473/8000 = 0.934125, Loss: 0.2559027373790741
ASR: 7101/7193 = 0.987210


<Backdoor Training> Train Epoch: 59 	Loss: 0.004858, lr: 0.010000, Time: 6.29s
Clean ACC: 7462/8000 = 0.932750, Loss: 0.2594028115272522
ASR: 7112/7193 = 0.988739


<Backdoor Training> Train Epoch: 60 	Loss: 0.001934, lr: 0.010000, Time: 6.21s
Clean ACC: 7470/8000 = 0.933750, Loss: 0.2586894631385803
ASR: 7123/7193 = 0.990268


<Backdoor Training> Train Epoch: 61 	Loss: 0.001607, lr: 0.010000, Time: 6.46s
Clean ACC: 7474/8000 = 0.934250, Loss: 0.26744845509529114
ASR: 7129/7193 = 0.991102


<Backdoor Training> Train Epoch: 62 	Loss: 0.006081, lr: 0.010000, Time: 6.39s
Clean ACC: 7481/8000 = 0.935125, Loss: 0.2628113627433777
ASR: 7114/7193 = 0.989017


<Backdoor Training> Train Epoch: 63 	Loss: 0.014231, lr: 0.010000, Time: 6.42s
Clean ACC: 7477/8000 = 0.934625, Loss: 0.2689715325832367
ASR: 7109/7193 = 0.988322


<Backdoor Training> Train Epoch: 64 	Loss: 0.000887, lr: 0.010000, Time: 6.83s
Clean ACC: 7488/8000 = 0.936000, Loss: 0.272813618183136
ASR: 7119/7193 = 0.989712


<Backdoor Training> Train Epoch: 65 	Loss: 0.002833, lr: 0.010000, Time: 6.78s
Clean ACC: 7489/8000 = 0.936125, Loss: 0.26666876673698425
ASR: 7099/7193 = 0.986932


<Backdoor Training> Train Epoch: 66 	Loss: 0.011763, lr: 0.010000, Time: 6.73s
Clean ACC: 7476/8000 = 0.934500, Loss: 0.2744241952896118
ASR: 7118/7193 = 0.989573


<Backdoor Training> Train Epoch: 67 	Loss: 0.037038, lr: 0.010000, Time: 6.61s
Clean ACC: 7472/8000 = 0.934000, Loss: 0.2742657959461212
ASR: 7111/7193 = 0.988600


<Backdoor Training> Train Epoch: 68 	Loss: 0.024278, lr: 0.010000, Time: 6.68s
Clean ACC: 7473/8000 = 0.934125, Loss: 0.2772972285747528
ASR: 7093/7193 = 0.986098


<Backdoor Training> Train Epoch: 69 	Loss: 0.000519, lr: 0.010000, Time: 6.66s
Clean ACC: 7482/8000 = 0.935250, Loss: 0.2710862159729004
ASR: 7102/7193 = 0.987349


<Backdoor Training> Train Epoch: 70 	Loss: 0.006683, lr: 0.010000, Time: 6.52s
Clean ACC: 7497/8000 = 0.937125, Loss: 0.2771192491054535
ASR: 7093/7193 = 0.986098


<Backdoor Training> Train Epoch: 71 	Loss: 0.009035, lr: 0.010000, Time: 6.38s
Clean ACC: 7488/8000 = 0.936000, Loss: 0.2762964069843292
ASR: 7097/7193 = 0.986654


<Backdoor Training> Train Epoch: 72 	Loss: 0.001953, lr: 0.010000, Time: 6.41s
Clean ACC: 7491/8000 = 0.936375, Loss: 0.27722033858299255
ASR: 7084/7193 = 0.984846


<Backdoor Training> Train Epoch: 73 	Loss: 0.001498, lr: 0.010000, Time: 6.16s
Clean ACC: 7495/8000 = 0.936875, Loss: 0.27395740151405334
ASR: 7127/7193 = 0.990824


<Backdoor Training> Train Epoch: 74 	Loss: 0.029623, lr: 0.010000, Time: 6.32s
Clean ACC: 7481/8000 = 0.935125, Loss: 0.2733789384365082
ASR: 7122/7193 = 0.990129


<Backdoor Training> Train Epoch: 75 	Loss: 0.001725, lr: 0.010000, Time: 6.71s
Clean ACC: 7491/8000 = 0.936375, Loss: 0.27764660120010376
ASR: 7092/7193 = 0.985959


<Backdoor Training> Train Epoch: 76 	Loss: 0.001525, lr: 0.001000, Time: 6.76s
Clean ACC: 7496/8000 = 0.937000, Loss: 0.2764749228954315
ASR: 7095/7193 = 0.986376


<Backdoor Training> Train Epoch: 77 	Loss: 0.002999, lr: 0.001000, Time: 6.87s
Clean ACC: 7490/8000 = 0.936250, Loss: 0.2770818769931793
ASR: 7094/7193 = 0.986237


<Backdoor Training> Train Epoch: 78 	Loss: 0.001181, lr: 0.001000, Time: 6.65s
Clean ACC: 7492/8000 = 0.936500, Loss: 0.27673739194869995
ASR: 7097/7193 = 0.986654


<Backdoor Training> Train Epoch: 79 	Loss: 0.002068, lr: 0.001000, Time: 6.58s
Clean ACC: 7500/8000 = 0.937500, Loss: 0.27440935373306274
ASR: 7110/7193 = 0.988461


<Backdoor Training> Train Epoch: 80 	Loss: 0.004273, lr: 0.001000, Time: 6.63s
Clean ACC: 7488/8000 = 0.936000, Loss: 0.27748361229896545
ASR: 7085/7193 = 0.984985


<Backdoor Training> Train Epoch: 81 	Loss: 0.022415, lr: 0.001000, Time: 6.78s
Clean ACC: 7492/8000 = 0.936500, Loss: 0.2759852111339569
ASR: 7109/7193 = 0.988322


<Backdoor Training> Train Epoch: 82 	Loss: 0.001751, lr: 0.001000, Time: 6.34s
Clean ACC: 7492/8000 = 0.936500, Loss: 0.274623841047287
ASR: 7090/7193 = 0.985681


<Backdoor Training> Train Epoch: 83 	Loss: 0.019773, lr: 0.001000, Time: 6.41s
Clean ACC: 7498/8000 = 0.937250, Loss: 0.27561143040657043
ASR: 7107/7193 = 0.988044


<Backdoor Training> Train Epoch: 84 	Loss: 0.003301, lr: 0.001000, Time: 6.32s
Clean ACC: 7500/8000 = 0.937500, Loss: 0.27281415462493896
ASR: 7110/7193 = 0.988461


<Backdoor Training> Train Epoch: 85 	Loss: 0.001047, lr: 0.001000, Time: 6.39s
Clean ACC: 7498/8000 = 0.937250, Loss: 0.2744632661342621
ASR: 7112/7193 = 0.988739


<Backdoor Training> Train Epoch: 86 	Loss: 0.001642, lr: 0.001000, Time: 6.49s
Clean ACC: 7491/8000 = 0.936375, Loss: 0.27314233779907227
ASR: 7097/7193 = 0.986654


<Backdoor Training> Train Epoch: 87 	Loss: 0.000770, lr: 0.001000, Time: 6.70s
Clean ACC: 7495/8000 = 0.936875, Loss: 0.2742997407913208
ASR: 7097/7193 = 0.986654


<Backdoor Training> Train Epoch: 88 	Loss: 0.001786, lr: 0.001000, Time: 6.79s
Clean ACC: 7495/8000 = 0.936875, Loss: 0.2750222086906433
ASR: 7108/7193 = 0.988183


<Backdoor Training> Train Epoch: 89 	Loss: 0.001622, lr: 0.001000, Time: 6.64s
Clean ACC: 7493/8000 = 0.936625, Loss: 0.2735428214073181
ASR: 7092/7193 = 0.985959


<Backdoor Training> Train Epoch: 90 	Loss: 0.002103, lr: 0.001000, Time: 6.69s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.2739338278770447
ASR: 7097/7193 = 0.986654


<Backdoor Training> Train Epoch: 91 	Loss: 0.000708, lr: 0.001000, Time: 6.57s
Clean ACC: 7502/8000 = 0.937750, Loss: 0.2750530242919922
ASR: 7113/7193 = 0.988878


<Backdoor Training> Train Epoch: 92 	Loss: 0.002359, lr: 0.001000, Time: 6.73s
Clean ACC: 7491/8000 = 0.936375, Loss: 0.27520594000816345
ASR: 7116/7193 = 0.989295


<Backdoor Training> Train Epoch: 93 	Loss: 0.035497, lr: 0.001000, Time: 6.38s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.2733008563518524
ASR: 7102/7193 = 0.987349


<Backdoor Training> Train Epoch: 94 	Loss: 0.000363, lr: 0.001000, Time: 6.32s
Clean ACC: 7500/8000 = 0.937500, Loss: 0.2741735875606537
ASR: 7106/7193 = 0.987905


<Backdoor Training> Train Epoch: 95 	Loss: 0.003630, lr: 0.001000, Time: 6.38s
Clean ACC: 7498/8000 = 0.937250, Loss: 0.2756347358226776
ASR: 7107/7193 = 0.988044


<Backdoor Training> Train Epoch: 96 	Loss: 0.017577, lr: 0.001000, Time: 6.31s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.276117205619812
ASR: 7114/7193 = 0.989017


<Backdoor Training> Train Epoch: 97 	Loss: 0.000319, lr: 0.001000, Time: 6.24s
Clean ACC: 7495/8000 = 0.936875, Loss: 0.2738146483898163
ASR: 7093/7193 = 0.986098


<Backdoor Training> Train Epoch: 98 	Loss: 0.003936, lr: 0.001000, Time: 6.75s
Clean ACC: 7497/8000 = 0.937125, Loss: 0.27441197633743286
ASR: 7110/7193 = 0.988461


<Backdoor Training> Train Epoch: 99 	Loss: 0.003773, lr: 0.001000, Time: 6.56s
Clean ACC: 7497/8000 = 0.937125, Loss: 0.27547499537467957
ASR: 7111/7193 = 0.988600


<Backdoor Training> Train Epoch: 100 	Loss: 0.000381, lr: 0.001000, Time: 6.77s
Clean ACC: 7502/8000 = 0.937750, Loss: 0.27440354228019714
ASR: 7112/7193 = 0.988739


Testing the backdoor model...
Evaluating model 'poisoned_train_set/cifar10/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 7502/8000 = 0.937750, Loss: 0.27440354228019714
ASR: 7112/7193 = 0.988739

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/cifar10/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7502/8000 = 0.937750, Loss: 0.2744109630584717
ASR: 7113/7193 = 0.988878

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.087006, poison_dis: 7.105009
Silhouette Score: 0.45007014
Saved figure at assets/pca_cifar10_blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7502/8000 = 0.937750, Loss: 0.2744109630584717
ASR: 7113/7193 = 0.988878

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.087006, poison_dis: 7.105009
Silhouette Score: 0.45007014
Saved figure at assets/tsne_cifar10_blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7502/8000 = 0.937750, Loss: 0.2744109630584717
ASR: 7113/7193 = 0.988878

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.087006, poison_dis: 7.105009
Silhouette Score: 0.45007014
SVM Accuracy: 1.0
Saved figure at assets/oracle_cifar10_blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/hellokitty_32.png
trigger_mask_path: ./triggers/mask_hellokitty_32.png
Evaluating model 'poisoned_train_set/cifar10/blend_0.010_alpha=0.200_trigger=hellokitty_32.png_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 93.7750015258789
asr: 98.8739013671875
target label: tensor([0], device='cuda:0')
start_index: 12
TPR: 97.79
FPR: 9.28
AUC: 0.9703
f1 score: 0.9445215816480531
Elapsed time: 20.79s
Experiment for cifar10 with blend completed.
