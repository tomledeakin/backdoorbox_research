Creating poisoned training set for trojan on cifar10...
[target class : 0]
Files already downloaded and verified
trigger: ./triggers/trojan_square_32.png
Poison indices: [6, 116, 244, 495, 639, 643, 777, 919, 1478, 1528, 1537, 1641, 1687, 1730, 1854, 1878, 1881, 2370, 2516, 2530, 2978, 3035, 3102, 3616, 4017, 4384, 4537, 4771, 4827, 4949, 5109, 5160, 5380, 5389, 5420, 5616, 5930, 6002, 6043, 6128, 6328, 6335, 6432, 6463, 6690, 6743, 6783, 7018, 7098, 7267, 7393, 7421, 7462, 7492, 7502, 7580, 7684, 7775, 8038, 8088, 8101, 8152, 8170, 8254, 8312, 8396, 8420, 8510, 8606, 8625, 8988, 9026, 9096, 9322, 9345, 9362, 9408, 9412, 9434, 9840, 9863, 9895, 10010, 10011, 10022, 10032, 10147, 10154, 10310, 10371, 10417, 10595, 10720, 10733, 10754, 11146, 11253, 11263, 11294, 11296, 11350, 11420, 11424, 11655, 11831, 11895, 11958, 11973, 11995, 12173, 12229, 12523, 12561, 12645, 12691, 12730, 12804, 12931, 12948, 13132, 13315, 13448, 13480, 13640, 13699, 13704, 13811, 13877, 14005, 14018, 14053, 14123, 14231, 14404, 14493, 14549, 14650, 14776, 14833, 14950, 15039, 15195, 15321, 15326, 15330, 15876, 15886, 15920, 16017, 16020, 16087, 16116, 16268, 16270, 16280, 16385, 16520, 16585, 16643, 16853, 16893, 17205, 17248, 17348, 17503, 17532, 17766, 17824, 18065, 18132, 18493, 18591, 18701, 18703, 18795, 18843, 18910, 18937, 19018, 19109, 19186, 19202, 19450, 19453, 19456, 19503, 19823, 19881, 19887, 19970, 20073, 20135, 20232, 20388, 20465, 20600, 20980, 20997, 21377, 21440, 21555, 21816, 21834, 21849, 22016, 22018, 22019, 22045, 22238, 22248, 22304, 22336, 22360, 22392, 22785, 22935, 22996, 23231, 23247, 23253, 23290, 23396, 23523, 23574, 23662, 23860, 23903, 23994, 24111, 24147, 24299, 24342, 24442, 24570, 24801, 24917, 24961, 25035, 25085, 25183, 25279, 25300, 25304, 25435, 25520, 25554, 25815, 25957, 26207, 26237, 26301, 26360, 26390, 26464, 26605, 26668, 26773, 26930, 26996, 27651, 27688, 27696, 27710, 27902, 28123, 28159, 28283, 28338, 28346, 28382, 28384, 28412, 28470, 28612, 28649, 28734, 28785, 28821, 28872, 29210, 29235, 29463, 29626, 29693, 29899, 29996, 30051, 30089, 30167, 30479, 30491, 30544, 30559, 30586, 30587, 30628, 30770, 30851, 30878, 30931, 31004, 31035, 31041, 31075, 31268, 31277, 31357, 31570, 31572, 31610, 31815, 32207, 32324, 32352, 32388, 32493, 32572, 32584, 32972, 33115, 33243, 33393, 33405, 33411, 33424, 33522, 33664, 33680, 33727, 33734, 33788, 33806, 33879, 33938, 34210, 34286, 34290, 34305, 34307, 34380, 34392, 34660, 34665, 34683, 35026, 35087, 35143, 35167, 35217, 35241, 35319, 35399, 35410, 35609, 35625, 35689, 35756, 36055, 36098, 36273, 36298, 36382, 36465, 36481, 36509, 36585, 36677, 36824, 36832, 37105, 37127, 37144, 37177, 37179, 37544, 37576, 37771, 37822, 38051, 38095, 38108, 38130, 38144, 38394, 38450, 38521, 38641, 38756, 38806, 38983, 39126, 39168, 39185, 39244, 39281, 39289, 39416, 39440, 39557, 39577, 39584, 39663, 39675, 39800, 39916, 39991, 40241, 40309, 40407, 40598, 40600, 40616, 40646, 40748, 40795, 40890, 40974, 40975, 41036, 41071, 41236, 41321, 41458, 41708, 41805, 41921, 42009, 42071, 42176, 42282, 42355, 42359, 42404, 42812, 43356, 43378, 43496, 43525, 43540, 43592, 43612, 44561, 44571, 44594, 44682, 44716, 44768, 44850, 44895, 44993, 45015, 45036, 45049, 45254, 45274, 45282, 45524, 45534, 45578, 45821, 45924, 46062, 46374, 46598, 46602, 46721, 46865, 47034, 47061, 47068, 47122, 47139, 47245, 47268, 47428, 47813, 47904, 47981, 47996, 48071, 48072, 48167, 48178, 48271, 48314, 48356, 48412, 48416, 48570, 48757, 48900, 49116, 49146, 49208, 49444, 49525, 49592, 49703, 49770, 49882]
[Generate Poisoned Set] Save 50000 Images
[Generate Poisoned Set] Save poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/imgs
[Generate Poisoned Set] Save poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/labels
[Generate Poisoned Set] Save poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/poison_indices
Training the model on the poisoned dataset...
dataset : poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/imgs
Will save to 'poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt'.
<Backdoor Training> Train Epoch: 1 	Loss: 1.656863, lr: 0.100000, Time: 10.40s
Clean ACC: 3031/8000 = 0.378875, Loss: 1.6817959547042847
ASR: 235/7193 = 0.032671


<Backdoor Training> Train Epoch: 2 	Loss: 1.256928, lr: 0.100000, Time: 6.21s
Clean ACC: 3851/8000 = 0.481375, Loss: 1.4108552932739258
ASR: 258/7193 = 0.035868


<Backdoor Training> Train Epoch: 3 	Loss: 1.455023, lr: 0.100000, Time: 6.13s
Clean ACC: 4457/8000 = 0.557125, Loss: 1.2632601261138916
ASR: 1244/7193 = 0.172946


<Backdoor Training> Train Epoch: 4 	Loss: 0.944736, lr: 0.100000, Time: 6.28s
Clean ACC: 5153/8000 = 0.644125, Loss: 1.0032269954681396
ASR: 5364/7193 = 0.745725


<Backdoor Training> Train Epoch: 5 	Loss: 0.984725, lr: 0.100000, Time: 6.22s
Clean ACC: 5512/8000 = 0.689000, Loss: 0.905321478843689
ASR: 5593/7193 = 0.777562


<Backdoor Training> Train Epoch: 6 	Loss: 0.854667, lr: 0.100000, Time: 6.12s
Clean ACC: 5716/8000 = 0.714500, Loss: 0.8128473162651062
ASR: 7026/7193 = 0.976783


<Backdoor Training> Train Epoch: 7 	Loss: 0.584321, lr: 0.100000, Time: 6.77s
Clean ACC: 5969/8000 = 0.746125, Loss: 0.733434796333313
ASR: 6961/7193 = 0.967746


<Backdoor Training> Train Epoch: 8 	Loss: 0.469985, lr: 0.100000, Time: 6.81s
Clean ACC: 6105/8000 = 0.763125, Loss: 0.7011231184005737
ASR: 7026/7193 = 0.976783


<Backdoor Training> Train Epoch: 9 	Loss: 0.420905, lr: 0.100000, Time: 6.85s
Clean ACC: 6366/8000 = 0.795750, Loss: 0.5954943895339966
ASR: 7080/7193 = 0.984290


<Backdoor Training> Train Epoch: 10 	Loss: 0.595896, lr: 0.100000, Time: 6.83s
Clean ACC: 6433/8000 = 0.804125, Loss: 0.5890264511108398
ASR: 5245/7193 = 0.729181


<Backdoor Training> Train Epoch: 11 	Loss: 0.388204, lr: 0.100000, Time: 6.73s
Clean ACC: 6329/8000 = 0.791125, Loss: 0.6138978004455566
ASR: 7121/7193 = 0.989990


<Backdoor Training> Train Epoch: 12 	Loss: 0.519306, lr: 0.100000, Time: 6.21s
Clean ACC: 6722/8000 = 0.840250, Loss: 0.4872063994407654
ASR: 7191/7193 = 0.999722


<Backdoor Training> Train Epoch: 13 	Loss: 0.417497, lr: 0.100000, Time: 6.29s
Clean ACC: 6769/8000 = 0.846125, Loss: 0.4486611783504486
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 14 	Loss: 0.314003, lr: 0.100000, Time: 6.30s
Clean ACC: 6785/8000 = 0.848125, Loss: 0.46025750041007996
ASR: 7155/7193 = 0.994717


<Backdoor Training> Train Epoch: 15 	Loss: 0.331076, lr: 0.100000, Time: 6.30s
Clean ACC: 6717/8000 = 0.839625, Loss: 0.47150367498397827
ASR: 7162/7193 = 0.995690


<Backdoor Training> Train Epoch: 16 	Loss: 0.432387, lr: 0.100000, Time: 6.32s
Clean ACC: 6781/8000 = 0.847625, Loss: 0.4641123414039612
ASR: 7151/7193 = 0.994161


<Backdoor Training> Train Epoch: 17 	Loss: 0.190125, lr: 0.100000, Time: 6.25s
Clean ACC: 6892/8000 = 0.861500, Loss: 0.41774752736091614
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 18 	Loss: 0.305581, lr: 0.100000, Time: 6.27s
Clean ACC: 6783/8000 = 0.847875, Loss: 0.4570503830909729
ASR: 7159/7193 = 0.995273


<Backdoor Training> Train Epoch: 19 	Loss: 0.287193, lr: 0.100000, Time: 6.89s
Clean ACC: 6946/8000 = 0.868250, Loss: 0.399235337972641
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 20 	Loss: 0.255071, lr: 0.100000, Time: 6.88s
Clean ACC: 6917/8000 = 0.864625, Loss: 0.4121560752391815
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 21 	Loss: 0.170871, lr: 0.100000, Time: 6.81s
Clean ACC: 7001/8000 = 0.875125, Loss: 0.38377875089645386
ASR: 7100/7193 = 0.987071


<Backdoor Training> Train Epoch: 22 	Loss: 0.197901, lr: 0.100000, Time: 6.68s
Clean ACC: 6975/8000 = 0.871875, Loss: 0.3918404281139374
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 23 	Loss: 0.156296, lr: 0.100000, Time: 6.66s
Clean ACC: 7066/8000 = 0.883250, Loss: 0.3742857575416565
ASR: 7173/7193 = 0.997220


<Backdoor Training> Train Epoch: 24 	Loss: 0.219838, lr: 0.100000, Time: 6.22s
Clean ACC: 7004/8000 = 0.875500, Loss: 0.39219123125076294
ASR: 7176/7193 = 0.997637


<Backdoor Training> Train Epoch: 25 	Loss: 0.422355, lr: 0.100000, Time: 6.22s
Clean ACC: 7058/8000 = 0.882250, Loss: 0.36902275681495667
ASR: 7125/7193 = 0.990546


<Backdoor Training> Train Epoch: 26 	Loss: 0.237426, lr: 0.100000, Time: 6.22s
Clean ACC: 6948/8000 = 0.868500, Loss: 0.42099133133888245
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 27 	Loss: 0.225861, lr: 0.100000, Time: 6.23s
Clean ACC: 7028/8000 = 0.878500, Loss: 0.3840411603450775
ASR: 7181/7193 = 0.998332


<Backdoor Training> Train Epoch: 28 	Loss: 0.185874, lr: 0.100000, Time: 6.21s
Clean ACC: 7043/8000 = 0.880375, Loss: 0.3747691810131073
ASR: 7167/7193 = 0.996385


<Backdoor Training> Train Epoch: 29 	Loss: 0.098064, lr: 0.100000, Time: 6.16s
Clean ACC: 7080/8000 = 0.885000, Loss: 0.3832050561904907
ASR: 7083/7193 = 0.984707


<Backdoor Training> Train Epoch: 30 	Loss: 0.214114, lr: 0.100000, Time: 6.24s
Clean ACC: 7029/8000 = 0.878625, Loss: 0.40053051710128784
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 31 	Loss: 0.217859, lr: 0.100000, Time: 6.78s
Clean ACC: 6886/8000 = 0.860750, Loss: 0.47539272904396057
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 32 	Loss: 0.236665, lr: 0.100000, Time: 6.78s
Clean ACC: 7057/8000 = 0.882125, Loss: 0.3779255747795105
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 33 	Loss: 0.182951, lr: 0.100000, Time: 6.89s
Clean ACC: 7085/8000 = 0.885625, Loss: 0.3724895417690277
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 34 	Loss: 0.108245, lr: 0.100000, Time: 6.87s
Clean ACC: 7072/8000 = 0.884000, Loss: 0.4042229950428009
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 35 	Loss: 0.184386, lr: 0.100000, Time: 6.76s
Clean ACC: 7020/8000 = 0.877500, Loss: 0.4241499900817871
ASR: 7148/7193 = 0.993744


<Backdoor Training> Train Epoch: 36 	Loss: 0.231702, lr: 0.100000, Time: 6.07s
Clean ACC: 7138/8000 = 0.892250, Loss: 0.3406876027584076
ASR: 7180/7193 = 0.998193


<Backdoor Training> Train Epoch: 37 	Loss: 0.141277, lr: 0.100000, Time: 6.20s
Clean ACC: 7043/8000 = 0.880375, Loss: 0.4101499617099762
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 38 	Loss: 0.149771, lr: 0.100000, Time: 6.22s
Clean ACC: 7189/8000 = 0.898625, Loss: 0.34626275300979614
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 39 	Loss: 0.177470, lr: 0.100000, Time: 6.23s
Clean ACC: 7131/8000 = 0.891375, Loss: 0.3584998846054077
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 40 	Loss: 0.225879, lr: 0.100000, Time: 6.23s
Clean ACC: 7039/8000 = 0.879875, Loss: 0.4066297113895416
ASR: 7170/7193 = 0.996802


<Backdoor Training> Train Epoch: 41 	Loss: 0.140141, lr: 0.100000, Time: 6.38s
Clean ACC: 6966/8000 = 0.870750, Loss: 0.44566333293914795
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 42 	Loss: 0.228765, lr: 0.100000, Time: 6.26s
Clean ACC: 7179/8000 = 0.897375, Loss: 0.3437724709510803
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 43 	Loss: 0.111579, lr: 0.100000, Time: 6.78s
Clean ACC: 7114/8000 = 0.889250, Loss: 0.36547720432281494
ASR: 7125/7193 = 0.990546


<Backdoor Training> Train Epoch: 44 	Loss: 0.115869, lr: 0.100000, Time: 6.79s
Clean ACC: 7130/8000 = 0.891250, Loss: 0.38387781381607056
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 45 	Loss: 0.210236, lr: 0.100000, Time: 6.87s
Clean ACC: 7122/8000 = 0.890250, Loss: 0.388184517621994
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 46 	Loss: 0.244633, lr: 0.100000, Time: 6.81s
Clean ACC: 7120/8000 = 0.890000, Loss: 0.3757539987564087
ASR: 7191/7193 = 0.999722


<Backdoor Training> Train Epoch: 47 	Loss: 0.210817, lr: 0.100000, Time: 6.90s
Clean ACC: 7128/8000 = 0.891000, Loss: 0.3767145872116089
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 48 	Loss: 0.222842, lr: 0.100000, Time: 6.38s
Clean ACC: 7037/8000 = 0.879625, Loss: 0.436663419008255
ASR: 7182/7193 = 0.998471


<Backdoor Training> Train Epoch: 49 	Loss: 0.120015, lr: 0.100000, Time: 6.13s
Clean ACC: 7078/8000 = 0.884750, Loss: 0.39643850922584534
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 50 	Loss: 0.131894, lr: 0.100000, Time: 6.17s
Clean ACC: 7116/8000 = 0.889500, Loss: 0.4084671139717102
ASR: 7145/7193 = 0.993327


<Backdoor Training> Train Epoch: 51 	Loss: 0.037591, lr: 0.010000, Time: 6.23s
Clean ACC: 7445/8000 = 0.930625, Loss: 0.2369489073753357
ASR: 7189/7193 = 0.999444


<Backdoor Training> Train Epoch: 52 	Loss: 0.020240, lr: 0.010000, Time: 6.26s
Clean ACC: 7450/8000 = 0.931250, Loss: 0.23808465898036957
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 53 	Loss: 0.014229, lr: 0.010000, Time: 6.25s
Clean ACC: 7488/8000 = 0.936000, Loss: 0.23551616072654724
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 54 	Loss: 0.010219, lr: 0.010000, Time: 6.21s
Clean ACC: 7475/8000 = 0.934375, Loss: 0.24087874591350555
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 55 	Loss: 0.003190, lr: 0.010000, Time: 6.78s
Clean ACC: 7494/8000 = 0.936750, Loss: 0.24181094765663147
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 56 	Loss: 0.020376, lr: 0.010000, Time: 6.76s
Clean ACC: 7485/8000 = 0.935625, Loss: 0.24542316794395447
ASR: 7182/7193 = 0.998471


<Backdoor Training> Train Epoch: 57 	Loss: 0.002103, lr: 0.010000, Time: 6.80s
Clean ACC: 7492/8000 = 0.936500, Loss: 0.24780794978141785
ASR: 7183/7193 = 0.998610


<Backdoor Training> Train Epoch: 58 	Loss: 0.010349, lr: 0.010000, Time: 6.91s
Clean ACC: 7504/8000 = 0.938000, Loss: 0.25028350949287415
ASR: 7188/7193 = 0.999305


<Backdoor Training> Train Epoch: 59 	Loss: 0.010046, lr: 0.010000, Time: 6.89s
Clean ACC: 7494/8000 = 0.936750, Loss: 0.24926850199699402
ASR: 7184/7193 = 0.998749


<Backdoor Training> Train Epoch: 60 	Loss: 0.010292, lr: 0.010000, Time: 6.27s
Clean ACC: 7497/8000 = 0.937125, Loss: 0.2560393810272217
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 61 	Loss: 0.009795, lr: 0.010000, Time: 6.17s
Clean ACC: 7494/8000 = 0.936750, Loss: 0.2587278485298157
ASR: 7185/7193 = 0.998888


<Backdoor Training> Train Epoch: 62 	Loss: 0.017943, lr: 0.010000, Time: 6.23s
Clean ACC: 7494/8000 = 0.936750, Loss: 0.25976037979125977
ASR: 7182/7193 = 0.998471


<Backdoor Training> Train Epoch: 63 	Loss: 0.003670, lr: 0.010000, Time: 6.19s
Clean ACC: 7491/8000 = 0.936375, Loss: 0.26981276273727417
ASR: 7191/7193 = 0.999722


<Backdoor Training> Train Epoch: 64 	Loss: 0.007528, lr: 0.010000, Time: 6.19s
Clean ACC: 7478/8000 = 0.934750, Loss: 0.2666475176811218
ASR: 7185/7193 = 0.998888


<Backdoor Training> Train Epoch: 65 	Loss: 0.004697, lr: 0.010000, Time: 6.25s
Clean ACC: 7476/8000 = 0.934500, Loss: 0.2681521773338318
ASR: 7191/7193 = 0.999722


<Backdoor Training> Train Epoch: 66 	Loss: 0.015172, lr: 0.010000, Time: 6.35s
Clean ACC: 7496/8000 = 0.937000, Loss: 0.26698973774909973
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 67 	Loss: 0.002376, lr: 0.010000, Time: 6.89s
Clean ACC: 7503/8000 = 0.937875, Loss: 0.26832884550094604
ASR: 7186/7193 = 0.999027


<Backdoor Training> Train Epoch: 68 	Loss: 0.016825, lr: 0.010000, Time: 6.98s
Clean ACC: 7506/8000 = 0.938250, Loss: 0.2697668969631195
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 69 	Loss: 0.012848, lr: 0.010000, Time: 6.83s
Clean ACC: 7503/8000 = 0.937875, Loss: 0.26884183287620544
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 70 	Loss: 0.002518, lr: 0.010000, Time: 6.82s
Clean ACC: 7499/8000 = 0.937375, Loss: 0.2718304395675659
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 71 	Loss: 0.003388, lr: 0.010000, Time: 6.75s
Clean ACC: 7494/8000 = 0.936750, Loss: 0.271000474691391
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 72 	Loss: 0.008882, lr: 0.010000, Time: 6.40s
Clean ACC: 7503/8000 = 0.937875, Loss: 0.26843568682670593
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 73 	Loss: 0.002681, lr: 0.010000, Time: 6.20s
Clean ACC: 7505/8000 = 0.938125, Loss: 0.2711021304130554
ASR: 7193/7193 = 1.000000


<Backdoor Training> Train Epoch: 74 	Loss: 0.004089, lr: 0.010000, Time: 6.05s
Clean ACC: 7507/8000 = 0.938375, Loss: 0.2740013301372528
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 75 	Loss: 0.002004, lr: 0.010000, Time: 6.17s
Clean ACC: 7506/8000 = 0.938250, Loss: 0.27438291907310486
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 76 	Loss: 0.001742, lr: 0.001000, Time: 6.30s
Clean ACC: 7509/8000 = 0.938625, Loss: 0.2766415774822235
ASR: 7190/7193 = 0.999583


<Backdoor Training> Train Epoch: 77 	Loss: 0.002842, lr: 0.001000, Time: 6.26s
Clean ACC: 7512/8000 = 0.939000, Loss: 0.2733989655971527
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 78 	Loss: 0.002347, lr: 0.001000, Time: 6.38s
Clean ACC: 7511/8000 = 0.938875, Loss: 0.27330291271209717
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 79 	Loss: 0.014267, lr: 0.001000, Time: 6.76s
Clean ACC: 7510/8000 = 0.938750, Loss: 0.2722216546535492
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 80 	Loss: 0.002188, lr: 0.001000, Time: 6.70s
Clean ACC: 7517/8000 = 0.939625, Loss: 0.27097514271736145
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 81 	Loss: 0.007001, lr: 0.001000, Time: 6.82s
Clean ACC: 7517/8000 = 0.939625, Loss: 0.2721053957939148
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 82 	Loss: 0.003878, lr: 0.001000, Time: 6.90s
Clean ACC: 7513/8000 = 0.939125, Loss: 0.27171793580055237
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 83 	Loss: 0.000635, lr: 0.001000, Time: 6.90s
Clean ACC: 7515/8000 = 0.939375, Loss: 0.2723884582519531
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 84 	Loss: 0.003090, lr: 0.001000, Time: 6.33s
Clean ACC: 7509/8000 = 0.938625, Loss: 0.2733084559440613
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 85 	Loss: 0.000796, lr: 0.001000, Time: 6.12s
Clean ACC: 7515/8000 = 0.939375, Loss: 0.2740463316440582
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 86 	Loss: 0.003274, lr: 0.001000, Time: 6.32s
Clean ACC: 7518/8000 = 0.939750, Loss: 0.27217593789100647
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 87 	Loss: 0.015531, lr: 0.001000, Time: 6.15s
Clean ACC: 7506/8000 = 0.938250, Loss: 0.27300646901130676
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 88 	Loss: 0.002052, lr: 0.001000, Time: 6.26s
Clean ACC: 7513/8000 = 0.939125, Loss: 0.2718234360218048
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 89 	Loss: 0.000589, lr: 0.001000, Time: 6.16s
Clean ACC: 7512/8000 = 0.939000, Loss: 0.27306365966796875
ASR: 7191/7193 = 0.999722


<Backdoor Training> Train Epoch: 90 	Loss: 0.005626, lr: 0.001000, Time: 6.18s
Clean ACC: 7519/8000 = 0.939875, Loss: 0.27163946628570557
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 91 	Loss: 0.000918, lr: 0.001000, Time: 6.80s
Clean ACC: 7511/8000 = 0.938875, Loss: 0.27297112345695496
ASR: 7191/7193 = 0.999722


<Backdoor Training> Train Epoch: 92 	Loss: 0.002208, lr: 0.001000, Time: 6.79s
Clean ACC: 7511/8000 = 0.938875, Loss: 0.27154338359832764
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 93 	Loss: 0.002644, lr: 0.001000, Time: 6.89s
Clean ACC: 7518/8000 = 0.939750, Loss: 0.27243757247924805
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 94 	Loss: 0.006053, lr: 0.001000, Time: 6.84s
Clean ACC: 7511/8000 = 0.938875, Loss: 0.2717065215110779
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 95 	Loss: 0.011902, lr: 0.001000, Time: 6.78s
Clean ACC: 7507/8000 = 0.938375, Loss: 0.2747114598751068
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 96 	Loss: 0.006611, lr: 0.001000, Time: 6.35s
Clean ACC: 7517/8000 = 0.939625, Loss: 0.27217161655426025
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 97 	Loss: 0.023898, lr: 0.001000, Time: 6.21s
Clean ACC: 7515/8000 = 0.939375, Loss: 0.2721898853778839
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 98 	Loss: 0.000548, lr: 0.001000, Time: 6.20s
Clean ACC: 7514/8000 = 0.939250, Loss: 0.27235791087150574
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 99 	Loss: 0.002190, lr: 0.001000, Time: 6.29s
Clean ACC: 7517/8000 = 0.939625, Loss: 0.27374589443206787
ASR: 7192/7193 = 0.999861


<Backdoor Training> Train Epoch: 100 	Loss: 0.000903, lr: 0.001000, Time: 6.22s
Clean ACC: 7509/8000 = 0.938625, Loss: 0.2736116051673889
ASR: 7192/7193 = 0.999861


Testing the backdoor model...
Evaluating model 'poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
Clean ACC: 7509/8000 = 0.938625, Loss: 0.2736116051673889
ASR: 7192/7193 = 0.999861

Visualizing the model's latent space...
Visualizing model 'poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7509/8000 = 0.938625, Loss: 0.2736074924468994
ASR: 7192/7193 = 0.999861

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.283910, poison_dis: 4.204110
Silhouette Score: 0.15591343
Saved figure at assets/pca_cifar10_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7509/8000 = 0.938625, Loss: 0.2736074924468994
ASR: 7192/7193 = 0.999861

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.283910, poison_dis: 4.204110
Silhouette Score: 0.15591343
Saved figure at assets/tsne_cifar10_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Visualizing model 'poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt' on cifar10...
[test]
Clean ACC: 7509/8000 = 0.938625, Loss: 0.2736074924468994
ASR: 7192/7193 = 0.999861

Total Clean: 49500
Total Poisoned: 500
torch.Size([512])
clean_dis: 3.283910, poison_dis: 4.204110
Silhouette Score: 0.15591343
SVM Accuracy: 1.0
Saved figure at assets/oracle_cifar10_trojan_0.010_poison_seed=0_full_base_aug_seed=2333.pt_class=0.png
Applying IBD_PSC defense method...
trigger_path: ./triggers/trojan_square_32.png
trigger_mask_path: ./triggers/mask_trojan_square_32.png
Evaluating model 'poisoned_train_set/cifar10/trojan_0.010_poison_seed=0/full_base_aug_seed=2333.pt'...
ba: 93.86250305175781
asr: 99.98609924316406
target label: tensor([0], device='cuda:0')
start_index: 10
TPR: 99.99
FPR: 7.41
AUC: 0.9999
f1 score: 0.9641996142719382
Elapsed time: 18.45s
Experiment for cifar10 with trojan completed.
